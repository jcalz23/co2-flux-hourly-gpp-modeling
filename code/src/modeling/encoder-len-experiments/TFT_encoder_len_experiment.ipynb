{"cells":[{"cell_type":"markdown","metadata":{"id":"CU5xMX4lMdOX"},"source":["# 0. Preparation"]},{"cell_type":"markdown","metadata":{"id":"tqqvjx_EMfQR"},"source":["## Mount google drive\n","- Make sure that available access is the user's own drive(no access across files in shared folder)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"2VY5heBv1X2o","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23dcaac8-9fe6-403b-f7f9-6a015e1a5506","executionInfo":{"status":"ok","timestamp":1678162205310,"user_tz":480,"elapsed":1159,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","  IN_COLLAB = True\n","else:\n","  IN_COLLAB = False\n","\n","#TODO: CHANGE THIS BASED ON YOUR OWN LOCAL SETTINGS\n","MY_HOME_ABS_PATH = \"/content/drive/MyDrive/W210/co2-flux-hourly-gpp-modeling\"\n","\n","if IN_COLLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"bOpEMAgCzHNc"},"source":["## (pip install)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"fi0G0eqBtg0V","executionInfo":{"status":"ok","timestamp":1678162217640,"user_tz":480,"elapsed":12336,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[],"source":["# install required modules quietly\n","required_packages = ['azure-storage-blob', 'pytorch_forecasting',\n","                     'numba', 'scikit-learn']\n","\n","for p in required_packages: \n","  try:\n","      __import__(p)\n","  except ImportError:\n","      %pip install {p} --quiet"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"E25Nsd7lD2FA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab5864c6-42db-4af0-f0d2-df91782b2275","executionInfo":{"status":"ok","timestamp":1678162223158,"user_tz":480,"elapsed":5527,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (0.13.5)\n","Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.10.1)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (0.5.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.22.4)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (23.0)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->statsmodels) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->statsmodels) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.2->statsmodels) (1.15.0)\n"]}],"source":["! pip install statsmodels --upgrade"]},{"cell_type":"code","source":["! pip install pytorch_lightning==1.9.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqjuRXA7awBH","executionInfo":{"status":"ok","timestamp":1678162227769,"user_tz":480,"elapsed":4640,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}},"outputId":"586e3588-66bf-4c85-d17d-d3d20176bab2"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch_lightning==1.9.0 in /usr/local/lib/python3.8/dist-packages (1.9.0)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (1.13.1+cu116)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (2023.1.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (4.5.0)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (23.0)\n","Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (0.7.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (6.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (1.22.4)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (0.11.3)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.9.0) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (2.25.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (3.8.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (3.0.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (6.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (22.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (1.8.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (4.0.2)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.9.0) (2.10)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Hcdd8BpC14Dr"},"source":["## Import libraries"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Rurx0Qa-tUIy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6535fc0b-a1e7-4e6a-f6fb-ea824857a205","executionInfo":{"status":"ok","timestamp":1678162227770,"user_tz":480,"elapsed":12,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"]},{"output_type":"execute_result","data":{"text/plain":["42"]},"metadata":{},"execution_count":26}],"source":["import os\n","import sys\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import copy\n","import json\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import TensorBoardLogger\n","import torch\n","import torch.nn as nn\n","\n","from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n","from pytorch_forecasting.data import GroupNormalizer\n","from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n","from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n","from pytorch_forecasting import BaseModel, MAE\n","from pytorch_forecasting.metrics.point import RMSE\n","from pytorch_forecasting.data.encoders import NaNLabelEncoder\n","\n","from sklearn.metrics import r2_score\n","from timeit import default_timer\n","\n","# Load locale custome modules\n","os.chdir(MY_HOME_ABS_PATH)\n","if IN_COLLAB:\n","  sys.path.insert(0,os.path.abspath(\"./code/src/tools\"))\n","else:\n","  sys.path.append(os.path.abspath(\"./code/src/tools\"))\n","  \n","from CloudIO.AzStorageClient import AzStorageClient\n","from data_pipeline_lib import *\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.float_format', lambda x: '%.5f' % x)\n","pl.seed_everything(42)"]},{"cell_type":"markdown","metadata":{"id":"5LRk1xhgDrvZ"},"source":["# Load data from Azure blob"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"Ndvl36VUIDjf","executionInfo":{"status":"ok","timestamp":1678162227770,"user_tz":480,"elapsed":8,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[],"source":["root_dir =  MY_HOME_ABS_PATH\n","tmp_dir =  root_dir + os.sep + '.tmp'\n","raw_data_dir = tmp_dir\n","data_dir = root_dir + os.sep + 'data'\n","model_dir = data_dir + os.sep + 'model'\n","cred_dir = root_dir + os.sep + '.cred'\n","az_cred_file = cred_dir + os.sep + 'azblobcred.json'\n","\n","container = \"all-sites-data\"\n","blob_name = \"full_2010_2015_all_v_exp_raw.parquet\"\n","local_file = tmp_dir + os.sep + blob_name"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"z8T-YT1fEXjR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"33bd9cbd-f42f-40e1-9db1-0602d00002ea","executionInfo":{"status":"ok","timestamp":1678162268614,"user_tz":480,"elapsed":40851,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data size: (4822944, 50)\n","Data size: (4818384, 50)\n"]}],"source":["# Download full data\n","data_df = None\n","\n","if not (os.path.exists(local_file)):\n","    azStorageClient = AzStorageClient(az_cred_file)\n","    file_stream = azStorageClient.downloadBlob2Stream(container, blob_name)\n","    data_df = pd.read_parquet(file_stream, engine='pyarrow')\n","    data_df.to_parquet(local_file)\n","else:\n","    data_df = pd.read_parquet(local_file)\n","print(f\"Data size: {data_df.shape}\")\n","\n","# Convert Dtypes\n","cat_cols = [\"year\", \"month\", \"day\", \"hour\", \"IGBP\", \"koppen_main\", \"koppen_sub\", \n","            \"gap_flag_month\", \"gap_flag_hour\"]\n","for col in cat_cols:\n","  data_df[col] = data_df[col].astype(str).astype(\"category\")\n","\n","data_df.dropna(inplace=True)\n","print(f\"Data size: {data_df.shape}\")"]},{"cell_type":"code","source":["data_df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z9CyY-z359Yt","executionInfo":{"status":"ok","timestamp":1678162268615,"user_tz":480,"elapsed":30,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}},"outputId":"d176abb0-a897-40cf-e576-d0e6bc488861"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['GPP_NT_VUT_REF', 'site_id', 'timestep_idx_local',\n","       'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day',\n","       'hour', 'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA',\n","       'PA_ERA', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',\n","       'b7', 'IGBP', 'lat', 'long', 'koppen_sub', 'koppen_main', 'c3c4',\n","       'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily',\n","       'PET', 'Ts', 'ESACCI-sm', 'MODIS_LC', 'NDWI', 'Percent_Snow', 'Fpar',\n","       'Lai', 'LST_Day', 'LST_Night', 'MODIS_PFT', 'gap_flag_hour',\n","       'gap_flag_month'],\n","      dtype='object')"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["data_df.isna().sum().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JIM-93h6bwF","executionInfo":{"status":"ok","timestamp":1678162270095,"user_tz":480,"elapsed":1507,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}},"outputId":"82ce7fb4-1692-4bb0-e259-eec792f527fd"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"xrphWFPqzUv8"},"source":["# Data Preprocessing Methods"]},{"cell_type":"code","source":["SITE_SPLITS =[\n","  ['AR-SLu', 'AU-ASM', 'AU-Cum', 'AU-How', 'CA-TP3', 'CA-TPD', 'CN-Sw2', 'DE-Lnf',\n","   'IT-CA3', 'NL-Hor', 'US-Syv', 'US-AR2', 'US-ARM', 'US-Vcp', 'CH-Cha', 'CZ-KrP', \n","   'CZ-Lnz', 'DE-Geb', 'DE-Obe', 'ES-LJu', 'FI-Let', 'IT-Lav', 'SE-Deg'],\n","  ['AU-Cpr', 'AU-Wom', 'CZ-BK2', 'DE-SfN', 'IT-CA1', 'IT-CA2', 'IT-Ro2', 'US-IB2', \n","   'US-Me6', 'US-Ton', 'CA-Ca3', 'US-CRT', 'US-KFS', 'US-Mpj', 'US-Prr', 'US-Ro1', \n","   'US-Tw4', 'BE-Bra', 'CZ-BK1', 'DE-Hai', 'IL-Yat', 'IT-Tor', 'SE-Htm'],\n","  ['AT-Neu', 'AU-RDF', 'AU-Whr', 'CA-TP1', 'DE-Zrk', 'IT-SRo', 'US-Wkg', 'CA-Ca2',\n","   'CA-TP4', 'US-Bar', 'US-Fmf', 'US-Oho', 'US-SRG', 'US-Ses', 'CH-Lae', 'CZ-RAJ',\n","   'CZ-wet', 'DE-Kli', 'DE-RuR', 'ES-LM2', 'FR-Fon', 'FR-Lam'],\n","  ['AR-Vir', 'AU-DaS', 'AU-Emr', 'AU-Gin', 'AU-Rig', 'AU-TTE', 'DE-Spw', 'FR-Pue',\n","   'IT-Isp', 'IT-Noe', 'US-Twt', 'US-WPT', 'CA-Cbo', 'US-Vcm', 'BE-Dor', 'BE-Vie',\n","   'CZ-Stn', 'FI-Hyy', 'SE-Nor', 'SE-Ros', 'NL-Loo', 'SE-Lnn'],\n","  ['AU-DaP', 'AU-GWW', 'AU-Rob', 'AU-Stp', 'US-GLE', 'US-NR1', 'US-Whs', 'CA-Ca1',\n","   'CA-Gro', 'US-AR1', 'US-Rws', 'US-UMd', 'US-Wjs', 'CH-Fru', 'CH-Oe2', 'DE-Tha',\n","   'DK-Sor', 'FR-Bil', 'FR-Hes', 'IT-BCi', 'IT-SR2', 'DE-Hte'],\n","  ['CA-Oas', 'ES-Amo', 'FI-Sod', 'US-Myb', 'US-SRM', 'US-Tw3', 'US-Var', 'US-WCr',\n","   'US-Ho1', 'US-Seg', 'US-UMB', 'BE-Lon', 'CH-Dav', 'DE-Gri', 'DE-HoH', 'ES-LM1',\n","   'FR-Aur', 'FR-FBn', 'GF-Guy', 'IT-MBo', 'IT-Ren', 'RU-Fyo']\n","]\n","\n","def get_splited_datasets(df, val_index, test_index): \n","  train_sites, val_sites, test_sites = [], [], []\n","  for i, subset in enumerate(SITE_SPLITS):\n","    if i == val_index:\n","      val_sites = SITE_SPLITS[i]\n","    elif i == test_index:\n","      test_sites = SITE_SPLITS[i]\n","    else:\n","      train_sites += SITE_SPLITS[i]\n","\n","  train_df = data_df.loc[data_df['site_id'].isin(train_sites), ].copy()\n","  val_df   = data_df.loc[data_df['site_id'].isin(val_sites), ].copy()\n","\n","  if len(train_df['site_id'].unique()) != len(train_sites):\n","    print(f\"Expected Train({len(train_sites)}): {train_sites}\")\n","    print(f\"Actual Train({len(train_df['site_id'].unique())}): {train_df['site_id'].unique()}\")\n","  \n","  if len(val_df['site_id'].unique()) != len(val_sites):\n","    print(f\"Expected Val({len(val_sites)}): {val_sites}\")\n","    print(f\"Actual Val({len(val_df['site_id'].unique())}): {val_df['site_id'].unique()}\")\n","\n","  if test_index is not None:\n","    test_df = data_df.loc[data_df['site_id'].isin(test_sites), ].copy()\n","    if len(test_df['site_id'].unique()) != len(test_sites):\n","      print(f\"Expected Test({len(test_sites)}): {test_sites}\")\n","      print(f\"Actual Test({len(test_df['site_id'].unique())}): {test_df['site_id'].unique()}\")\n","  else:\n","    test_df = None\n","\n","  return (train_df, val_df, test_df)\n","\n","def subset_data(train_df, val_df, test_df, subset_len):\n","  print(f'Subest length: {subset_len} timesteps')\n","  # Subset the time series within sites to save more time (300 timesteps)\n","  train_df = train_df.loc[train_df['timestep_idx_global'] < subset_len, ].copy()\n","  print(f\"Subset num train timesteps: {len(train_df)}\")\n","  val_df = val_df.loc[val_df['timestep_idx_global'] < subset_len, ].copy()\n","  print(f\"Subset num val timesteps: {len(val_df)}\")\n","  if test_df is not None:\n","    test_df = test_df.loc[test_df['timestep_idx_global'] < subset_len, ].copy()\n","    print(f\"Subset num test timesteps: {len(test_df)}\")\n","\n","  return (train_df, val_df, test_df)"],"metadata":{"id":"PrvMVkItclOF","executionInfo":{"status":"ok","timestamp":1678162327400,"user_tz":480,"elapsed":154,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# Run Experiment"],"metadata":{"id":"Yx8fHH5jr4z3"}},{"cell_type":"code","source":["def setup_train_val_tsdataset(train_df, val_df, min_encoder_len):\n","  # create training and validation TS dataset \n","  training = TimeSeriesDataSet(\n","      train_df, # <------ no longer subsetting, option 1 split can use entire train site sequence\n","      time_idx=\"timestep_idx_global\",\n","      target=\"GPP_NT_VUT_REF\",\n","      group_ids=[\"site_id\"],\n","      allow_missing_timesteps=True, # <---- turned on bc some rows are removed.\n","      min_encoder_length=min_encoder_len,\n","      max_encoder_length=min_encoder_len,\n","      min_prediction_length=max_prediction_length,\n","      max_prediction_length=max_prediction_length,\n","      static_categoricals=[\"IGBP\",\"koppen_main\",\"koppen_sub\", \"gap_flag_month\", \"gap_flag_hour\"],\n","      static_reals=[], #elevation lat long\n","      time_varying_known_categoricals=[\"year\", \"month\", \"day\", \"hour\"],\n","      time_varying_known_reals=[\"timestep_idx_global\", \n","                                'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA', 'PA_ERA',\n","                                'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', \n","                                'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily', 'PET', 'Ts', \n","                                'ESACCI-sm', 'NDWI', 'Percent_Snow', 'Fpar', 'Lai', 'LST_Day','LST_Night'],\n","      time_varying_unknown_categoricals=[], \n","      time_varying_unknown_reals=[\"GPP_NT_VUT_REF\"],\n","      target_normalizer=None, # <---- not sure if we need this given we scale in data pipeline.... but might want to change to scale at Group level?\n","      categorical_encoders={'IGBP': NaNLabelEncoder(add_nan=True),\n","                            'koppen_main': NaNLabelEncoder(add_nan=True),\n","                            'koppen_sub': NaNLabelEncoder(add_nan=True),\n","                            'year': NaNLabelEncoder(add_nan=True), # temp for subset\n","                            'month': NaNLabelEncoder(add_nan=True), # temp for subset\n","                            'day': NaNLabelEncoder(add_nan=True), # temp for subset\n","                            },\n","      add_relative_time_idx=True,\n","      add_target_scales=False, # <------- turned off\n","      add_encoder_length=False, # <------- turned off\n","  )\n","  \n","  validation = TimeSeriesDataSet.from_dataset(training, val_df, predict=True, stop_randomization=True)\n","\n","  return (training, validation)\n","\n","def get_eval_metrics(predictions, actuals):\n","    \n","    mae = (actuals - predictions).abs().mean()\n","    \n","    criterion = nn.MSELoss()\n","    rmse = torch.sqrt(criterion(actuals, predictions))\n","\n","    r2 = r2_score(actuals, predictions)\n","\n","    return { 'mae': mae, 'rmse': rmse, 'r2':r2}"],"metadata":{"id":"gkwIa1LRDyx3","executionInfo":{"status":"ok","timestamp":1678162330961,"user_tz":480,"elapsed":153,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","execution_count":35,"metadata":{"id":"ZCPmz6c6FxSQ","executionInfo":{"status":"ok","timestamp":1678162333999,"user_tz":480,"elapsed":222,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[],"source":["# (data is already splited to train/validation set)\n","max_prediction_length = 1 #24\n","max_encoder_length_candidates =  [24*7, 24*7*2, 24*7*4, 24*7*4*3]\n","exp_names = [\"1 Week\", \"2 Weeks\", \"1 Month\", \"3 Months\"]\n","\n","TEST_INDEX = 5\n","VAL_INDICES = [0, 2, 4]\n","SUBSET_LEN = int(24*7*4*3*1.5)\n","\n","if not (os.path.exists(model_dir)):\n","  os.makedirs(model_dir)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"EiRHlcR60ZJQ","colab":{"base_uri":"https://localhost:8080/","height":799},"outputId":"fe3877b2-1417-4e05-b59a-7b4c24852586","executionInfo":{"status":"error","timestamp":1678162342010,"user_tz":480,"elapsed":6972,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment: max_encoder_length = 168 (1 Week)\n","Expected Train(111): ['AU-Cpr', 'AU-Wom', 'CZ-BK2', 'DE-SfN', 'IT-CA1', 'IT-CA2', 'IT-Ro2', 'US-IB2', 'US-Me6', 'US-Ton', 'CA-Ca3', 'US-CRT', 'US-KFS', 'US-Mpj', 'US-Prr', 'US-Ro1', 'US-Tw4', 'BE-Bra', 'CZ-BK1', 'DE-Hai', 'IL-Yat', 'IT-Tor', 'SE-Htm', 'AT-Neu', 'AU-RDF', 'AU-Whr', 'CA-TP1', 'DE-Zrk', 'IT-SRo', 'US-Wkg', 'CA-Ca2', 'CA-TP4', 'US-Bar', 'US-Fmf', 'US-Oho', 'US-SRG', 'US-Ses', 'CH-Lae', 'CZ-RAJ', 'CZ-wet', 'DE-Kli', 'DE-RuR', 'ES-LM2', 'FR-Fon', 'FR-Lam', 'AR-Vir', 'AU-DaS', 'AU-Emr', 'AU-Gin', 'AU-Rig', 'AU-TTE', 'DE-Spw', 'FR-Pue', 'IT-Isp', 'IT-Noe', 'US-Twt', 'US-WPT', 'CA-Cbo', 'US-Vcm', 'BE-Dor', 'BE-Vie', 'CZ-Stn', 'FI-Hyy', 'SE-Nor', 'SE-Ros', 'NL-Loo', 'SE-Lnn', 'AU-DaP', 'AU-GWW', 'AU-Rob', 'AU-Stp', 'US-GLE', 'US-NR1', 'US-Whs', 'CA-Ca1', 'CA-Gro', 'US-AR1', 'US-Rws', 'US-UMd', 'US-Wjs', 'CH-Fru', 'CH-Oe2', 'DE-Tha', 'DK-Sor', 'FR-Bil', 'FR-Hes', 'IT-BCi', 'IT-SR2', 'DE-Hte', 'CA-Oas', 'ES-Amo', 'FI-Sod', 'US-Myb', 'US-SRM', 'US-Tw3', 'US-Var', 'US-WCr', 'US-Ho1', 'US-Seg', 'US-UMB', 'BE-Lon', 'CH-Dav', 'DE-Gri', 'DE-HoH', 'ES-LM1', 'FR-Aur', 'FR-FBn', 'GF-Guy', 'IT-MBo', 'IT-Ren', 'RU-Fyo']\n","Actual Train(103): ['AR-Vir' 'AT-Neu' 'AU-Cpr' 'AU-DaP' 'AU-DaS' 'AU-Emr' 'AU-Gin' 'AU-RDF'\n"," 'AU-Rig' 'AU-Stp' 'AU-TTE' 'AU-Whr' 'AU-Wom' 'BE-Bra' 'BE-Dor' 'BE-Lon'\n"," 'BE-Vie' 'CA-Ca3' 'CA-Cbo' 'CA-Gro' 'CA-Oas' 'CA-TP1' 'CA-TP4' 'CH-Dav'\n"," 'CH-Fru' 'CH-Lae' 'CH-Oe2' 'CZ-BK1' 'CZ-BK2' 'CZ-RAJ' 'CZ-Stn' 'CZ-wet'\n"," 'DE-Gri' 'DE-Hai' 'DE-HoH' 'DE-Hte' 'DE-Kli' 'DE-RuR' 'DE-SfN' 'DE-Spw'\n"," 'DE-Tha' 'DK-Sor' 'ES-Amo' 'ES-LM1' 'ES-LM2' 'FI-Hyy' 'FI-Sod' 'FR-Aur'\n"," 'FR-Bil' 'FR-FBn' 'FR-Fon' 'FR-Hes' 'FR-Lam' 'FR-Pue' 'GF-Guy' 'IL-Yat'\n"," 'IT-BCi' 'IT-CA1' 'IT-CA2' 'IT-MBo' 'IT-Noe' 'IT-Ren' 'IT-Ro2' 'IT-SR2'\n"," 'IT-SRo' 'IT-Tor' 'NL-Loo' 'RU-Fyo' 'SE-Htm' 'SE-Lnn' 'SE-Nor' 'US-AR1'\n"," 'US-Bar' 'US-CRT' 'US-Fmf' 'US-GLE' 'US-Ho1' 'US-IB2' 'US-KFS' 'US-Me6'\n"," 'US-Mpj' 'US-Myb' 'US-NR1' 'US-Oho' 'US-Prr' 'US-Ro1' 'US-Rws' 'US-SRG'\n"," 'US-SRM' 'US-Seg' 'US-Ses' 'US-Ton' 'US-Tw4' 'US-Twt' 'US-UMB' 'US-UMd'\n"," 'US-Var' 'US-Vcm' 'US-WCr' 'US-WPT' 'US-Whs' 'US-Wjs' 'US-Wkg']\n","Expected Val(23): ['AR-SLu', 'AU-ASM', 'AU-Cum', 'AU-How', 'CA-TP3', 'CA-TPD', 'CN-Sw2', 'DE-Lnf', 'IT-CA3', 'NL-Hor', 'US-Syv', 'US-AR2', 'US-ARM', 'US-Vcp', 'CH-Cha', 'CZ-KrP', 'CZ-Lnz', 'DE-Geb', 'DE-Obe', 'ES-LJu', 'FI-Let', 'IT-Lav', 'SE-Deg']\n","Actual Val(22): ['AR-SLu' 'AU-ASM' 'AU-Cum' 'AU-How' 'CA-TP3' 'CA-TPD' 'CH-Cha' 'CZ-KrP'\n"," 'CZ-Lnz' 'DE-Geb' 'DE-Lnf' 'DE-Obe' 'ES-LJu' 'FI-Let' 'IT-CA3' 'IT-Lav'\n"," 'NL-Hor' 'SE-Deg' 'US-AR2' 'US-ARM' 'US-Syv' 'US-Vcp']\n","Subest length: 3024 timesteps\n","Subset num train timesteps: 206856\n","Subset num val timesteps: 45360\n","  Number of parameters in network: 61.4k\n"]},{"output_type":"error","ename":"MisconfigurationException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-83f248e6c0f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoardLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lightning_logs\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# logging results to a tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     trainer = pl.Trainer(\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0menable_model_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/argparse.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, inference_mode)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_connector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple_trainloader_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         self._accelerator_connector = AcceleratorConnector(\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_auto_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_gpu_accelerator_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_parallel_devices_and_init_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m_choose_gpu_accelerator_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No supported gpu backend found!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_parallel_devices_and_init_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMisconfigurationException\u001b[0m: No supported gpu backend found!"]}],"source":["experiment_result = pd.DataFrame(columns=['experiment', 'fold', 'val_index',\n","                                        'training_time', 'eval_time',\n","                                        'MAE', 'RMSE', 'R2',\n","                                        'model_path'])\n","\n","for i, max_encoder_len in enumerate(max_encoder_length_candidates):\n","  print(f'Experiment: max_encoder_length = {max_encoder_len} ({exp_names[i]})')\n","  \n","  for k, val_index in enumerate(VAL_INDICES):\n","\n","    train_time, eval_time = 0, 0\n","\n","    # split data\n","    train_df, val_df, test_df = get_splited_datasets(data_df, val_index, None)\n","    train_df, val_df, test_df = subset_data(train_df, val_df, test_df, SUBSET_LEN)\n","    (training, validation) = setup_train_val_tsdataset(train_df, val_df, max_encoder_len)\n","\n","    # create dataloaders for model\n","    batch_size = 32  # set this between 32 to 128\n","    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n","    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)\n","\n","    # Create TFT model from dataset\n","    tft = TemporalFusionTransformer.from_dataset(\n","        training,\n","        learning_rate=1e-3,\n","        hidden_size=16,  # most important hyperparameter apart from learning rate\n","        attention_head_size=1, # Set to up to 4 for large datasets\n","        dropout=0.1,           # Between 0.1 and 0.3 are good values\n","        hidden_continuous_size=8,  # set to <= hidden_size\n","        output_size=7,  # 7 quantiles by default\n","        loss=QuantileLoss(),\n","        logging_metrics=nn.ModuleList([MAE(), RMSE()]), #SMAPE(), #MAPE() #<---- added metrics to report in TensorBoard\n","        reduce_on_plateau_patience=4, # reduce learning rate if no improvement in validation loss after x epochs\n","        optimizer=\"adam\"\n","        )\n","    print(f\"  Number of parameters in network: {tft.size()/1e3:.1f}k\")\n","\n","    # configure network and trainer\n","    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n","    lr_logger = LearningRateMonitor()  # log the learning rate\n","    logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n","\n","    trainer = pl.Trainer(\n","        max_epochs=2,\n","        enable_model_summary=True,\n","        gradient_clip_val=0.1,\n","        fast_dev_run=False,  # comment in to check that network or dataset has no serious bugs\n","        accelerator='gpu',\n","        devices=1,\n","        callbacks=[lr_logger, early_stop_callback],\n","        logger=logger,\n","    )\n","\n","    start = default_timer()\n","    trainer.fit(\n","        tft,\n","        train_dataloaders=train_dataloader,\n","        val_dataloaders=val_dataloader,\n","    )\n","    train_time = default_timer() - start\n","    print(f\"  Training time: {train_time}\")\n","\n","    # load the best model according to the validation loss\n","    best_model_path = trainer.checkpoint_callback.best_model_path\n","    print(\"  Best model path: \" + best_model_path)\n","    best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n","\n","    exp_dir = model_dir + os.sep + exp_names[i]\n","    if not (os.path.exists(exp_dir)):\n","      os.makedirs(exp_dir)\n","    local_model_path = exp_dir + os.sep + f\"fold-{k}-model.pth\"\n","    torch.save(best_tft.state_dict(), local_model_path)\n","    print(f\" Saved model to {local_model_path}\")\n","\n","    # Print Model Eval on Validation Set\n","    start = default_timer()\n","    actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n","    predictions = best_tft.predict(val_dataloader)\n","    eval_time = default_timer() - start\n","    print(f\"  Val eval time: {eval_time}\")\n","\n","    eval_metric = get_eval_metrics\n","    print(eval_metric)\n","    result_data = {  'experiment': exp_names[i], \n","                     'fold': k+1, \n","                     'val_index': val_index,\n","                     'training_time': train_time, \n","                     'eval_time': eval_time,\n","                     'model_path': local_model_path,\n","                     'MAE': eval_metric['MAE'],\n","                     'RMSE': eval_metric['RMSE'],\n","                     'R2': eval_metric['R2']}\n","    experiment_result = experiment_result.append(result_data, ignore_index=True)\n","  \n","  # Print experiment results\n","  display(experiment_result[experiment_result['experiment'] ==  exp_names[i]])"]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"Ybfazoz-HPfU"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["tqqvjx_EMfQR","bOpEMAgCzHNc"],"provenance":[],"machine_shape":"hm"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}