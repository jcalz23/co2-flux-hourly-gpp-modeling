{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFP4auo0a4R8",
        "outputId": "5b1687b9-14d2-4bbd-a902-16ad6f1144f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaXGMTqJr71d"
      },
      "source": [
        "# Notebook Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    IN_COLLAB = True\n",
        "else:\n",
        "    IN_COLLAB = False\n",
        "\n",
        "if IN_COLLAB:\n",
        "    #TODO: CHANGE THIS BASED ON YOUR OWN LOCAL SETTINGS\n",
        "    # MY_HOME_ABS_PATH = \"/content/drive/MyDrive/W210/co2-flux-hourly-gpp-modeling\"\n",
        "    MY_HOME_ABS_PATH = \"/content/drive/MyDrive/TFT_baseline\"\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "else:\n",
        "    # MY_HOME_ABS_PATH = \"/root/co2-flux-hourly-gpp-modeling/\"\n",
        "    MY_HOME_ABS_PATH = \"/home/ec2-user/SageMaker/root/co2-flux-hourly-gpp-modeling\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDKm-L00cbfQ",
        "outputId": "83a376c9-934b-4901-cd64-c4e4d6ca74d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "KaBFcdIwamyE"
      },
      "outputs": [],
      "source": [
        "#TODO: CHANGE THIS BASED ON YOUR OWN LOCAL SETTINGS\n",
        "#MY_HOME_ABS_PATH = \"/Users/jetcalz07/Desktop/MIDS/W210_Capstone/co2-flux-hourly-gpp-modeling\"\n",
        "# MY_HOME_ABS_PATH = \"/root/co2-flux-hourly-gpp-modeling\"\n",
        "MY_HOME_ABS_PATH =  \"/content/drive/MyDrive/TFT_baseline\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2bHb6TEy3_D"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure.storage.blob "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSrZ4-MmbM6f",
        "outputId": "6b122fd1-2b42-46f7-ef7f-d031ef86386d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting azure.storage.blob\n",
            "  Downloading azure_storage_blob-12.15.0-py3-none-any.whl (387 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.8/387.8 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.26.0\n",
            "  Downloading azure_core-1.26.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from azure.storage.blob) (4.5.0)\n",
            "Collecting isodate>=0.6.1\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.9/dist-packages (from azure.storage.blob) (40.0.1)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.9/dist-packages (from azure-core<2.0.0,>=1.26.0->azure.storage.blob) (2.27.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from azure-core<2.0.0,>=1.26.0->azure.storage.blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=2.1.4->azure.storage.blob) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure.storage.blob) (2.21)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (2022.12.7)\n",
            "Installing collected packages: isodate, azure-core, azure.storage.blob\n",
            "Successfully installed azure-core-1.26.3 azure.storage.blob-12.15.0 isodate-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FdqnNwZbM3M",
        "outputId": "9647b375-82f0-48d6-8ca0-f0a49c3ee8c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.0.1-py3-none-any.whl (716 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.4/716.4 KB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (23.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (1.13.1+cu116)\n",
            "Collecting lightning-utilities>=0.7.0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (2023.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.5.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.65.0)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, torchmetrics, aiosignal, aiohttp, pytorch_lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch_lightning-2.0.1 torchmetrics-0.11.4 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_forecasting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKLebkmpbpB-",
        "outputId": "2028f1ec-4576-4eb2-be7a-4a7eb63cd5ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_forecasting\n",
            "  Downloading pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/141.4 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from pytorch_forecasting) (3.7.1)\n",
            "Collecting scikit-learn<1.2,>=0.24\n",
            "  Downloading scikit_learn-1.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning<2.0.0,>=1.2.4\n",
            "  Downloading pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 KB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna<3.0.0,>=2.3.0\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.2/308.2 KB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_forecasting) (1.4.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.9/dist-packages (from pytorch_forecasting) (0.13.5)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.9/dist-packages (from pytorch_forecasting) (1.10.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.7 in /usr/local/lib/python3.9/dist-packages (from pytorch_forecasting) (1.13.1+cu116)\n",
            "Collecting cliff\n",
            "  Downloading cliff-4.2.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (23.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.65.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.4.47)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (2023.3.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (0.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (0.8.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (3.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch_forecasting) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch_forecasting) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch_forecasting) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch_forecasting) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch_forecasting) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch_forecasting) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch_forecasting) (0.11.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.9/dist-packages (from statsmodels->pytorch_forecasting) (0.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (3.8.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->pytorch_forecasting) (3.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.2->statsmodels->pytorch_forecasting) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.0.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-5.0.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.9/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.7.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (6.1.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (1.8.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.6)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch_forecasting) (1.26.15)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11135 sha256=7cb8e7287955cac85a6f6d5d41e161366588e5e326e6ee47aee330221277fc2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/09/9e/49e21a6840ef7955b06d47394afef0058f0378c0914e48b8b8\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, Mako, colorlog, cmd2, cmaes, autopage, stevedore, scikit-learn, alembic, cliff, pytorch-lightning, optuna, pytorch_forecasting\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pytorch-lightning\n",
            "    Found existing installation: pytorch-lightning 2.0.1\n",
            "    Uninstalling pytorch-lightning-2.0.1:\n",
            "      Successfully uninstalled pytorch-lightning-2.0.1\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 autopage-0.5.1 cliff-4.2.0 cmaes-0.9.1 cmd2-2.4.3 colorlog-6.7.0 optuna-2.10.1 pbr-5.11.1 pyperclip-1.8.2 pytorch-lightning-1.9.4 pytorch_forecasting-0.10.3 scikit-learn-1.1.3 stevedore-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient\n",
        "from collections import defaultdict\n",
        "from io import BytesIO\n",
        "import os.path\n",
        "import json\n",
        "\n",
        "class AzStorageClient:\n",
        "    def __init__(self, cred_file):\n",
        "        self.blob_svc_client = None\n",
        "        self.container_client_list = defaultdict(str)\n",
        "        if os.path.exists(cred_file):\n",
        "            connect_str = \"\"\n",
        "            with open(cred_file, \"rb\") as f:\n",
        "                data = json.load(f)\n",
        "                connect_str = data['connectionstr']\n",
        "                self.blob_svc_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "                tokens = connect_str.split(';')\n",
        "                for t in tokens:\n",
        "                  if \"AccountName=\" in t:\n",
        "                    self.AccountName = t[len(\"AccountName=\"):]\n",
        "                  elif \"AccountKey=\" in t:\n",
        "                    self.AccountKey = t[len(\"AccountKey=\"):]\n",
        "        else:\n",
        "            print(\"ERROR: {cred_file} not found\")\n",
        "    \n",
        "    def getSparkSessionKeys(self):\n",
        "      return [f'fs.azure.account.key.{self.AccountName}.blob.core.windows.net',  self.AccountKey, self.AccountName]\n",
        "\n",
        "    def createContainer(self, container_name):\n",
        "        if self.blob_svc_client:\n",
        "            self.blob_svc_client.create_container(container_name)\n",
        "            print(f\"Container '{container_name}' created.\")\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "\n",
        "    def listBlobs(self, container_name):\n",
        "        if self.blob_svc_client:\n",
        "            if not self.container_client_list[container_name]:\n",
        "                self.container_client_list[container_name] = self.blob_svc_client.get_container_client(container= container_name)\n",
        "            blob_list = self.container_client_list[container_name].list_blobs()\n",
        "            return blob_list\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "\n",
        "    def uploadBlob(self, container_name, blob_name, data, overwrite=False, verbose=True):\n",
        "        if self.blob_svc_client:\n",
        "            blob_cleint = self.blob_svc_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "            blob_cleint.upload_blob(data, overwrite=overwrite)\n",
        "            if verbose:\n",
        "                print(f'File uploaded to {container_name}/{blob_name}')\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    \n",
        "    def downloadBlob(self, container_name, blob_name):\n",
        "        if self.blob_svc_client:\n",
        "            if not self.container_client_list[container_name]:\n",
        "                self.container_client_list[container_name] = self.blob_svc_client.get_container_client(container= container_name)\n",
        "            \n",
        "            return self.container_client_list[container_name].download_blob(blob_name).readall()\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    \n",
        "    def downloadBlob2Stream(self, container_name, blob_name):\n",
        "        if self.blob_svc_client:\n",
        "            if not self.container_client_list[container_name]:\n",
        "                self.container_client_list[container_name] = self.blob_svc_client.get_container_client(container= container_name)\n",
        "            \n",
        "            stream = BytesIO()\n",
        "            self.container_client_list[container_name].download_blob(blob_name).readinto(stream)\n",
        "            return stream\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    \n",
        "    def deleteBlob(self, container_name, blob_name, verbose=True):\n",
        "        if self.blob_svc_client:\n",
        "            blob_client = self.blob_svc_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "            blob_client.delete_blob()\n",
        "            if verbose:\n",
        "                print(f'{container_name}/{blob_name} deleted')\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    "
      ],
      "metadata": {
        "id": "eKthP2bscHFb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime \n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# if (\"UseSpark\" in os.environ) or (os.environ.get('UseSpark') == \"true\"):\n",
        "#   from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
        "#   from pyspark.sql.functions import col\n",
        "\n",
        "from IPython.display import display\n",
        "# from CloudIO.AzStorageClient import AzStorageClient\n",
        "# import AzStorageClient\n",
        "\n",
        "def get_min_max(df):\n",
        "  return (df.min(), df.max())\n",
        "\n",
        "def get_min_max_datetime(df):\n",
        "  return (pd.to_datetime(df).min(), pd.to_datetime(df).max())\n",
        "\n",
        "def is_leap_year(year):\n",
        "  return year%4 == 0 ;\n",
        "\n",
        "def data_cleanup(data_dir, site_id_file_df, target, target_qc, features):\n",
        "  data_df = None\n",
        "  # qc_flag_dtype = CategoricalDtype([0, 1, 2, 3], ordered=True)\n",
        "  qc_flags_features = [s for s in features if \"_QC\" in s]\n",
        "\n",
        "  # Iterate through each site:\n",
        "  for i, r in site_id_file_df.iterrows():        \n",
        "    if not r.filename or type(r.filename) != type(\"\"):\n",
        "      print(f'\\nERROR: {r.site_id} is mssing hourly data.')\n",
        "      continue\n",
        "\n",
        "    # Get only `features` from file\n",
        "    local_filename = data_dir + os.sep + r.filename\n",
        "    site_df = pd.read_csv(local_filename, usecols = [target, target_qc] + features)\n",
        "    site_df['datetime'] = pd.to_datetime(site_df['datetime'])\n",
        "    site_df['date'] = pd.to_datetime(site_df['date'])\n",
        "    site_df['minute'] = site_df['datetime'].dt.minute\n",
        "    if len(qc_flags_features) != 0:\n",
        "      site_df[qc_flags_features] = site_df[qc_flags_features].astype('int')\n",
        "    site_df['site_id'] = r.site_id\n",
        "\n",
        "    # Add time index columns\n",
        "    site_df = add_time_index(site_df, 'datetime', '30T')\n",
        "\n",
        "    # Remove zero or negative SW\n",
        "    site_df.drop(site_df[site_df['SW_IN_ERA'] <= 0].index, inplace = True)\n",
        "\n",
        "    # Drop rows with NAs for Target Variable\n",
        "    site_df.dropna(subset=[target], axis=0, inplace=True)\n",
        "\n",
        "    # Drop rows with bad NEE_VUT_REF_QC (aka bad GPP records)\n",
        "    site_df.drop(site_df[site_df[target_qc] == 3].index, inplace = True)\n",
        "    site_df.drop([target_qc], axis=1, inplace=True)\n",
        "\n",
        "    # Drop rows with any NA\n",
        "    site_df.dropna(axis=0, inplace=True)\n",
        "\n",
        "    print(f\"{r.site_id}: {site_df.shape}\")\n",
        "    if type(data_df) == type(None):\n",
        "      data_df = site_df\n",
        "    else:\n",
        "      data_df = pd.concat([data_df, site_df])\n",
        "          \n",
        "  return data_df\n",
        "\n",
        "def merge_site_metadata(data_df, site_metadata_df):\n",
        "  data_df = data_df.merge(site_metadata_df, how='left', left_on='site_id', right_on='site_id')\n",
        "  return data_df\n",
        "\n",
        "def check_and_drop_na(data_df):\n",
        "  if data_df.isna().sum().sum() > 0:\n",
        "    print(\"Data has NA.\")\n",
        "    display(pd.DataFrame(data_df.isna().sum()).T)\n",
        "    data_df.dropna(axis=0, inplace=True)\n",
        "  else:\n",
        "    print(\"Datas has no NA.\")\n",
        "\n",
        "def add_time_index(data_df, time_col, duration):\n",
        "  resampled_df = data_df.sort_values(by=[time_col])\n",
        "  resampled_df.set_index(time_col, inplace=True)\n",
        "  resampled_df = resampled_df.resample(duration).mean()\n",
        "  resampled_df = resampled_df.reset_index()\n",
        "  resampled_df.index.name='timestep_idx'\n",
        "  resampled_df = resampled_df.reset_index()\n",
        "  data_df = data_df.merge(resampled_df[[time_col, 'timestep_idx']], how='left', on='datetime')\n",
        "  return data_df\n",
        "\n",
        "\n",
        "class PrepareMonthlyData:\n",
        "    def __init__(self, included_features, monthly_data_input_fname, data_dir):\n",
        "        self.included_features =included_features\n",
        "        self.data_dir = data_dir\n",
        "        self.monthly_data_input_fname = monthly_data_input_fname\n",
        "        self.month_df = pd.read_csv(self.monthly_data_input_fname, usecols=self.included_features)\n",
        "        self.month_df['date'] = pd.to_datetime(self.month_df['TIMESTAMP'],  format=\"%Y%m\")\n",
        "\n",
        "\n",
        "    def to_datetime(self, row):\n",
        "        return pd.to_datetime(f'{row.year}{row.month:02}', format='%Y%m')\n",
        "\n",
        "\n",
        "    def knn_impute(self, df, knn_imp_cols, k, weights):\n",
        "        # Fit and transform the data using KNNImputer, format as DF\n",
        "        inds = df.index.copy()\n",
        "        df_subcols = df[knn_imp_cols].copy()\n",
        "        df_subcols = df_subcols.dropna(axis=1, how='all')\n",
        "\n",
        "        # Execute imputation\n",
        "        imputer = KNNImputer(n_neighbors=k, weights=weights)\n",
        "        imputed_group = imputer.fit_transform(df_subcols)\n",
        "        imputed_group = pd.DataFrame(imputed_group, columns=df_subcols.columns, index=inds)\n",
        "\n",
        "        # Fill NA in initial site/group df\n",
        "        df.fillna(imputed_group, inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    def impute(self, impute_method, resample_monthly, knn_imp_cols=None, k=None, weights=None, c=-1):\n",
        "        # Resample to fill in missing month gaps, and interpolate values at site-level\n",
        "        monthly_df = None\n",
        "\n",
        "        # Subset month_df to only sites with hourly records available\n",
        "        available_sites = [x[-10:-4] for x in os.listdir(self.data_dir)]\n",
        "        init_sites = len(self.month_df['SITE_ID'].unique())\n",
        "        self.month_df = self.month_df.loc[self.month_df['SITE_ID'].isin(available_sites)]\n",
        "        print(f\"# sites dropped bc not available in data_dir: {init_sites - len(self.month_df['SITE_ID'].unique())}\")\n",
        "        \n",
        "        # Loop through hourly site data to determine which months are present\n",
        "        for i, s in tqdm(enumerate(self.month_df['SITE_ID'].unique())):\n",
        "            # Get monthly data for site\n",
        "            site_month = self.month_df[self.month_df['SITE_ID'] == s].copy()\n",
        "            site_month.reset_index(drop = True, inplace=True)\n",
        "            site_month['gap_flag_month'] = int(0)\n",
        "\n",
        "            if resample_monthly:\n",
        "                # Get start and end range for given site <------------------------- CREATE DF NEXT TIME TO SAVE TIME (30 seconds per run)\n",
        "                site_file = f'data_full_half_hourly_raw_v0_1_{s}.csv'\n",
        "                site_hr_df = pd.read_csv(f\"{self.data_dir}/{site_file}\", usecols=['SITE_ID', 'datetime', 'year', 'month'])\n",
        "                dates = [d for d in pd.date_range(start=site_hr_df['datetime'].min(), end=site_hr_df['datetime'].max(), freq='M')]\n",
        "\n",
        "                # Create range of monthly dates from beginning of minimum month to beginning of next month after maximum month\n",
        "                site_hr_df['datetime'] = pd.to_datetime(site_hr_df['datetime'])\n",
        "                min_datetime = site_hr_df['datetime'].min()\n",
        "                max_datetime = site_hr_df['datetime'].max()\n",
        "                dates = pd.date_range(start=min_datetime.replace(day=1), end=max_datetime.replace(day=1) + pd.offsets.MonthBegin(1), freq='MS')\n",
        "\n",
        "                # Create dataframe\n",
        "                site_hr_df = pd.DataFrame({'datetime': dates})\n",
        "                site_hr_df['year'] = site_hr_df['datetime'].dt.year\n",
        "                site_hr_df['month'] = site_hr_df['datetime'].dt.month\n",
        "                site_hr_df['SITE_ID'] = s\n",
        "\n",
        "                # Resample montlhly data to get the months required in hourly data\n",
        "                pft = site_month['MODIS_PFT'][0] # retain PFT to fill new rows\n",
        "                igbp = site_month['MODIS_IGBP'][0] # retain PFT to fill new rows\n",
        "                site_month = pd.merge(site_hr_df, site_month, how='left', on =['SITE_ID', 'year', 'month'])\n",
        "                site_month['MODIS_PFT'] = pft\n",
        "                site_month['MODIS_IGBP'] = igbp\n",
        "                site_month['SITE_ID'] = s\n",
        "                site_month['gap_flag_month'].fillna(int(1), inplace=True)\n",
        "\n",
        "            # Fill in known values for new/resampled month-level rows\n",
        "            site_month['datetime'] = site_month.apply(self.to_datetime, axis=1)\n",
        "            site_month.set_index('datetime', inplace=True)\n",
        "            site_month.drop(columns='TIMESTAMP', inplace=True)\n",
        "            site_month.drop(columns='date', inplace=True)\n",
        "\n",
        "            # If any new months added by resample, interpolate gap values at site-level\n",
        "            if site_month.isna().sum().sum() != 0: \n",
        "                if impute_method == 'interpolate':\n",
        "                    site_month.interpolate(method='linear', limit_direction='both', inplace=True)\n",
        "\n",
        "                elif impute_method == 'knn':\n",
        "                    nan_cols = site_month.columns[site_month.isna().all()].tolist()\n",
        "                    site_month = self.knn_impute(site_month, knn_imp_cols, k, weights)\n",
        "                    if len(nan_cols) > 0:\n",
        "                        print(f'{s} has column(s) with only NAN: {nan_cols}')\n",
        "                        for c in nan_cols:\n",
        "                            site_month[c] = np.nan\n",
        "                            \n",
        "                elif impute_method == 'constant':\n",
        "                    monthly_df = self.month_df.fillna(c)\n",
        "\n",
        "            # Concat site_month to monthly_df\n",
        "            if type(monthly_df) == type(None):\n",
        "                monthly_df = site_month\n",
        "            else:\n",
        "                monthly_df = pd.concat([monthly_df, site_month])\n",
        "\n",
        "        # if any site had 100% missing for a feature, impute these using global data\n",
        "        if monthly_df.isna().sum().sum() != 0:\n",
        "            print(\"Imputing values where site has 100 percent of feature missing\")\n",
        "            print(f\"# of NA features before global impute: {monthly_df.isna().sum().sum()}\")\n",
        "            if impute_method == 'interpolate':\n",
        "                monthly_df.interpolate(method='linear', limit_direction='both', inplace=True)\n",
        "\n",
        "            elif impute_method == 'knn':\n",
        "                monthly_df = self.knn_impute(monthly_df, knn_imp_cols, k, weights)\n",
        "\n",
        "            elif impute_method == 'constant':\n",
        "                monthly_df = self.monthly_df.fillna(c)\n",
        "\n",
        "            print(f\"# of NA features after global impute: {monthly_df.isna().sum().sum()}\")\n",
        "\n",
        "        return monthly_df\n",
        "\n",
        "\n",
        "    def run(self, impute=False, impute_method=None, resample_monthly=False, knn_imp_cols=None, k=None, weights=None, c=-1):\n",
        "        # Hanlde missing values\n",
        "        if impute:\n",
        "            print(f\"Impute method: {impute_method}\")\n",
        "            print(f\"Resampling and gap filling missing months: {resample_monthly}\")\n",
        "            monthly_df = self.impute(impute_method, resample_monthly, knn_imp_cols, k, weights, c)\n",
        "        else:\n",
        "            print(\"Not gap filling or filling NAs, leave be\")\n",
        "            available_sites = [x[-10:-4] for x in os.listdir(self.data_dir)]\n",
        "            self.month_df = self.month_df.loc[self.month_df['SITE_ID'].isin(available_sites)]\n",
        "            monthly_df = self.month_df.copy()\n",
        "            \n",
        "        # Confirm No NAS\n",
        "        if monthly_df.isna().sum().sum() == 0:\n",
        "            print(\"Confirmed: No NA values remain\")\n",
        "        elif type(impute_method) != type(None):\n",
        "            print(\"ISSUE: SOME NA VALUES REMAIN - INVESTIGATE\")\n",
        "            monthly_df.isna().sum()\n",
        "\n",
        "        return monthly_df\n",
        "        \n",
        "\n",
        "class PrepareAllSitesHourly:\n",
        "    def __init__(self, site_metadata_filename, monthly_data_filename, train_sites, val_sites, test_sites, \n",
        "                hourly_features, metadata_features, target_variable_qc, target_variable, data_dir):\n",
        "        self.site_metadata_filename = site_metadata_filename\n",
        "        self.monthly_data_filename = monthly_data_filename\n",
        "        self.train_sites = train_sites\n",
        "        self.val_sites = val_sites\n",
        "        self.test_sites = test_sites\n",
        "        if train_sites is not None and val_sites is not None and test_sites is not None:\n",
        "          self.all_sites = train_sites + val_sites + test_sites\n",
        "        else:\n",
        "          self.all_sites = None\n",
        "        self.hourly_features = hourly_features\n",
        "        self.metadata_features = metadata_features\n",
        "        self.target_variable_qc = target_variable_qc\n",
        "        self.target_variable = target_variable\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "    def add_time_index(self, df, time_col, duration, site_id):\n",
        "        df['gap_flag_hour'] = int(0)\n",
        "        df.sort_values(time_col, inplace=True)\n",
        "        df.set_index(time_col, inplace=True)\n",
        "        df = df.resample(duration).first()\n",
        "        df = df.reset_index()\n",
        "        df['gap_flag_hour'].fillna(int(1), inplace=True)\n",
        "\n",
        "        # Fix time records that are NA for new rows\n",
        "        df['year'] = df['datetime'].dt.year.astype(int)\n",
        "        df['month'] = df['datetime'].dt.month.astype(int)\n",
        "        df['day'] = df['datetime'].dt.day.astype(int)\n",
        "        df['hour'] = df['datetime'].dt.hour.astype(int)\n",
        "        df['date'] = df['datetime'].dt.date\n",
        "        df['site_id'] = site_id\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    def knn_impute(self, df, imp_cols, k, weights, n_fit=20000):\n",
        "        # Init Imputer\n",
        "        imputer = KNNImputer(n_neighbors=k, weights=weights)\n",
        "\n",
        "        # Get subset of rows to speed up impute time (instead of fitting on every single record)\n",
        "        df_subcols = df[imp_cols].copy()\n",
        "        na_mask = df_subcols.isna().any(axis=1)\n",
        "        na_rows = df_subcols[na_mask]\n",
        "        nan_cols = []\n",
        "        imputed_group_columns = df_subcols.columns\n",
        "\n",
        "        # If there are at least 10k rows that don't have NA, use them to fit imputer (saves time)\n",
        "        if (len(df) - len(na_rows)) > 10000:\n",
        "            not_na_rows = df_subcols.dropna()\n",
        "            not_na_rows = not_na_rows[na_rows.columns]\n",
        "            not_na_rows = not_na_rows.sample(n=np.min([n_fit, len(not_na_rows)]))\n",
        "            imputer.fit(not_na_rows)\n",
        "            imputed_group = imputer.transform(na_rows)\n",
        "        else:\n",
        "            nan_cols = na_rows.columns[na_rows.isna().all()].tolist()\n",
        "            na_rows = na_rows.dropna(axis=1, how='all')\n",
        "            imputed_group_columns = na_rows.columns\n",
        "            imputed_group = imputer.fit_transform(na_rows)\n",
        "\n",
        "        imputed_group = pd.DataFrame(imputed_group, columns=imputed_group_columns, index=na_rows.index)\n",
        "        if len(nan_cols) > 0:\n",
        "            print(f'  Column(s) with only NAN: {nan_cols}')\n",
        "            for c in nan_cols:\n",
        "                imputed_group[c] = np.nan\n",
        "\n",
        "        # Reinsert NA rows\n",
        "        df_subcols.loc[na_mask] = imputed_group\n",
        "\n",
        "        # Fill NA in initial site/group df\n",
        "        df.fillna(df_subcols, inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    \n",
        "    def check_imputation(self, df_init,  df_imputed):\n",
        "        # Drop NA rows from both (using indices) confirm they are same df now\n",
        "        drop_na = df_init.dropna(how='any')\n",
        "        drop_imp = df_imputed.loc[drop_na.index, ]\n",
        "        drop_na.reset_index(inplace=True, drop=True)\n",
        "        drop_imp.reset_index(inplace=True, drop=True)\n",
        "        if not drop_na.equals(drop_imp):\n",
        "            print(\"IMPUTATION ERROR: Non-NA values were affected in imputation\")\n",
        "\n",
        "        # Check that 50 rows that initial had NA are the same in non-NA cols\n",
        "        na_inds = df_init.loc[df_init.isna().any(axis=1), ].index\n",
        "        errors = 0\n",
        "        for ind in na_inds[:50]:\n",
        "            check_ind = pd.concat([df_init.iloc[ind], df_imputed.iloc[ind]], axis=1).dropna()\n",
        "            check_ind.columns = ['initial', 'post_imp']\n",
        "            if not check_ind['initial'].equals(check_ind['post_imp']):\n",
        "                errors += 1\n",
        "                print(ind)\n",
        "\n",
        "        if errors != 0:\n",
        "            print(\"IMPUTATION ERROR: Non-NA values in rows with NA were affected by imputation\")\n",
        "\n",
        "        # DF length is the same \n",
        "        if len(df_init) != len(df_imputed):\n",
        "            print(\"IMPUTATION ERROR: Post imputation df has different row count than initial df\")\n",
        "\n",
        "\n",
        "    def filter_date_range(self, df, start_date, end_date, time_col, missing_thresh=0.2):\n",
        "        df.set_index(time_col, inplace=True)\n",
        "        filtered_df = df.loc[start_date:end_date].copy()\n",
        "\n",
        "        # Remove sites without at least one year of records\n",
        "        if len(filtered_df) < 365*24:\n",
        "            return None\n",
        "        else:\n",
        "            # Remove sites that have > 20% gaps in sequence\n",
        "            first_date = filtered_df.index.min()\n",
        "            last_date = filtered_df.index.max()\n",
        "            total_expected_count = len(pd.date_range(start=first_date, end=last_date, freq='H'))\n",
        "            missing_percentage = (total_expected_count - len(filtered_df)) / total_expected_count\n",
        "\n",
        "            if missing_percentage > missing_thresh:\n",
        "                return None\n",
        "            else:\n",
        "                filtered_df.reset_index(inplace=True)\n",
        "                return filtered_df\n",
        "            \n",
        "\n",
        "    def prep_metadata(self):\n",
        "        site_metadata_df = pd.read_csv(self.site_metadata_filename, usecols = self.metadata_features)\n",
        "        \n",
        "        if self.all_sites is not None:\n",
        "          site_metadata_df = site_metadata_df.loc[site_metadata_df['site_id'].isin(self.all_sites), ]\n",
        "        \n",
        "        site_metadata_df = site_metadata_df.loc[site_metadata_df['monthly_data_available']=='Yes', ] # <---- not including sites that have zero monthly data (ask team)\n",
        "        site_metadata_df.reset_index(inplace=True, drop=True)\n",
        "        return site_metadata_df\n",
        "\n",
        "\n",
        "    def merge_site_metadata(self, data_df, site_metadata_df):\n",
        "        site_metadata_df = site_metadata_df.drop(['filename', 'monthly_data_available'], axis=1)\n",
        "        data_df = data_df.merge(site_metadata_df, how='left', left_on='site_id', right_on='site_id')\n",
        "        print(f\"Data size after after merged with site metadata: {data_df.shape}\")\n",
        "\n",
        "        if data_df.isna().sum().sum() != 0:\n",
        "            print(f\"Missing values after metadata merge {data_df.isna().sum().sum()} \")\n",
        "\n",
        "        return data_df\n",
        "\n",
        "\n",
        "    def merge_monthly_data(self, data_df):\n",
        "        # Prep monthly\n",
        "        monthly_df = pd.read_csv(self.monthly_data_filename)\n",
        "        monthly_df.reset_index(inplace=True, drop=True)\n",
        "        monthly_df[['year','month', 'MODIS_LC']] = monthly_df[['year','month', 'MODIS_LC']].astype('int')\n",
        "\n",
        "        if monthly_df.isna().sum().sum() != 0:\n",
        "            print(f\"{monthly_df.isna().sum().sum()} missing values in monthly data\")\n",
        "\n",
        "        # Merge\n",
        "        data_df = data_df.merge(monthly_df, how='left',\n",
        "                        left_on =['site_id', 'year', 'month'],\n",
        "                        right_on=['SITE_ID', 'year', 'month'])\n",
        "        data_df.drop('SITE_ID', axis=1, inplace=True)\n",
        "        print(f\"Data size after after merged with monthly data: {data_df.shape}\")\n",
        "\n",
        "        if data_df.isna().sum().sum() != 0:\n",
        "            print(f\"{data_df.isna().sum().sum()} missing values introduced after monthly merge\")\n",
        "\n",
        "        return data_df\n",
        "    \n",
        "\n",
        "    def site_data_cleanup(self, site_metadata_df, imp_cols, resample, impute, impute_method,\n",
        "                         impute_global, k, weights, n_fit, time_col, duration, start_date, end_date, missing_thresh=0.2, c=None):\n",
        "        data_df = None\n",
        "        num_records = 0\n",
        "        available_site_count = 0\n",
        "        retained_site_count = 0\n",
        "        qc_flags_features = [s for s in self.hourly_features if \"_QC\" in s]\n",
        "\n",
        "        # Global time index base\n",
        "        global_time_index_base = datetime(1970, 1, 1, 0, 0, 0)\n",
        "\n",
        "        ## SITE-LEVEL CLEANING -> LOOP & CONCATENATE\n",
        "        for i, r in tqdm(site_metadata_df[['site_id','filename']].iterrows()):\n",
        "          if not r.filename or type(r.filename) != type(\"\"):\n",
        "            print(f'SKIP: {r.site_id} is missing hourly data.')\n",
        "            continue\n",
        "\n",
        "          available_site_count += 1  \n",
        "\n",
        "          # Prepare hourly site df\n",
        "          local_filename = self.data_dir + os.sep + r.filename\n",
        "          site_df = pd.read_csv(local_filename, usecols = [self.target_variable] + self.hourly_features)\n",
        "\n",
        "          # Format columns\n",
        "          site_df['datetime'] = pd.to_datetime(site_df['datetime'])\n",
        "          site_df['date'] = pd.to_datetime(site_df['date'])\n",
        "          site_df['minute'] = site_df['datetime'].dt.minute\n",
        "          if len(qc_flags_features) != 0:\n",
        "              site_df[qc_flags_features] = site_df[qc_flags_features].astype('int')\n",
        "          site_df['site_id'] = r.site_id\n",
        "\n",
        "          # Move from HH to H level\n",
        "          site_df = site_df.loc[site_df['datetime'].dt.minute == 0, ].copy()\n",
        "          site_df.drop('minute', axis=1, inplace=True)\n",
        "            \n",
        "          # Filter site date-range and drop sites without > 1 year and <20% gaps after trim\n",
        "          if start_date is not None and end_date is not None:\n",
        "            site_df = self.filter_date_range(site_df, start_date, end_date, time_col, missing_thresh)\n",
        "          \n",
        "          if site_df is None:\n",
        "              print(f'SKIP: {r.site_id} does not have sufficient data in desired time period')\n",
        "              continue\n",
        "          else:\n",
        "              retained_site_count += 1\n",
        "              num_records += len(site_df)\n",
        "\n",
        "          # Resample to add rows for missing timesteps, assign timestep_idx and \"gap_flag\"\n",
        "          if resample:\n",
        "              site_df = self.add_time_index(site_df, time_col, duration, site_id=r.site_id)\n",
        "          else:\n",
        "              site_df['gap_flag_hour'] = 0\n",
        "              site_df.sort_values(time_col, inplace=True)\n",
        "              site_df = site_df.reset_index()\n",
        "\n",
        "          # Save site_df pre-imputation to check post-imputation (once per run, random site each time)\n",
        "          if self.all_sites is not None:\n",
        "            random_check = random.randint(0, len(self.all_sites))\n",
        "          else:\n",
        "            random_check = random.randint(0, site_metadata_df['site_id'].unique().shape[0])\n",
        "          \n",
        "          if i == random_check:   \n",
        "              site_df_pre_imp = site_df.copy()\n",
        "          \n",
        "          # Impute missing values at site-level, otherwise fillna w/ -1 at very end\n",
        "          if (impute) & (site_df.isna().sum().sum() != 0):\n",
        "              if impute_method=='ffill': # select most recent record\n",
        "                  site_df.sort_values(time_col, ascending=True, inplace=True)\n",
        "                  site_df.fillna(method=\"ffill\", inplace=True)\n",
        "              elif impute_method=='knn': # use KNNImputer\n",
        "                  nan_cols = site_df.columns[site_df.isna().all()].tolist()\n",
        "                  site_df = self.knn_impute(site_df, imp_cols, k, weights, n_fit)\n",
        "                  if len(nan_cols) > 0:\n",
        "                      print(f'{r.site_id} has column(s) with only NAN: {nan_cols}')\n",
        "                      for c in nan_cols:\n",
        "                          site_df[c] = pd.NA\n",
        "              elif impute_method=='constant':\n",
        "                  site_df[imp_cols] = site_df[imp_cols].fillna(c)\n",
        "\n",
        "          if i == random_check:\n",
        "              self.check_imputation(site_df_pre_imp, site_df)\n",
        "          \n",
        "          # Create local timestep_idx\n",
        "          site_df.sort_values(time_col, ascending=True, inplace=True)\n",
        "          site_df['timestep_idx_local'] = range(len(site_df))\n",
        "\n",
        "          # Create global timestamp inds\n",
        "          site_df['timestep_idx_global'] = (site_df[time_col]- global_time_index_base).\\\n",
        "                                            apply(lambda x: int(x.total_seconds() / 3600))\n",
        "\n",
        "          # Concatenate site_dfs together into global data_df\n",
        "          print(f'{i+1}. {r.site_id}: {site_df.shape}')\n",
        "          if type(data_df) == type(None):\n",
        "              data_df = site_df\n",
        "          else:\n",
        "              data_df = pd.concat([data_df, site_df])\n",
        "        # End all-site loop\n",
        "\n",
        "        ## Global Data-DF Cleanup\n",
        "        # Order cols + sort\n",
        "        data_df.sort_values(['site_id', time_col], ascending=True, inplace=True)\n",
        "\n",
        "        # Print stats\n",
        "        print(f\"Initial records: {num_records}, Final records after resampling + gap-filling: {len(data_df)}\")\n",
        "        print(f\"Total retained sites: {retained_site_count}/{available_site_count} = {retained_site_count/available_site_count:.2f}\")\n",
        "\n",
        "        # Handle remaining missing data (if 100% of feature missing for one site)\n",
        "        print(f\"Missing values after site-level imputation: {data_df.isna().sum().sum()}\")\n",
        "        if (impute_global) & (data_df.isna().sum().sum() != 0):\n",
        "            if impute_method=='ffill': # select most recent record\n",
        "                data_df.sort_values(time_col, ascending=True, inplace=True)\n",
        "                data_df.fillna(method=\"ffill\", inplace=True)\n",
        "                data_df.fillna(method=\"bfill\", inplace=True) # in rare case of missing first record\n",
        "                \n",
        "            elif impute_method=='knn': # use KNNImputer\n",
        "                data_df = self.knn_impute(data_df, imp_cols, k, weights, n_fit)\n",
        "\n",
        "            elif impute_method=='constant':\n",
        "                data_df[imp_cols] = data_df[imp_cols].fillna(c)\n",
        "        else:\n",
        "            print(\"Not imputing missing values at global level\")\n",
        "        print(f\"Missing values after global-level imputation: {data_df.isna().sum().sum()}\")\n",
        "\n",
        "        return data_df\n",
        "    \n",
        "\n",
        "    def all_sites_all_sources(self, imp_cols, resample, impute, impute_method, impute_global, k,\n",
        "                            weights, n_fit, time_col, duration, start_date, end_date, missing_thresh, c):\n",
        "        \n",
        "        site_metadata_df = self.prep_metadata()\n",
        "        \n",
        "        if self.all_sites is not None:\n",
        "          sites_missing_monthly = [s for s in self.all_sites if s not in site_metadata_df['site_id'].values]\n",
        "          if len(sites_missing_monthly):\n",
        "            print(f'Sites with missing monthly data: {sites_missing_monthly}')\n",
        "\n",
        "        data_df = self.site_data_cleanup(site_metadata_df, imp_cols, resample, impute, impute_method, \n",
        "                                        impute_global, k, weights, n_fit, time_col, duration, start_date, end_date, missing_thresh, c)\n",
        "\n",
        "        # Merge with site metadata and monthly data\n",
        "        data_df = self.merge_site_metadata(data_df, site_metadata_df)\n",
        "        data_df = self.merge_monthly_data(data_df)\n",
        "\n",
        "        # Reorder columns\n",
        "        features = data_df.columns.to_list()\n",
        "        remove_cols = [self.target_variable, 'site_id', 'timestep_idx_local', 'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day', 'hour', 'gap_flag_hour', 'gap_flag_month']\n",
        "        features = list(filter(lambda x: x not in remove_cols, features))\n",
        "        data_df = data_df[([self.target_variable, 'site_id', 'timestep_idx_local', 'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day', 'hour'] + features + ['gap_flag_hour', 'gap_flag_month'])]\n",
        "\n",
        "        return data_df\n",
        "\n",
        "if (\"UseSpark\" in os.environ) or (os.environ.get('UseSpark') == \"true\"):\n",
        "    class PySparkMLDataTransformer:\n",
        "      def __init__(self, spark_session, train_sites, test_sites, \\\n",
        "                  data_file_path = None, data_df = None, ):\n",
        "        \n",
        "        self.spark_session = spark_session\n",
        "        self.data_df = data_df \n",
        "        self.train_df = None \n",
        "        self.test_df = None \n",
        "        self.train_sites = train_sites\n",
        "        self.test_sites = test_sites\n",
        "        self.scaler = None\n",
        "\n",
        "        if type(data_df) == type(None):\n",
        "          if os.path.exists(data_file_path):\n",
        "            self.data_df = self.spark_session.read.parquet(data_file_path)\n",
        "            if '__index_level_0__' in self.data_df.columns:\n",
        "              self.data_df = self.data_df.drop(*['__index_level_0__'])\n",
        "          else:\n",
        "            print(f\"ERROR: {data_file_path} not found.\")\n",
        "        \n",
        "        if 'date' in self.data_df.columns:\n",
        "          self.data_df = self.data_df.drop(*['date'])\n",
        "        print(f\"Data loaded: {self.data_df.count()} rows x {len(self.data_df.columns)} columns.\")\n",
        "      \n",
        "      def data_transform(self, categorical_cols, timestamp_cols, target_col):\n",
        "        self.categorical_cols = categorical_cols\n",
        "        self.timestamp_cols =  timestamp_cols\n",
        "        self.target_col =  target_col\n",
        "\n",
        "        # One-Hot Encoding\n",
        "        string_indexer = StringIndexer(inputCols=categorical_cols, outputCols=[x + \"_Index\" for x in categorical_cols]) \n",
        "        self.data_df = string_indexer.fit(self.data_df).transform(self.data_df)\n",
        "        one_hot_encoder  = OneHotEncoder(inputCols=string_indexer.getOutputCols(), outputCols=[x + \"_OHE\" for x in categorical_cols])\n",
        "        self.data_df = one_hot_encoder.fit(self.data_df).transform(self.data_df)\n",
        "        self.data_df = self.data_df.drop(*string_indexer.getOutputCols())\n",
        "\n",
        "        print(f\"Data size after encoding: {self.data_df.count()} rows x {len(self.data_df.columns)} columns.\")\n",
        "        self.data_df.show(5, False)\n",
        "\n",
        "        # Get Features\n",
        "        features = self.data_df.columns\n",
        "        features.remove(target_col)\n",
        "        features.remove('site_id')\n",
        "        for f in categorical_cols + timestamp_cols:\n",
        "          features.remove(f)\n",
        "        print(f\"Features({len(features)}): {features}\")\n",
        "\n",
        "        # Assemable Data\n",
        "        assembler = VectorAssembler(inputCols=features, outputCol=\"vectorized_features\")\n",
        "        self.data_df = assembler.transform(self.data_df)\n",
        "        print(f\"Data size after assembling: {self.data_df.count()} rows x {len(self.data_df.columns)} columns.\")\n",
        "        self.data_df.show(5, False)\n",
        "\n",
        "        # Split into train and test sets\n",
        "        train_df = self.data_df.filter(col('site_id').isin(self.train_sites))\n",
        "        test_df = self.data_df.filter(col('site_id').isin(self.test_sites))\n",
        "        print(f\"Train data size: {train_df.count()} rows x {len(train_df.columns)} columns.\")\n",
        "        print(f\"Test data size: {test_df.count()} rows x {len(test_df.columns)} columns.\")\n",
        "\n",
        "        print(\"Train data peak:\")\n",
        "        train_df.show(5, False)\n",
        "        print(\"Test data peak:\")\n",
        "        test_df.show(5, False)\n",
        "\n",
        "        # Normalize data\n",
        "        self.scaler = MinMaxScaler(inputCol='vectorized_features', outputCol='features').fit(train_df)\n",
        "        train_df = self.scaler.transform(train_df)\n",
        "        test_df = self.scaler.transform(test_df)\n",
        "\n",
        "        train_df = train_df.drop(*['vectorized_features'])\n",
        "        test_df = test_df.drop(*['vectorized_features'])\n",
        "        print(f\"Train data size: {train_df.count()} rows x {len(train_df.columns)} columns.\")\n",
        "        print(f\"Test data size: {test_df.count()} rows x {len(test_df.columns)} columns.\")\n",
        "\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "        return (train_df, test_df)\n",
        "      \n",
        "      def upload_train_test_to_azure(self, az_cred_file, container, train_blob_name, val_blob_name, test_blob_name):\n",
        "        # Initialize AzStorageClient \n",
        "        azStorageClient = AzStorageClient(az_cred_file)\n",
        "        sessionkeys = azStorageClient.getSparkSessionKeys()\n",
        "        self.spark_session.conf.set(sessionkeys[0],sessionkeys[1])\n",
        "\n",
        "        # Upload train dataset\n",
        "        train_blob_path = f\"wasbs://{container}@{sessionkeys[2]}.blob.core.windows.net/{train_blob_name}\"\n",
        "        print(f\"Uploading train dataset to {train_blob_path}...\")\n",
        "        self.train_df.write.format(\"parquet\").mode(\"overwrite\").save(train_blob_path)\n",
        "\n",
        "        # Upload val dataset\n",
        "        val_blob_name = f\"wasbs://{container}@{sessionkeys[2]}.blob.core.windows.net/{val_blob_name}\"\n",
        "        print(f\"Uploading train dataset to {val_blob_name}...\")\n",
        "        self.val_df.write.format(\"parquet\").mode(\"overwrite\").save(val_blob_name)\n",
        "\n",
        "        # Upload test dataset\n",
        "        test_blob_path = f\"wasbs://{container}@{sessionkeys[2]}.blob.core.windows.net/{test_blob_name}\"\n",
        "        print(f\"Uploading test dataset to {test_blob_path}...\")\n",
        "        self.test_df.write.format(\"parquet\").mode(\"overwrite\").save(test_blob_path)\n",
        "\n",
        "class TFTDataTransformer:\n",
        "  def __init__(self, train_sites, val_sites, test_sites, \\\n",
        "              data_file_path = None, data_df = None):\n",
        "    \n",
        "    self.data_df = data_df \n",
        "    self.train_sites = train_sites\n",
        "    self.val_sites = val_sites\n",
        "    self.test_sites = test_sites\n",
        "    self.scaler = None\n",
        "\n",
        "    # Load data df\n",
        "    if type(data_df) == type(None):\n",
        "      if os.path.exists(data_file_path):\n",
        "        self.data_df = pd.read_parquet(data_file_path, engine='pyarrow')\n",
        "      else:\n",
        "        print(f\"ERROR: {data_file_path} not found.\")\n",
        "    \n",
        "    if 'date' in self.data_df.columns:\n",
        "      self.data_df = self.data_df.drop(['date'], axis = 1)\n",
        "    print(f\"Data size: {self.data_df.shape}.\")\n",
        "\n",
        "  def get_test_train_raw(self):\n",
        "    train_df = self.data_df[self.data_df['site_id'].isin(self.train_sites)]\n",
        "    test_df  = self.data_df[self.data_df['site_id'].isin(self.test_sites)]\n",
        "    print(f\"Train data size: {train_df.shape}.\")\n",
        "    print(f\"Test data size: {test_df.shape}.\")\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    return (train_df, test_df)\n",
        "\n",
        "  def data_transform(self, categorical_cols, realNum_cols, cat_encode_type='label'):\n",
        "    data_df = self.data_df\n",
        "    print(f\"Data size: {self.data_df.shape}.\")\n",
        "\n",
        "    # Encode the categorical columns\n",
        "    if cat_encode_type == 'label':\n",
        "      data_df[categorical_cols] = data_df[categorical_cols].apply(LabelEncoder().fit_transform)\n",
        "    elif cat_encode_type == 'dummy':\n",
        "      dummy_df = pd.get_dummies(data_df[categorical_cols])\n",
        "      data_df = data_df.drop(columns=categorical_cols)\n",
        "      data_df = pd.concat([data_df, dummy_df], axis=1)\n",
        "    print(f\"Data size after encoding: {data_df.shape}\")\n",
        "      \n",
        "    # Split into train, val, and test sets\n",
        "    train_df = data_df.loc[data_df['site_id'].isin(self.train_sites), ].copy()\n",
        "    val_df = data_df.loc[data_df['site_id'].isin(self.val_sites), ].copy()\n",
        "    test_df  = data_df.loc[data_df['site_id'].isin(self.test_sites), ].copy()\n",
        "    print(f\"Number of sites in df: {len(data_df['site_id'].unique())}\")\n",
        "    print(f\"Train Sites: {train_df['site_id'].unique()}\")\n",
        "    print(f\"Val Sites: {val_df['site_id'].unique()}\")\n",
        "    print(f\"Test Sites: {test_df['site_id'].unique()}\")\n",
        "\n",
        "    # Normalize data\n",
        "    print(f\"Normalizing real features ({len(realNum_cols)})\")\n",
        "    scaler = StandardScaler().fit(train_df[realNum_cols])\n",
        "    train_df.loc[:,realNum_cols] = scaler.transform(train_df[realNum_cols])\n",
        "    val_df.loc[:,realNum_cols] = scaler.transform(val_df[realNum_cols])\n",
        "    test_df.loc[:,realNum_cols] = scaler.transform(test_df[realNum_cols])\n",
        "\n",
        "    # Save scaler object <--- later\n",
        "    \n",
        "    print(f\"Train data size: {train_df.shape}.\")\n",
        "    print(f\"Val data size: {val_df.shape}.\")\n",
        "    print(f\"Test data size: {test_df.shape}.\")  \n",
        "    train_df.reset_index(inplace=True, drop=True)\n",
        "    val_df.reset_index(inplace=True, drop=True)\n",
        "    test_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "    return (train_df, val_df, test_df)\n",
        "\n",
        "  def upload_train_test_to_azure(self, az_cred_file, container, train_blob_name, test_blob_name):\n",
        "    # Initialize AzStorageClient \n",
        "    azStorageClient = AzStorageClient(az_cred_file)\n",
        "\n",
        "    # Upload train dataset\n",
        "    train_file = BytesIO()\n",
        "    self.train_df.to_parquet(train_file, engine='pyarrow')\n",
        "    train_file.seek(0)\n",
        "    print(f\"Uploading train dataset to {train_blob_name}...\")\n",
        "    azStorageClient.uploadBlob(container, train_blob_name, train_file, overwrite=True)\n",
        "\n",
        "    # Upload test dataset\n",
        "    test_file = BytesIO()\n",
        "    self.test_df.to_parquet(test_file, engine='pyarrow')\n",
        "    test_file.seek(0)\n",
        "    print(f\"Uploading test dataset to {test_blob_name}...\")\n",
        "    azStorageClient.uploadBlob(container, test_blob_name, test_file, overwrite=True)\n"
      ],
      "metadata": {
        "id": "pMYCv6JxbMz-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW\n",
        "# MY_HOME_ABS_PATH = \"/root/co2-flux-hourly-gpp-modeling\"\n",
        "\n",
        "# Inmport Libraries\n",
        "import os\n",
        "os.chdir(MY_HOME_ABS_PATH)\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import copy\n",
        "import logging\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Any, Dict, List, Tuple, Union\n",
        "import tensorflow as tf\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Callback\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import statsmodels.api as sm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
        "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
        "from pytorch_forecasting import BaseModel, MAE\n",
        "from pytorch_forecasting.metrics.point import RMSE\n",
        "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback, TensorBoardCallback\n",
        "import optuna.logging\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from timeit import default_timer\n",
        "from datetime import datetime\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "# Load locale custome modules\n",
        "os.chdir(MY_HOME_ABS_PATH)\n",
        "sys.path.append('./.cred')\n",
        "sys.path.append('./code/src/tools')\n",
        "sys.path.append(os.path.abspath(\"./code/src/tools\"))\n",
        "  \n",
        "from AzStorageClient import AzStorageClient\n",
        "# from data_pipeline_lib import *\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "pl.seed_everything(42)\n",
        "\n",
        "root_dir =  MY_HOME_ABS_PATH\n",
        "tmp_dir =  root_dir + os.sep + 'tmp'\n",
        "data_dir = root_dir + os.sep + 'data'\n",
        "model_dir = data_dir + os.sep + 'models'\n",
        "cred_dir = root_dir + os.sep + 'cred'\n",
        "az_cred_file = cred_dir + os.sep + 'azblobcred.json'\n",
        "\n",
        "# Data loading functions\n",
        "\n",
        "def get_raw_datasets(container, blob_name):\n",
        "    local_file = tmp_dir + os.sep + blob_name\n",
        "    data_df = None\n",
        "    if not (os.path.exists(local_file)):\n",
        "        azStorageClient = AzStorageClient(az_cred_file)\n",
        "        file_stream = azStorageClient.downloadBlob2Stream(container, blob_name)\n",
        "        data_df = pd.read_parquet(file_stream, engine='pyarrow')\n",
        "        data_df.to_parquet(local_file)\n",
        "    else:\n",
        "        data_df = pd.read_parquet(local_file)\n",
        "    \n",
        "    print(f\"Data size: {data_df.shape}\")\n",
        "    \n",
        "    # Convert Dtypes\n",
        "    cat_cols = [\"year\", \"month\", \"day\", \"hour\", \"MODIS_IGBP\", \"koppen_main\", \"koppen_sub\", \n",
        "                \"gap_flag_month\", \"gap_flag_hour\"]\n",
        "    for col in cat_cols:\n",
        "        data_df[col] = data_df[col].astype(str).astype(\"category\")\n",
        "    \n",
        "    print(f\"Data Columns: {data_df.columns}\")\n",
        "    print(f\"NA count: {data_df.isna().sum().sum()}\")\n",
        "    return data_df\n",
        "\n",
        "def get_splited_datasets(data_df, val_index, test_index):\n",
        "          \n",
        "    SITE_SPLITS =[\n",
        "      ['AR-SLu', 'AU-ASM', 'AU-Cpr', 'AU-Cum', 'AU-RDF', 'CA-TP3', 'CA-TPD', 'CN-Sw2',\n",
        "        'DE-SfN', 'NL-Hor', 'US-Me6', 'US-Syv', 'US-WCr', 'US-AR2', 'US-Tw4', 'US-UMB', \n",
        "        'US-Vcp', 'CH-Cha', 'CZ-BK1', 'CZ-KrP', 'DE-Obe', 'ES-LJu', 'FI-Let', 'FR-Lam', \n",
        "        'IT-Lav', 'SE-Lnn'], \n",
        "      ['CZ-BK2', 'DE-Spw', 'FR-Pue', 'IT-CA3', 'IT-Noe', 'IT-Ro2', 'US-IB2', 'US-Myb',\n",
        "        'US-SRM', 'CA-Ca3', 'US-CRT', 'US-Fmf', 'US-KFS', 'US-Prr', 'US-UMd', 'US-Wjs',\n",
        "        'BE-Bra', 'BE-Lon', 'CH-Lae', 'CZ-RAJ', 'DE-HoH', 'DE-Kli', 'DE-RuR', 'IL-Yat', \n",
        "        'IT-Tor', 'SE-Htm'], \n",
        "      ['AR-Vir', 'AT-Neu', 'AU-DaS', 'AU-TTE', 'AU-Wom', 'CA-TP1', 'IT-CA1', 'IT-SRo',\n",
        "        'US-WPT', 'US-Wkg', 'CA-Ca2', 'CA-Cbo', 'CA-TP4', 'US-ARM', 'US-Ro1', 'US-Rws',\n",
        "        'US-SRG', 'US-Vcm', 'BE-Dor', 'BE-Vie', 'CZ-Stn', 'DE-Geb', 'ES-LM2', 'FR-Fon', \n",
        "        'SE-Ros', 'DE-Hte'],\n",
        "      ['AU-DaP', 'AU-Emr', 'AU-Gin', 'AU-How', 'AU-Rig', 'US-GLE', 'US-NR1', 'US-Twt',\n",
        "        'CA-Ca1', 'CA-Gro', 'US-AR1', 'US-Bar', 'US-Mpj', 'US-Ses', 'CH-Fru', 'CH-Oe2',\n",
        "        'DE-Hai', 'DK-Sor', 'FI-Hyy', 'FR-Aur', 'FR-Hes', 'GF-Guy', 'IT-SR2', 'SE-Deg',\n",
        "        'SE-Nor', 'NL-Loo'],\n",
        "      ['AU-Stp', 'AU-Whr', 'CA-Oas', 'DE-Lnf', 'ES-Amo', 'FI-Sod', 'IT-CA2', 'US-Ton',\n",
        "        'US-Var', 'US-Whs', 'US-Ho1', 'US-Oho', 'US-Seg', 'CH-Dav', 'CZ-Lnz', 'CZ-wet',\n",
        "        'DE-Gri', 'DE-Tha', 'ES-LM1', 'FR-Bil', 'FR-FBn', 'IT-BCi', 'IT-MBo', 'IT-Ren',\n",
        "        'RU-Fyo']\n",
        "    ]\n",
        "\n",
        "    train_sites, val_sites, test_sites = [], [], []\n",
        "    for i, subset in enumerate(SITE_SPLITS):\n",
        "        if i == val_index:\n",
        "            val_sites = SITE_SPLITS[i]\n",
        "        elif i == test_index:\n",
        "            test_sites = SITE_SPLITS[i]\n",
        "        else:\n",
        "            train_sites += SITE_SPLITS[i]\n",
        "\n",
        "    train_df = data_df.loc[data_df['site_id'].isin(train_sites), ].copy()\n",
        "    val_df   = data_df.loc[data_df['site_id'].isin(val_sites), ].copy()\n",
        "\n",
        "    if len(train_df['site_id'].unique()) != len(train_sites):\n",
        "        print(f\"Expected Train({len(train_sites)}), Actual Train({len(train_df['site_id'].unique())})\")\n",
        "        sites_missing = [s for s in train_sites if s not in train_df['site_id'].unique()]\n",
        "        print(f'  missing: {sites_missing}')\n",
        "\n",
        "    if len(val_df['site_id'].unique()) != len(val_sites):\n",
        "        print(f\"Expected Train({len(val_sites)}), Actual Train({len(val_df['site_id'].unique())})\")\n",
        "        sites_missing = [s for s in val_sites if s not in val_df['site_id'].unique()]\n",
        "        print(f'  missing: {sites_missing}')\n",
        "\n",
        "    if test_index is not None:\n",
        "        test_df = data_df.loc[data_df['site_id'].isin(test_sites), ].copy()\n",
        "        if len(test_df['site_id'].unique()) != len(test_sites):\n",
        "            print(f\"Expected Train({len(test_sites)}), Actual Train({len(test_df['site_id'].unique())})\")\n",
        "            sites_missing = [s for s in test_sites if s not in test_df['site_id'].unique()]\n",
        "            print(f'  missing: {sites_missing}')\n",
        "    else:\n",
        "        test_df = None\n",
        "\n",
        "    return (train_df, val_df, test_df)\n",
        "\n",
        "def subset_data(train_df, val_df, test_df, subset_len):\n",
        "    print(f'Subest length: {subset_len} timesteps for each sites')\n",
        "    \n",
        "    train_df = train_df.loc[train_df['timestep_idx_local'] < subset_len, ].copy()\n",
        "    print(f\"Subset num train timesteps: {len(train_df)}\")\n",
        "    val_df = val_df.loc[val_df['timestep_idx_local'] < subset_len, ].copy()\n",
        "    print(f\"Subset num val timesteps: {len(val_df)}\")\n",
        "    if test_df is not None:\n",
        "        test_df = test_df.loc[test_df['timestep_idx_local'] < subset_len, ].copy()\n",
        "        print(f\"Subset num test timesteps: {len(test_df)}\")\n",
        "\n",
        "    return (train_df, val_df, test_df)\n",
        "\n",
        "# Don't use this one\n",
        "def setup_tsdataset_mvp_mistake(train_df, val_df, test_df, min_encoder_len):\n",
        "    # create training and validation TS dataset \n",
        "    training = TimeSeriesDataSet(\n",
        "      train_df, # <------ no longer subsetting, option 1 split can use entire train site sequence\n",
        "      time_idx=\"timestep_idx_global\",\n",
        "      target=\"GPP_NT_VUT_REF\",\n",
        "      group_ids=[\"site_id\"],\n",
        "      allow_missing_timesteps=False, # <---- turned on bc some rows are removed.\n",
        "      min_encoder_length=min_encoder_len,\n",
        "      max_encoder_length=min_encoder_len,\n",
        "      min_prediction_length=1,\n",
        "      max_prediction_length=1,\n",
        "      static_categoricals=[\"MODIS_IGBP\",\"koppen_main\",\"koppen_sub\", \"gap_flag_month\", \"gap_flag_hour\"],\n",
        "      static_reals=[],\n",
        "      time_varying_known_categoricals=[\"year\", \"month\", \"day\", \"hour\"],\n",
        "      time_varying_known_reals=[\"timestep_idx_global\", \n",
        "                                'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA', 'PA_ERA',\n",
        "                                'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', \n",
        "                                'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily', 'PET', 'Ts', \n",
        "                                'ESACCI-sm', 'NDWI', 'Percent_Snow', 'Fpar', 'Lai', 'LST_Day','LST_Night'],\n",
        "      time_varying_unknown_categoricals=[], \n",
        "      time_varying_unknown_reals=[\"GPP_NT_VUT_REF\"],\n",
        "      target_normalizer=None,\n",
        "      categorical_encoders={'MODIS_IGBP': NaNLabelEncoder(add_nan=True),\n",
        "                            'koppen_main': NaNLabelEncoder(add_nan=True),\n",
        "                            'koppen_sub': NaNLabelEncoder(add_nan=True),\n",
        "                            'year': NaNLabelEncoder(add_nan=True), # temp for subset\n",
        "                            'month': NaNLabelEncoder(add_nan=True), # temp for subset\n",
        "                            'day': NaNLabelEncoder(add_nan=True), # temp for subset\n",
        "                            },\n",
        "      add_relative_time_idx=True,\n",
        "      add_target_scales=False, # <------- turned off\n",
        "      add_encoder_length=False, # <------- turned off\n",
        "    )\n",
        "\n",
        "    validation = TimeSeriesDataSet.from_dataset(training, val_df, predict=False, stop_randomization=True)\n",
        "    \n",
        "    if test_df is not None:\n",
        "        testing = TimeSeriesDataSet.from_dataset(training, test_df, predict=False, stop_randomization=True)\n",
        "    else:\n",
        "        testing = None\n",
        "\n",
        "    return (training, validation, testing)\n",
        "\n",
        "# Use this instead!!\n",
        "def setup_tsdataset(train_df, val_df, test_df, min_encoder_len):\n",
        "    # create training and validation TS dataset \n",
        "    training = TimeSeriesDataSet(\n",
        "      train_df, # <------ no longer subsetting, option 1 split can use entire train site sequence\n",
        "      time_idx=\"timestep_idx_global\",\n",
        "      target=\"GPP_NT_VUT_REF\",\n",
        "      group_ids=[\"site_id\"],\n",
        "      allow_missing_timesteps=False, # <---- turned on bc some rows are removed.\n",
        "      min_encoder_length=min_encoder_len,\n",
        "      max_encoder_length=min_encoder_len,\n",
        "      min_prediction_length=1,\n",
        "      max_prediction_length=1,\n",
        "      static_categoricals=[\"MODIS_IGBP\",\"koppen_main\",\"koppen_sub\"],\n",
        "      static_reals=[],\n",
        "      time_varying_known_categoricals=[\"year\", \"month\", \"day\", \"hour\"],\n",
        "      time_varying_known_reals=[\"timestep_idx_global\", \n",
        "                                'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA', 'PA_ERA',\n",
        "                                'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', \n",
        "                                'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily', 'PET', 'Ts', \n",
        "                                'ESACCI-sm', 'NDWI', 'Percent_Snow', 'Fpar', 'Lai', 'LST_Day','LST_Night'],\n",
        "      time_varying_unknown_categoricals=[\"gap_flag_month\", \"gap_flag_hour\"], \n",
        "      time_varying_unknown_reals=[\"GPP_NT_VUT_REF\"],\n",
        "      target_normalizer=None,\n",
        "      categorical_encoders={'MODIS_IGBP': NaNLabelEncoder(add_nan=True),\n",
        "                            'koppen_main': NaNLabelEncoder(add_nan=True),\n",
        "                            'koppen_sub': NaNLabelEncoder(add_nan=True),\n",
        "                            'year': NaNLabelEncoder(add_nan=True),\n",
        "                            },\n",
        "      add_relative_time_idx=True,\n",
        "      add_target_scales=False, # <------- turned off\n",
        "      add_encoder_length=False, # <------- turned off\n",
        "    )\n",
        "\n",
        "    validation = TimeSeriesDataSet.from_dataset(training, val_df, predict=False, stop_randomization=True)\n",
        "    \n",
        "    if test_df is not None:\n",
        "        testing = TimeSeriesDataSet.from_dataset(training, test_df, predict=False, stop_randomization=True)\n",
        "    else:\n",
        "        testing = None\n",
        "\n",
        "    return (training, validation, testing)\n",
        "\n",
        "def setup_tsdataset_nogpp(train_df, val_df, test_df, min_encoder_len):\n",
        "    # create training and validation TS dataset \n",
        "    training = TimeSeriesDataSet(\n",
        "      train_df, # <------ no longer subsetting, option 1 split can use entire train site sequence\n",
        "      time_idx=\"timestep_idx_global\",\n",
        "      target=\"GPP_NT_VUT_REF\",\n",
        "      group_ids=[\"site_id\"],\n",
        "      allow_missing_timesteps=False, # <---- turned on bc some rows are removed.\n",
        "      min_encoder_length=min_encoder_len,\n",
        "      max_encoder_length=min_encoder_len,\n",
        "      min_prediction_length=1,\n",
        "      max_prediction_length=1,\n",
        "      static_categoricals=[\"MODIS_IGBP\",\"koppen_main\",\"koppen_sub\"],\n",
        "      static_reals=[],\n",
        "      time_varying_known_categoricals=[\"year\", \"month\", \"day\", \"hour\"],\n",
        "      time_varying_known_reals=[\"timestep_idx_global\", \n",
        "                                'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA', 'PA_ERA',\n",
        "                                'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', \n",
        "                                'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily', 'PET', 'Ts', \n",
        "                                'ESACCI-sm', 'NDWI', 'Percent_Snow', 'Fpar', 'Lai', 'LST_Day','LST_Night'],\n",
        "      time_varying_unknown_categoricals=[\"gap_flag_month\", \"gap_flag_hour\"], \n",
        "      time_varying_unknown_reals=[],\n",
        "      target_normalizer=None,\n",
        "      categorical_encoders={'MODIS_IGBP': NaNLabelEncoder(add_nan=True),\n",
        "                            'koppen_main': NaNLabelEncoder(add_nan=True),\n",
        "                            'koppen_sub': NaNLabelEncoder(add_nan=True),\n",
        "                            'year': NaNLabelEncoder(add_nan=True),\n",
        "                            },\n",
        "      add_relative_time_idx=True,\n",
        "      add_target_scales=False, # <------- turned off\n",
        "      add_encoder_length=False, # <------- turned off\n",
        "    )\n",
        "\n",
        "    validation = TimeSeriesDataSet.from_dataset(training, val_df, predict=False, stop_randomization=True)\n",
        "    \n",
        "    if test_df is not None:\n",
        "        testing = TimeSeriesDataSet.from_dataset(training, test_df, predict=False, stop_randomization=True)\n",
        "    else:\n",
        "        testing = None\n",
        "\n",
        "    return (training, validation, testing)\n",
        "\n",
        "# Eval Functions\n",
        "def nash_sutcliffe(observed_values, predicted_values):\n",
        "    numerator = torch.sum((observed_values - predicted_values)**2)\n",
        "    denominator = torch.sum((observed_values - torch.mean(observed_values))**2)\n",
        "    nse_val = 1 - (numerator / denominator)\n",
        "    return nse_val\n",
        "\n",
        "def numpy_normalised_quantile_loss(y, y_pred, quantile):\n",
        "    \"\"\"Computes normalised quantile loss for numpy arrays.\n",
        "    ref: https://github.com/google-research/google-research/blob/master/tft/script_train_fixed_params.py\n",
        "    Uses the q-Risk metric as defined in the \"Training Procedure\" section of the main TFT paper.\n",
        "    Args:\n",
        "    y: Targets\n",
        "    y_pred: Predictions\n",
        "    quantile: Quantile to use for loss calculations (between 0 & 1)\n",
        "    Returns:\n",
        "    Float for normalised quantile loss.\n",
        "    \"\"\"\n",
        "    prediction_underflow = y - y_pred\n",
        "    weighted_errors = quantile * np.maximum(prediction_underflow, 0.) \\\n",
        "      + (1. - quantile) * np.maximum(-prediction_underflow, 0.)\n",
        "\n",
        "    return 2 * (weighted_errors.mean()) / (y.abs().mean())\n",
        "\n",
        "\n",
        "def get_eval_mask(dataloader):\n",
        "    return torch.logical_not(torch.cat([x['decoder_cont'][:, :, -1].reshape(-1) for x, y in iter(dataloader)]))\n",
        "\n",
        "def get_eval_metrics(y_true, y_pred, mask=None, p90_pred=None):    \n",
        "    # Apply mask if there is any\n",
        "    if mask is not None:            \n",
        "        y_true = y_true[mask.bool()]\n",
        "        y_pred = y_pred[mask.bool()]\n",
        "        if p90_pred is not None:\n",
        "            p90_pred = p90_pred[mask.bool()]\n",
        "\n",
        "    rmse = torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
        "    mae = torch.mean((y_true - y_pred).abs())\n",
        "    nse = nash_sutcliffe(y_true, y_pred)\n",
        "    r2 = r2_score(y_true.numpy(), y_pred.numpy())\n",
        "    p50_loss = numpy_normalised_quantile_loss(y_true, y_pred, 0.5)\n",
        "    evals = {\"rmse\": rmse.item(), \"mae\": mae.item(), \"nse\": nse.item(), \"r2\": r2, \"p50_loss\": p50_loss.item()}\n",
        "\n",
        "    if p90_pred is not None:\n",
        "        p90_loss = numpy_normalised_quantile_loss(y_true, p90_pred, 0.9)\n",
        "        evals[\"p90_loss\"] = p90_loss.item()\n",
        "    \n",
        "    return evals\n",
        "\n",
        "# Mask metrics for validation set\n",
        "def masked_eval_metrics(dataloader, model):\n",
        "    # Get y_true, y_pred, mask\n",
        "    y_true = torch.cat([y[0] for x, y in iter(dataloader)]).reshape(-1)\n",
        "    y_pred = model.predict(dataloader).reshape(-1)\n",
        "    mask = torch.logical_not(torch.cat([x['decoder_cont'][:, :, -1].reshape(-1) for x, y in iter(dataloader)]))\n",
        "\n",
        "    # Apply mask\n",
        "    masked_y_true = y_true[mask.bool()]\n",
        "    masked_y_pred = y_pred[mask.bool()]\n",
        "\n",
        "    # Get masked RMSE, MAE, NSE\n",
        "    masked_rmse = torch.sqrt(torch.mean((masked_y_true - masked_y_pred) ** 2))\n",
        "    masked_mae = torch.mean((masked_y_true - masked_y_pred).abs())\n",
        "    masked_nse = nash_sutcliffe(masked_y_true.reshape(-1).numpy(), masked_y_pred.reshape(-1).numpy())\n",
        "    masked_r2 = r2_score(masked_y_true.reshape(-1).numpy(), masked_y_pred.reshape(-1).numpy())\n",
        "\n",
        "    return masked_rmse, masked_mae, masked_nse, masked_r2\n",
        "\n",
        "# Custom Hyperparameter Optimizer\n",
        "# ref: https://pytorch-forecasting.readthedocs.io/en/stable/_modules/pytorch_forecasting/models/temporal_fusion_transformer/tuning.html#optimize_hyperparameters\n",
        "\n",
        "optuna_logger = logging.getLogger(\"optuna\")\n",
        "\n",
        "class MetricsCallback(Callback):\n",
        "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.metrics = []\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        self.metrics.append(trainer.callback_metrics)\n",
        "        \n",
        "def custom_optimize_hyperparameters(\n",
        "    train_dataloaders: DataLoader,\n",
        "    val_dataloaders: DataLoader,\n",
        "    model_path: str,\n",
        "    max_epochs: int = 20,\n",
        "    n_trials: int = 100,\n",
        "    timeout: float = 3600 * 8.0,  # 8 hours\n",
        "    gradient_clip_val_range: Tuple[float, float] = (0.01, 100.0),\n",
        "    hidden_size_range: Tuple[int, int] = (16, 265),\n",
        "    hidden_continuous_size_range: Tuple[int, int] = (8, 64),\n",
        "    attention_head_size_range: Tuple[int, int] = (1, 4),\n",
        "    dropout_range: Tuple[float, float] = (0.1, 0.3),\n",
        "    learning_rate_range: Tuple[float, float] = (1e-5, 1.0),\n",
        "    use_learning_rate_finder: bool = True,\n",
        "    trainer_kwargs: Dict[str, Any] = {},\n",
        "    trainer_callbacks: List[Callback] = None,\n",
        "    log_dir: str = \"lightning_logs\",\n",
        "    study: optuna.Study = None,\n",
        "    verbose: Union[int, bool] = None,\n",
        "    pruner: optuna.pruners.BasePruner = optuna.pruners.SuccessiveHalvingPruner(),\n",
        "    **kwargs,\n",
        ") -> optuna.Study:\n",
        "    \"\"\"\n",
        "    Optimize Temporal Fusion Transformer hyperparameters.\n",
        "\n",
        "    Run hyperparameter optimization. Learning rate for is determined with\n",
        "    the PyTorch Lightning learning rate finder.\n",
        "\n",
        "    Args:\n",
        "        train_dataloaders (DataLoader): dataloader for training model\n",
        "        val_dataloaders (DataLoader): dataloader for validating model\n",
        "        model_path (str): folder to which model checkpoints are saved\n",
        "        max_epochs (int, optional): Maximum number of epochs to run training. Defaults to 20.\n",
        "        n_trials (int, optional): Number of hyperparameter trials to run. Defaults to 100.\n",
        "        timeout (float, optional): Time in seconds after which training is stopped regardless of number of epochs\n",
        "            or validation metric. Defaults to 3600*8.0.\n",
        "        hidden_size_range (Tuple[int, int], optional): Minimum and maximum of ``hidden_size`` hyperparameter. Defaults\n",
        "            to (16, 265).\n",
        "        hidden_continuous_size_range (Tuple[int, int], optional):  Minimum and maximum of ``hidden_continuous_size``\n",
        "            hyperparameter. Defaults to (8, 64).\n",
        "        attention_head_size_range (Tuple[int, int], optional):  Minimum and maximum of ``attention_head_size``\n",
        "            hyperparameter. Defaults to (1, 4).\n",
        "        dropout_range (Tuple[float, float], optional):  Minimum and maximum of ``dropout`` hyperparameter. Defaults to\n",
        "            (0.1, 0.3).\n",
        "        learning_rate_range (Tuple[float, float], optional): Learning rate range. Defaults to (1e-5, 1.0).\n",
        "        use_learning_rate_finder (bool): If to use learning rate finder or optimize as part of hyperparameters.\n",
        "            Defaults to True.\n",
        "        trainer_kwargs (Dict[str, Any], optional): Additional arguments to the\n",
        "            `PyTorch Lightning trainer <https://pytorch-lightning.readthedocs.io/en/latest/trainer.html>`_ such\n",
        "            as ``limit_train_batches``. Defaults to {}.\n",
        "        trainer_callbacks ( List[Callback], optiona) Early stoppping option for trainer.\n",
        "        log_dir (str, optional): Folder into which to log results for tensorboard. Defaults to \"lightning_logs\".\n",
        "        study (optuna.Study, optional): study to resume. Will create new study by default.\n",
        "        verbose (Union[int, bool]): level of verbosity.\n",
        "            * None: no change in verbosity level (equivalent to verbose=1 by optuna-set default).\n",
        "            * 0 or False: log only warnings.\n",
        "            * 1 or True: log pruning events.\n",
        "            * 2: optuna logging level at debug level.\n",
        "            Defaults to None.\n",
        "        pruner (optuna.pruners.BasePruner, optional): The optuna pruner to use.\n",
        "            Defaults to optuna.pruners.SuccessiveHalvingPruner().\n",
        "\n",
        "        **kwargs: Additional arguments for the :py:class:`~TemporalFusionTransformer`.\n",
        "\n",
        "    Returns:\n",
        "        optuna.Study: optuna study results\n",
        "    \"\"\"\n",
        "    assert isinstance(train_dataloaders.dataset, TimeSeriesDataSet) and isinstance(\n",
        "        val_dataloaders.dataset, TimeSeriesDataSet\n",
        "    ), \"dataloaders must be built from timeseriesdataset\"\n",
        "\n",
        "    logging_level = {\n",
        "        None: optuna.logging.get_verbosity(),\n",
        "        0: optuna.logging.WARNING,\n",
        "        1: optuna.logging.INFO,\n",
        "        2: optuna.logging.DEBUG,\n",
        "    }\n",
        "    optuna_verbose = logging_level[verbose]\n",
        "    optuna.logging.set_verbosity(optuna_verbose)\n",
        "\n",
        "    loss = kwargs.get(\n",
        "        \"loss\", QuantileLoss()\n",
        "    )  # need a deepcopy of loss as it will otherwise propagate from one trial to the next\n",
        "\n",
        "    # create objective function\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        # Filenames for each trial must be made unique in order to access each checkpoint.\n",
        "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "            dirpath=os.path.join(model_path, \"trial_{}\".format(trial.number)), filename=\"{epoch}\", monitor=\"val_loss\"\n",
        "        )\n",
        "\n",
        "        # The default logger in PyTorch Lightning writes to event files to be consumed by\n",
        "        # TensorBoard. We don't use any logger here as it requires us to implement several abstract\n",
        "        # methods. Instead we setup a simple callback, that saves metrics from each validation step.\n",
        "        metrics_callback = MetricsCallback()\n",
        "        learning_rate_callback = LearningRateMonitor()\n",
        "        logger = TensorBoardLogger(log_dir, name=\"optuna\", version=trial.number)\n",
        "        gradient_clip_val = trial.suggest_loguniform(\"gradient_clip_val\", *gradient_clip_val_range)\n",
        "        default_trainer_kwargs = dict(\n",
        "            gpus=[0] if torch.cuda.is_available() else None,\n",
        "            max_epochs=max_epochs,\n",
        "            gradient_clip_val=gradient_clip_val,\n",
        "            callbacks=[\n",
        "                metrics_callback,\n",
        "                learning_rate_callback,\n",
        "                checkpoint_callback,\n",
        "                PyTorchLightningPruningCallback(trial, monitor=\"val_loss\"),\n",
        "            ],\n",
        "            logger=logger,\n",
        "            enable_progress_bar=optuna_verbose < optuna.logging.INFO,\n",
        "            enable_model_summary=[False, True][optuna_verbose < optuna.logging.INFO],\n",
        "        )\n",
        "        if trainer_callbacks is not None:\n",
        "            default_trainer_kwargs['callbacks'] += trainer_callbacks\n",
        "        default_trainer_kwargs.update(trainer_kwargs)\n",
        "        trainer = pl.Trainer(\n",
        "            **default_trainer_kwargs,\n",
        "        )\n",
        "\n",
        "        # create model\n",
        "        hidden_size = trial.suggest_int(\"hidden_size\", *hidden_size_range, log=True)\n",
        "        kwargs[\"loss\"] = copy.deepcopy(loss)\n",
        "        model = TemporalFusionTransformer.from_dataset(\n",
        "            train_dataloaders.dataset,\n",
        "            dropout=trial.suggest_uniform(\"dropout\", *dropout_range),\n",
        "            hidden_size=hidden_size,\n",
        "            hidden_continuous_size=trial.suggest_int(\n",
        "                \"hidden_continuous_size\",\n",
        "                hidden_continuous_size_range[0],\n",
        "                min(hidden_continuous_size_range[1], hidden_size),\n",
        "                log=True,\n",
        "            ),\n",
        "            attention_head_size=trial.suggest_int(\"attention_head_size\", *attention_head_size_range),\n",
        "            log_interval=-1,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # find good learning rate\n",
        "        if use_learning_rate_finder:\n",
        "            lr_trainer = pl.Trainer(\n",
        "                gradient_clip_val=gradient_clip_val,\n",
        "                gpus=[0] if torch.cuda.is_available() else None,\n",
        "                logger=False,\n",
        "                enable_progress_bar=False,\n",
        "                enable_model_summary=False,\n",
        "            )\n",
        "            res = lr_trainer.tuner.lr_find(\n",
        "                model,\n",
        "                train_dataloaders=train_dataloaders,\n",
        "                val_dataloaders=val_dataloaders,\n",
        "                early_stop_threshold=10000,\n",
        "                min_lr=learning_rate_range[0],\n",
        "                num_training=100,\n",
        "                max_lr=learning_rate_range[1],\n",
        "            )\n",
        "\n",
        "            loss_finite = np.isfinite(res.results[\"loss\"])\n",
        "            if loss_finite.sum() > 3:  # at least 3 valid values required for learning rate finder\n",
        "                lr_smoothed, loss_smoothed = sm.nonparametric.lowess(\n",
        "                    np.asarray(res.results[\"loss\"])[loss_finite],\n",
        "                    np.asarray(res.results[\"lr\"])[loss_finite],\n",
        "                    frac=1.0 / 10.0,\n",
        "                )[min(loss_finite.sum() - 3, 10) : -1].T\n",
        "                optimal_idx = np.gradient(loss_smoothed).argmin()\n",
        "                optimal_lr = lr_smoothed[optimal_idx]\n",
        "            else:\n",
        "                optimal_idx = np.asarray(res.results[\"loss\"]).argmin()\n",
        "                optimal_lr = res.results[\"lr\"][optimal_idx]\n",
        "            optuna_logger.info(f\"Using learning rate of {optimal_lr:.3g}\")\n",
        "            # add learning rate artificially\n",
        "            model.hparams.learning_rate = trial.suggest_uniform(\"learning_rate\", optimal_lr, optimal_lr)\n",
        "        else:\n",
        "            model.hparams.learning_rate = trial.suggest_loguniform(\"learning_rate\", *learning_rate_range)\n",
        "\n",
        "        # fit\n",
        "        trainer.fit(model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders)\n",
        "\n",
        "        # report result\n",
        "        return metrics_callback.metrics[-1][\"val_loss\"].item()\n",
        "\n",
        "    # setup optuna and run\n",
        "    if study is None:\n",
        "        study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
        "    study.optimize(objective, n_trials=n_trials, timeout=timeout)\n",
        "    return study"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pSCtLQgbggd",
        "outputId": "1862045f-48ad-4db4-9dd8-87394ae23f00"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1iRimJGJsAh7",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990144c4-fa39-41d8-c63c-87e6aaec7c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import copy\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
        "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
        "from pytorch_forecasting import BaseModel, MAE\n",
        "from pytorch_forecasting.metrics.point import RMSE\n",
        "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from timeit import default_timer\n",
        "from datetime import datetime\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "# Load locale custome modules\n",
        "os.chdir(MY_HOME_ABS_PATH)\n",
        "if IN_COLLAB:\n",
        "     sys.path.insert(0,os.path.abspath(\"./code/src/tools\"))\n",
        "else:\n",
        "    sys.path.append('./cred')\n",
        "    sys.path.append('./code/src/tools')\n",
        "    sys.path.append(os.path.abspath(\"./code/src/tools\"))\n",
        "\n",
        "# from CloudIO.AzStorageClient import AzStorageClient\n",
        "import AzStorageClient as AzStorageClient\n",
        "# from data_pipeline_lib import *\n",
        "# from model_pipeline_lib import *\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "mhKIB8BgGR5O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LRk1xhgDrvZ"
      },
      "source": [
        "# Load data from Azure blob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEOCHI64ysC2"
      },
      "source": [
        "## Define Local File System Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "H-AwqUa5sHYq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "root_dir =  MY_HOME_ABS_PATH\n",
        "tmp_dir =  root_dir + os.sep + 'tmp'\n",
        "raw_data_dir = tmp_dir\n",
        "data_dir = root_dir + os.sep + 'data'\n",
        "cred_dir = root_dir + os.sep + 'cred'\n",
        "az_cred_file = cred_dir + os.sep + 'azblobcred.json'\n",
        "# model_objects_dir = root_dir + os.sep + 'code/src/modeling/model_objects'\n",
        "model_objects_dir = root_dir + os.sep "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES9TafVQyVG7"
      },
      "source": [
        "# Load Train and Test dataset from Azure Storage Blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pZcOmGLRzAd9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define dataset\n",
        "container = \"all-sites-data\"\n",
        "ext = \"parquet\"\n",
        "ver = \"mvp-v2-knn\"\n",
        "model = \"rfr\"\n",
        "train_blob_name = f\"{model}-full_2010_2015-train-v-{ver}.{ext}\"\n",
        "val_blob_name = f\"{model}-full_2010_2015-val-v-{ver}.{ext}\"\n",
        "test_blob_name = f\"{model}-full_2010_2015-test-v-{ver}.{ext}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "az_cred_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xzAdZNE8di4j",
        "outputId": "4875d08f-79f7-4360-e24b-b8e57610dc17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/TFT_baseline/cred/azblobcred.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import AzStorageClient as AzStorageClient"
      ],
      "metadata": {
        "id": "tcZy6K7QdowE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient\n",
        "from collections import defaultdict\n",
        "from io import BytesIO\n",
        "import os.path\n",
        "import json\n",
        "\n",
        "class AzStorageClient:\n",
        "    def __init__(self, cred_file):\n",
        "        self.blob_svc_client = None\n",
        "        self.container_client_list = defaultdict(str)\n",
        "        if os.path.exists(cred_file):\n",
        "            connect_str = \"\"\n",
        "            with open(cred_file, \"rb\") as f:\n",
        "                data = json.load(f)\n",
        "                connect_str = data['connectionstr']\n",
        "                self.blob_svc_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "                tokens = connect_str.split(';')\n",
        "                for t in tokens:\n",
        "                  if \"AccountName=\" in t:\n",
        "                    self.AccountName = t[len(\"AccountName=\"):]\n",
        "                  elif \"AccountKey=\" in t:\n",
        "                    self.AccountKey = t[len(\"AccountKey=\"):]\n",
        "        else:\n",
        "            print(\"ERROR: {cred_file} not found\")\n",
        "    \n",
        "    def getSparkSessionKeys(self):\n",
        "      return [f'fs.azure.account.key.{self.AccountName}.blob.core.windows.net',  self.AccountKey, self.AccountName]\n",
        "\n",
        "    def createContainer(self, container_name):\n",
        "        if self.blob_svc_client:\n",
        "            self.blob_svc_client.create_container(container_name)\n",
        "            print(f\"Container '{container_name}' created.\")\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "\n",
        "    def listBlobs(self, container_name):\n",
        "        if self.blob_svc_client:\n",
        "            if not self.container_client_list[container_name]:\n",
        "                self.container_client_list[container_name] = self.blob_svc_client.get_container_client(container= container_name)\n",
        "            blob_list = self.container_client_list[container_name].list_blobs()\n",
        "            return blob_list\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "\n",
        "    def uploadBlob(self, container_name, blob_name, data, overwrite=False, verbose=True):\n",
        "        if self.blob_svc_client:\n",
        "            blob_cleint = self.blob_svc_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "            blob_cleint.upload_blob(data, overwrite=overwrite)\n",
        "            if verbose:\n",
        "                print(f'File uploaded to {container_name}/{blob_name}')\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    \n",
        "    def downloadBlob(self, container_name, blob_name):\n",
        "        if self.blob_svc_client:\n",
        "            if not self.container_client_list[container_name]:\n",
        "                self.container_client_list[container_name] = self.blob_svc_client.get_container_client(container= container_name)\n",
        "            \n",
        "            return self.container_client_list[container_name].download_blob(blob_name).readall()\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    \n",
        "    def downloadBlob2Stream(self, container_name, blob_name):\n",
        "        if self.blob_svc_client:\n",
        "            if not self.container_client_list[container_name]:\n",
        "                self.container_client_list[container_name] = self.blob_svc_client.get_container_client(container= container_name)\n",
        "            \n",
        "            stream = BytesIO()\n",
        "            self.container_client_list[container_name].download_blob(blob_name).readinto(stream)\n",
        "            return stream\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    \n",
        "    def deleteBlob(self, container_name, blob_name, verbose=True):\n",
        "        if self.blob_svc_client:\n",
        "            blob_client = self.blob_svc_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "            blob_client.delete_blob()\n",
        "            if verbose:\n",
        "                print(f'{container_name}/{blob_name} deleted')\n",
        "        else:\n",
        "            print(\"ERROR: Azure Storage Blob Client does not exist.\")\n",
        "    "
      ],
      "metadata": {
        "id": "0Ds94lLqeUBF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UOZGHip0yfGP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Load splits from Azure\n",
        "azStorageClient = AzStorageClient(az_cred_file)\n",
        "\n",
        "train_fs = azStorageClient.downloadBlob2Stream(container, train_blob_name)\n",
        "train_df = pd.read_parquet(train_fs, engine='pyarrow')\n",
        "\n",
        "val_fs = azStorageClient.downloadBlob2Stream(container, val_blob_name)\n",
        "val_df = pd.read_parquet(val_fs, engine='pyarrow')\n",
        "\n",
        "test_fs = azStorageClient.downloadBlob2Stream(container, test_blob_name)\n",
        "test_df = pd.read_parquet(test_fs, engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": [],
        "id": "xAnEvgr3amyK"
      },
      "outputs": [],
      "source": [
        "# Prep x, y dataset for train\n",
        "target_variable = 'GPP_NT_VUT_REF'\n",
        "drop_cols = ['site_id', 'timestep_idx_local', 'timestep_idx_global', 'index', 'datetime','gap_flag_hour', 'gap_flag_month']\n",
        "\n",
        "X_train = train_df.drop([target_variable] + drop_cols, axis=1)\n",
        "y_train = train_df[target_variable]\n",
        "X_val = val_df.drop([target_variable] + drop_cols, axis=1)\n",
        "y_val = val_df[target_variable]\n",
        "X_test = test_df.drop([target_variable] + drop_cols, axis=1)\n",
        "y_test = test_df[target_variable]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_Ko-f2TsAYb"
      },
      "source": [
        "## Train RFR Model w/ best params from v1 tuning (see mvp notebook)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7K3ENYUejvT",
        "outputId": "7de22c13-021d-42d2-a9e1-a3f484784036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA', 'PA_ERA', 'EVI',\n",
              "       'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7',\n",
              "       'TA_ERA_szn_mean', 'TA_ERA_amp_msc', 'TA_ERA_min_msc',\n",
              "       'SW_IN_ERA_szn_mean', 'SW_IN_ERA_amp_msc', 'SW_IN_ERA_min_msc',\n",
              "       'P_ERA_szn_mean', 'P_ERA_amp_msc', 'P_ERA_min_msc', 'EVI_szn_mean',\n",
              "       'EVI_amp_msc', 'EVI_min_msc', 'NDVI_szn_mean', 'NDVI_amp_msc',\n",
              "       'NDVI_min_msc', 'NIRv_szn_mean', 'NIRv_amp_msc', 'NIRv_min_msc',\n",
              "       'b4_szn_mean', 'b4_amp_msc', 'b4_min_msc', 'prcp_week_sum',\n",
              "       'prcp_month_sum', 'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN',\n",
              "       'CSIF-SIFdaily', 'PET', 'Ts', 'prcp', 'prcp-lag3', 'ESACCI-sm', 'NDWI',\n",
              "       'Percent_Snow', 'Fpar', 'Lai', 'LST_Day', 'LST_Night', 'koppen_sub',\n",
              "       'koppen_main', 'month', 'day', 'hour', 'MODIS_LC', 'c3c4_C3', 'c3c4_C4',\n",
              "       'c3c4_mix', 'c3c4_rotation', 'c3c4_unknown', 'MODIS_PFT_CRO',\n",
              "       'MODIS_PFT_DBF', 'MODIS_PFT_EBF', 'MODIS_PFT_ENF', 'MODIS_PFT_GRA',\n",
              "       'MODIS_PFT_MF', 'MODIS_PFT_Other', 'MODIS_PFT_SA', 'MODIS_PFT_SH',\n",
              "       'MODIS_IGBP_CRO', 'MODIS_IGBP_CSH', 'MODIS_IGBP_DBF', 'MODIS_IGBP_EBF',\n",
              "       'MODIS_IGBP_ENF', 'MODIS_IGBP_GRA', 'MODIS_IGBP_MF', 'MODIS_IGBP_OSH',\n",
              "       'MODIS_IGBP_SAV', 'MODIS_IGBP_URB', 'MODIS_IGBP_WAT', 'MODIS_IGBP_WET',\n",
              "       'MODIS_IGBP_WSA', 'hemisphere_NS_North', 'hemisphere_NS_South',\n",
              "       'lat_band_lat_band_2', 'lat_band_lat_band_3', 'lat_band_lat_band_4',\n",
              "       'lat_band_lat_band_5'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Search -> postponed because of the required resource and time..."
      ],
      "metadata": {
        "id": "lbKGUMi2e6dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "\n",
        "random_grid = {'bootstrap': [True, False],\n",
        " 'max_depth': [5, 10, 20, 40],\n",
        "#  'max_features': ['auto', 'sqrt'],\n",
        " 'min_samples_leaf': [1, 2, 4],\n",
        " 'min_samples_split': [2, 5, 10],\n",
        " 'n_estimators': [10, 50, 100, 200]}\n",
        "\n",
        "print(random_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVtIpSopejr7",
        "outputId": "7447d1fa-d894-486f-9332-ad75880b831d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': [True, False], 'max_depth': [5, 10, 20, 40], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [10, 50, 100, 200]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the random grid to search for best hyperparameters\n",
        "# # First create the base model to tune\n",
        "# rf = RandomForestRegressor()\n",
        "# # Random search of parameters, using 3 fold cross validation, \n",
        "# # search across 100 different combinations, and use all available cores\n",
        "# rf_random = RandomizedSearchCV(estimator = rf, \n",
        "#                                param_distributions = random_grid, \n",
        "#                                n_iter = 50, cv = 3, \n",
        "#                                verbose=2, random_state=42, n_jobs = -1)\n",
        "# # Fit the random search model\n",
        "# rf_random.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "t6AEfQRZejog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning using hyperopt\n",
        "\n",
        "The available hyperopt optimization algorithms are -\n",
        "\n",
        "`hp.choice(label, options)` — Returns one of the options, which should be a list or tuple.\n",
        "\n",
        "`hp.randint(label, upper)` — Returns a random integer between the range [0, upper).\n",
        "\n",
        "`hp.uniform(label, low, high)` — Returns a value uniformly between low and high.\n",
        "\n",
        "`hp.quniform(label, low, high, q)` — Returns a value round(uniform(low, high) / q) * q, i.e it rounds the decimal values and returns an integer.\n",
        "\n",
        "`hp.normal(label, mean, std)` — Returns a real value that’s normally-distributed with mean and standard deviation sigma."
      ],
      "metadata": {
        "id": "fIuu0NalUcht"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqHeoGAl7q-m"
      },
      "outputs": [],
      "source": [
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "\n",
        "space={'bootstrap': hp.choice('bootstrap', [True, False]),\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 200, q=1),\n",
        "        'max_depth': hp.quniform(\"max_depth\", 3, 50, 1),\n",
        "        'max_features': hp.choice('max_features', ['auto', 'sqrt']),\n",
        "        'min_samples_leaf': hp.quniform('min_samples_leaf',3,10,1),\n",
        "        'min_samples_split': hp.quniform('min_samples_leaf',2,10,1),\n",
        "        'seed': 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Define X_val and y_val)"
      ],
      "metadata": {
        "id": "LqlRIVH6uJzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def objective(space):\n",
        "    global X_train, y_train, X_val, y_val\n",
        "    \n",
        "    rfr = RandomForestRegressor(bootstrap = space['bootstrap'],\n",
        "                    n_estimators =int(space['n_estimators']), \n",
        "                    max_depth = int(space['max_depth']), \n",
        "                    max_features = space['max_features'],\n",
        "                    min_samples_leaf = int(space['min_samples_leaf']),\n",
        "                    min_samples_split = int(space['min_samples_split'])\n",
        "                    )\n",
        "    \n",
        "    rfr.fit(X_train, y_train)\n",
        "            # eval_metric=\"rmse\",\n",
        "            # early_stopping_rounds=10,verbose=False)\n",
        "    \n",
        "\n",
        "    y_pred = rfr.predict(X_val)\n",
        "    rmse = mean_squared_error(y_val, y_pred, squared=False) # squared=False returns RMSE\n",
        "\n",
        "    print (\"SCORE(RMSE):\", rmse)\n",
        "    return {'loss': -rmse, 'status': STATUS_OK }"
      ],
      "metadata": {
        "id": "QPGO1wAz5-aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "\n",
        "best_hyperparams = fmin(fn = objective,\n",
        "                        space = space,\n",
        "                        algo = tpe.suggest,\n",
        "                        max_evals = 50,\n",
        "                        trials = trials)"
      ],
      "metadata": {
        "id": "YJ0PBK5uqDUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best hyperparameters are : \",\"\\n\")\n",
        "print(best_hyperparams)"
      ],
      "metadata": {
        "id": "y4Ul8OCkqDRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tune best parameters"
      ],
      "metadata": {
        "id": "QE_Z-lGAuxx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "best_rfr = RandomForestRegressor(\n",
        "                    bootstrap = best_hyperparams['bootstrap'],\n",
        "                    n_estimators = best_hyperparams['n_estimators'], \n",
        "                    max_depth = best_hyperparams['max_depth'], \n",
        "                    max_features = best_hyperparams['max_features'],\n",
        "                    min_samples_leaf = best_hyperparams['min_samples_leaf'],\n",
        "                    min_samples_split = best_hyperparams['min_samples_split'])\n",
        "\n",
        "# Train the regressor on training data\n",
        "start_time = time.time()\n",
        "best_rfr.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "fit_time = end_time - start_time\n",
        "print(\"Time taken to fit the model: {:.2f} seconds\".format(fit_time))"
      ],
      "metadata": {
        "id": "FnHHAIlLtb3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final prediction"
      ],
      "metadata": {
        "id": "ZPMiV7RYu4wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained regressor to make predictions on test data\n",
        "y_pred = best_rfr.predict(X_test)\n",
        "\n",
        "# Calculate and print RMSE, MAE, and R-squared on the test set\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"RMSE: {:.2f}\".format(rmse))\n",
        "print(\"MAE: {:.2f}\".format(mae))\n",
        "print(\"R-squared: {:.2f}\".format(r2))\n"
      ],
      "metadata": {
        "id": "j1d7B5ndu4J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run RFR - intial result"
      ],
      "metadata": {
        "id": "4vVICb_QF2b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [],
        "id": "uY6WIJB3amyL"
      },
      "outputs": [],
      "source": [
        "# Using best params from the tuned model in V1\n",
        "best_params = {}\n",
        "best_params['n_estimators'] = 50\n",
        "best_params['max_depth'] = 10\n",
        "best_params['max_features'] = 'sqrt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1, verbose=1)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FP674RcuGWMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91YY_BZajnjQ"
      },
      "source": [
        "## Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "outputId": "260c6082-def7-4afb-e765-da43e43745a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gzGfrB2XjnjR"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# get the feature importances\n",
        "importances = pd.Series(model.feature_importances_, index=X_test.columns).sort_values(ascending=False)\n",
        "\n",
        "# Visualize\n",
        "importances_sorted = importances.sort_values(ascending=True)[-30:]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.barh(importances_sorted.index, importances_sorted.values)\n",
        "ax.set_title('Feature Importances')\n",
        "ax.set_xlabel('Importance')\n",
        "ax.set_ylabel('Feature')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "outputId": "e9a77ade-d0fe-4dea-cf79-f864c4584fc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKRtoIlKjnjS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SW_IN_ERA        0.36083\n",
            "hour             0.10370\n",
            "VPD_ERA          0.05758\n",
            "NIRv             0.04676\n",
            "NDVI             0.04636\n",
            "                   ...  \n",
            "MODIS_PFT_ENF    0.00002\n",
            "MODIS_IGBP_EBF   0.00001\n",
            "c3c4_unknown     0.00000\n",
            "MODIS_IGBP_CSH   0.00000\n",
            "MODIS_IGBP_WET   0.00000\n",
            "Length: 94, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIj2lvRojnjT",
        "outputId": "6abcaf78-1ddd-4069-d433-8728fe89f4a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8102959038876457"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "importances_df = pd.DataFrame(importances).reset_index()\n",
        "importances_df.columns = [\"feature_name\",\"importance\"]\n",
        "importances_df[\"importance\"][:13].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK_DTLrKamyP"
      },
      "source": [
        "## Evaluate RFR on Val & Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "LDrbwlDlamyP"
      },
      "outputs": [],
      "source": [
        "# # Predict on val/test sets\n",
        "# y_pred_val = model_pkl.predict(X_val)\n",
        "# y_pred_test = model_pkl.predict(X_test)\n",
        "\n",
        "# # Evaluate predictions - VAL\n",
        "# rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "# mae = mean_absolute_error(y_val, y_pred_val)\n",
        "# r2 = r2_score(y_val, y_pred_val)\n",
        "# print(f\"Val RMSE: {rmse}\")\n",
        "# print(f\"Val MAE: {mae}\")\n",
        "# print(f\"Val R2/NSE: {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Reduction"
      ],
      "metadata": {
        "id": "Y3Cacc9DiJPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RFR_fit_show_result(model, X_train, y_train, X_val, y_val, feature_list, model_name):\n",
        "  X_train = X_train[feature_list]\n",
        "  y_train = y_train\n",
        "  X_val = X_val[feature_list]\n",
        "  y_val = y_val\n",
        "  \n",
        "  model.fit(X_train, y_train)\n",
        "  # Predict on val/test sets\n",
        "  y_pred_val = model.predict(X_val)\n",
        "  # y_pred_test = model.predict(X_test)\n",
        "\n",
        "  # Evaluate predictions - VAL\n",
        "  rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "  mae = mean_absolute_error(y_val, y_pred_val)\n",
        "  r2 = r2_score(y_val, y_pred_val)\n",
        "  print(f\"   \")\n",
        "  print(f\"{model_name}, Val RMSE: {rmse}, Val MAE: {mae}, Val R2/NSE: {r2}\")\n",
        "  return [model_name, feature_list, rmse, mae, r2]"
      ],
      "metadata": {
        "id": "Z-FCAclOiJFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1, model_2, model_3, model_4, model_5 = [],[],[],[],[]\n",
        "model_6, model_7, model_8, model_9, model_10 = [],[],[],[],[]\n",
        "\n",
        "num_feature_list = [10, 12, 14, 16, 18, 20, 22, 25, 30, 35]\n",
        "importance_total = importances_df[\"importance\"][:13].sum()\n",
        "\n",
        "list(importances_df[\"feature_name\"][:13])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ft471GokPky",
        "outputId": "06b35dec-21f2-4646-ac56-3929236cdd37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SW_IN_ERA',\n",
              " 'hour',\n",
              " 'VPD_ERA',\n",
              " 'NIRv',\n",
              " 'NDVI',\n",
              " 'EVI',\n",
              " 'TA_ERA',\n",
              " 'Fpar',\n",
              " 'Lai',\n",
              " 'CSIF-SIFdaily',\n",
              " 'BESS-PARdiff',\n",
              " 'NDVI_szn_mean',\n",
              " 'b1']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_feature = 10\n",
        "feature_list = list(importances_df[\"feature_name\"][:num_feature])\n",
        "feature_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvZ2qoI5pkuW",
        "outputId": "57d2d765-9678-4bf7-854f-4b95d2b4e213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SW_IN_ERA',\n",
              " 'hour',\n",
              " 'VPD_ERA',\n",
              " 'NIRv',\n",
              " 'NDVI',\n",
              " 'EVI',\n",
              " 'TA_ERA',\n",
              " 'Fpar',\n",
              " 'Lai',\n",
              " 'CSIF-SIFdaily']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances_df[\"feature_name\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OCpDYY4JEzz",
        "outputId": "39e0c9fd-489c-4cae-c6c0-8694f9790101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94,)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_list = [[\"model_name\", \"feature_list\", \"RMSE\", \"MAE\", \"R2\"]]\n",
        "model_name_list = [\"model_1\", \"model_2\", \"model_3\", \"model_4\", \"model_5\", \n",
        "              \"model_6\", \"model_7\", \"model_8\", \"model_9\", \"model_10\", \n",
        "              \"model_11\", \"model_12\", \"model_13\", \"model_14\", \"model_15\"]\n",
        "num_feature_list = [3, 5, 7, 10, 12, 14, 16, 18, 20, 22, 25, 30, 35, 50, 90]\n",
        "\n",
        "for idx, num_feature in enumerate(num_feature_list):\n",
        "  feature_list = list(importances_df[\"feature_name\"][:num_feature])\n",
        "  model_name = model_name_list[idx]\n",
        "  model_list += [RFR_fit_show_result(model, X_train, y_train, X_val, y_val, feature_list, model_name)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX63Zgpyje7k",
        "outputId": "b216efdf-94b0-4219-b28c-47b07e8601e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.7s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_1, Val RMSE: 5.52138744384949, Val MAE: 3.2094065275957027, Val R2/NSE: 0.42746178931715895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.2s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.5s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_2, Val RMSE: 3.621476786666066, Val MAE: 2.0217146809382225, Val R2/NSE: 0.7536914762230129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.8s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_3, Val RMSE: 3.5837865520363006, Val MAE: 1.9915562279762076, Val R2/NSE: 0.7587916706097189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   21.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   34.2s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_4, Val RMSE: 3.5948660706926847, Val MAE: 2.001794608799337, Val R2/NSE: 0.7572979414430955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   19.8s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   31.7s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_5, Val RMSE: 3.6051838024087677, Val MAE: 2.0072484689993497, Val R2/NSE: 0.7559027693985813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.2s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_6, Val RMSE: 3.6223315400145513, Val MAE: 2.017037166854044, Val R2/NSE: 0.7535751933399648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   22.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   36.6s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_7, Val RMSE: 3.61070837408951, Val MAE: 2.015813674043955, Val R2/NSE: 0.7551540886294615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   22.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   35.4s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_8, Val RMSE: 3.624763829303129, Val MAE: 2.0258641412488854, Val R2/NSE: 0.7532441481869245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   22.1s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   34.5s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_9, Val RMSE: 3.6231792579152877, Val MAE: 2.0295305649642965, Val R2/NSE: 0.7534598404732845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   22.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   35.3s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_10, Val RMSE: 3.638509748917348, Val MAE: 2.0451750591627604, Val R2/NSE: 0.7513690922324698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   25.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   39.8s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_11, Val RMSE: 3.6717808127363183, Val MAE: 2.0582658885736977, Val R2/NSE: 0.7468012682921942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   23.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   37.0s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_12, Val RMSE: 3.6738487946260228, Val MAE: 2.08003764958367, Val R2/NSE: 0.7465159801066749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   23.9s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   37.2s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_13, Val RMSE: 3.679013409870923, Val MAE: 2.086391606279179, Val R2/NSE: 0.7458027947297341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   28.8s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.6s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_14, Val RMSE: 3.7343505548707285, Val MAE: 2.1189821144597727, Val R2/NSE: 0.7380983720434989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   28.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   43.7s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_15, Val RMSE: 3.8818803615209996, Val MAE: 2.28402534205913, Val R2/NSE: 0.7169961637261888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimensionality_reduction_RFR_df = pd.DataFrame(model_list[1:], columns=model_list[0])\n",
        "dimensionality_reduction_RFR_df[\"num_of_feature\"] = num_feature_list"
      ],
      "metadata": {
        "id": "LaghwOWvnlA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensionality_reduction_RFR_df =dimensionality_reduction_RFR_df[['model_name', 'num_of_feature','feature_list', 'RMSE', 'MAE', 'R2']]\n",
        "dimensionality_reduction_RFR_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "wxk_EDu7LSpr",
        "outputId": "d904bbba-6c34-4f3b-8683-b9850f9d4ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   model_name  num_of_feature  \\\n",
              "0     model_1               3   \n",
              "1     model_2               5   \n",
              "2     model_3               7   \n",
              "3     model_4              10   \n",
              "4     model_5              12   \n",
              "5     model_6              14   \n",
              "6     model_7              16   \n",
              "7     model_8              18   \n",
              "8     model_9              20   \n",
              "9    model_10              22   \n",
              "10   model_11              25   \n",
              "11   model_12              30   \n",
              "12   model_13              35   \n",
              "13   model_14              50   \n",
              "14   model_15              90   \n",
              "\n",
              "                                         feature_list    RMSE     MAE      R2  \n",
              "0                          [SW_IN_ERA, hour, VPD_ERA] 5.52139 3.20941 0.42746  \n",
              "1              [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI] 3.62148 2.02171 0.75369  \n",
              "2   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.58379 1.99156 0.75879  \n",
              "3   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.59487 2.00179 0.75730  \n",
              "4   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.60518 2.00725 0.75590  \n",
              "5   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.62233 2.01704 0.75358  \n",
              "6   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.61071 2.01581 0.75515  \n",
              "7   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.62476 2.02586 0.75324  \n",
              "8   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.62318 2.02953 0.75346  \n",
              "9   [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.63851 2.04518 0.75137  \n",
              "10  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.67178 2.05827 0.74680  \n",
              "11  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.67385 2.08004 0.74652  \n",
              "12  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.67901 2.08639 0.74580  \n",
              "13  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.73435 2.11898 0.73810  \n",
              "14  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.88188 2.28403 0.71700  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50769e09-4ca0-4ea6-92fd-9ba0c82718ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>num_of_feature</th>\n",
              "      <th>feature_list</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>3</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA]</td>\n",
              "      <td>5.52139</td>\n",
              "      <td>3.20941</td>\n",
              "      <td>0.42746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>5</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI]</td>\n",
              "      <td>3.62148</td>\n",
              "      <td>2.02171</td>\n",
              "      <td>0.75369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>7</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.58379</td>\n",
              "      <td>1.99156</td>\n",
              "      <td>0.75879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>model_4</td>\n",
              "      <td>10</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.59487</td>\n",
              "      <td>2.00179</td>\n",
              "      <td>0.75730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>model_5</td>\n",
              "      <td>12</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.60518</td>\n",
              "      <td>2.00725</td>\n",
              "      <td>0.75590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>model_6</td>\n",
              "      <td>14</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.62233</td>\n",
              "      <td>2.01704</td>\n",
              "      <td>0.75358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>model_7</td>\n",
              "      <td>16</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.61071</td>\n",
              "      <td>2.01581</td>\n",
              "      <td>0.75515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>model_8</td>\n",
              "      <td>18</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.62476</td>\n",
              "      <td>2.02586</td>\n",
              "      <td>0.75324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>model_9</td>\n",
              "      <td>20</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.62318</td>\n",
              "      <td>2.02953</td>\n",
              "      <td>0.75346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>model_10</td>\n",
              "      <td>22</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.63851</td>\n",
              "      <td>2.04518</td>\n",
              "      <td>0.75137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>model_11</td>\n",
              "      <td>25</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.67178</td>\n",
              "      <td>2.05827</td>\n",
              "      <td>0.74680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>model_12</td>\n",
              "      <td>30</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.67385</td>\n",
              "      <td>2.08004</td>\n",
              "      <td>0.74652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>model_13</td>\n",
              "      <td>35</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.67901</td>\n",
              "      <td>2.08639</td>\n",
              "      <td>0.74580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>model_14</td>\n",
              "      <td>50</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.73435</td>\n",
              "      <td>2.11898</td>\n",
              "      <td>0.73810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>model_15</td>\n",
              "      <td>90</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.88188</td>\n",
              "      <td>2.28403</td>\n",
              "      <td>0.71700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50769e09-4ca0-4ea6-92fd-9ba0c82718ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50769e09-4ca0-4ea6-92fd-9ba0c82718ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50769e09-4ca0-4ea6-92fd-9ba0c82718ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_list_2 = [[\"model_name\", \"feature_list\", \"RMSE\", \"MAE\", \"R2\"]]\n",
        "model_name_list = [\"model_2\", \"model2_2\", \"model_3\", \"model_3_2\", \"model_3_3\",\"model_4\"]#, \n",
        "              # \"model_6\", \"model_7\", \"model_8\", \"model_9\", \"model_10\", \n",
        "              # \"model_11\", \"model_12\", \"model_13\", \"model_14\", \"model_15\"]\n",
        "num_feature_list = [5, 6 , 7, 8, 9, 10]\n",
        "\n",
        "for idx, num_feature in enumerate(num_feature_list):\n",
        "  feature_list = list(importances_df[\"feature_name\"][:num_feature])\n",
        "  model_name = model_name_list[idx]\n",
        "  model_list_2 += [RFR_fit_show_result(model, X_train, y_train, X_val, y_val, feature_list, model_name)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYgIj4UuLlwk",
        "outputId": "d61eefd6-7d41-4102-99e5-b044afa8b99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.7s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_2, Val RMSE: 3.621476786666066, Val MAE: 2.0217146809382225, Val R2/NSE: 0.7536914762230129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.4s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model2_2, Val RMSE: 3.619276846252095, Val MAE: 2.022805911521489, Val R2/NSE: 0.7539906356678721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.6s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_3, Val RMSE: 3.5837865520363006, Val MAE: 1.9915562279762076, Val R2/NSE: 0.758791670609719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   16.9s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.1s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_3_2, Val RMSE: 3.600952005511753, Val MAE: 2.0082941602606517, Val R2/NSE: 0.7564754800868392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   22.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   36.1s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_3_3, Val RMSE: 3.5922364126835724, Val MAE: 1.9976995384708645, Val R2/NSE: 0.7576528865053909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   21.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   34.0s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "model_4, Val RMSE: 3.5948660706926847, Val MAE: 2.001794608799337, Val R2/NSE: 0.7572979414430955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimensionality_reduction_RFR_df_2 = pd.DataFrame(model_list_2[1:], columns=model_list_2[0])\n",
        "dimensionality_reduction_RFR_df_2[\"num_of_feature\"] = num_feature_list\n",
        "dimensionality_reduction_RFR_df_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "3PR3-WX9MLGi",
        "outputId": "5d4cb349-7949-457d-dee0-fd8b819f3e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  model_name                                       feature_list    RMSE  \\\n",
              "0    model_2             [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI] 3.62148   \n",
              "1   model2_2        [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI] 3.61928   \n",
              "2    model_3  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.58379   \n",
              "3  model_3_2  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.60095   \n",
              "4  model_3_3  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.59224   \n",
              "5    model_4  [SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA... 3.59487   \n",
              "\n",
              "      MAE      R2  num_of_feature  \n",
              "0 2.02171 0.75369               5  \n",
              "1 2.02281 0.75399               6  \n",
              "2 1.99156 0.75879               7  \n",
              "3 2.00829 0.75648               8  \n",
              "4 1.99770 0.75765               9  \n",
              "5 2.00179 0.75730              10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20f523f0-24ec-477a-86bc-fe9e5cde6a34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>feature_list</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>R2</th>\n",
              "      <th>num_of_feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_2</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI]</td>\n",
              "      <td>3.62148</td>\n",
              "      <td>2.02171</td>\n",
              "      <td>0.75369</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model2_2</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI]</td>\n",
              "      <td>3.61928</td>\n",
              "      <td>2.02281</td>\n",
              "      <td>0.75399</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.58379</td>\n",
              "      <td>1.99156</td>\n",
              "      <td>0.75879</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>model_3_2</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.60095</td>\n",
              "      <td>2.00829</td>\n",
              "      <td>0.75648</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>model_3_3</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.59224</td>\n",
              "      <td>1.99770</td>\n",
              "      <td>0.75765</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>model_4</td>\n",
              "      <td>[SW_IN_ERA, hour, VPD_ERA, NIRv, NDVI, EVI, TA...</td>\n",
              "      <td>3.59487</td>\n",
              "      <td>2.00179</td>\n",
              "      <td>0.75730</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20f523f0-24ec-477a-86bc-fe9e5cde6a34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20f523f0-24ec-477a-86bc-fe9e5cde6a34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20f523f0-24ec-477a-86bc-fe9e5cde6a34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build model with TOP7 features and store the model to pickle"
      ],
      "metadata": {
        "id": "spngJ7WKGcMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = ['SW_IN_ERA', 'hour', 'VPD_ERA', 'NIRv', 'NDVI', 'EVI', 'TA_ERA']"
      ],
      "metadata": {
        "id": "8H6j65ciHPnt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[feature_list]\n",
        "X_val = X_val[feature_list]\n",
        "\n",
        "model_top7 = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1, verbose=1)\n",
        "model_top7.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "C69wfKc0Gb3M",
        "outputId": "5ece1c31-51df-4db5-b531-ee0b1d8d4460"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.9s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=10, max_features='sqrt', n_estimators=50,\n",
              "                      n_jobs=-1, random_state=42, verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, n_estimators=50,\n",
              "                      n_jobs=-1, random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, n_estimators=50,\n",
              "                      n_jobs=-1, random_state=42, verbose=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on val/test sets\n",
        "y_pred_val = model_top7.predict(X_val)\n",
        "\n",
        "# Evaluate predictions - VAL\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "mae = mean_absolute_error(y_val, y_pred_val)\n",
        "r2 = r2_score(y_val, y_pred_val)\n",
        "print(f\"Val RMSE: {rmse}, Val MAE: {mae}, Val R2/NSE: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTb9TJyVHl_d",
        "outputId": "15fcf372-15d8-4785-9763-c622526d5de9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val RMSE: 3.5837865520363006, Val MAE: 1.9915562279762076, Val R2/NSE: 0.7587916706097189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_objects_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tenIh8zKIWMx",
        "outputId": "392d139d-102d-429a-a25e-5d3efc8ae3ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/TFT_baseline/code/src/modeling/model_objects'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "\n",
        "# Save model object\n",
        "model_save_path_pkl = os.path.join(model_objects_dir, 'rfr_mvp_v3_top7_features.pkl')\n",
        "model_save_path_jl = os.path.join(model_objects_dir, 'rfr_mvp_v3_top7_features.joblib')\n",
        "pickle.dump(model_top7, open(model_save_path_pkl, \"wb\"))\n",
        "\n",
        "if not os.path.exists(model_save_path_jl):\n",
        "    print(\"Saving model in .joblib format\")\n",
        "    joblib.dump(model_top7, model_save_path_jl)"
      ],
      "metadata": {
        "id": "54d78ueNGbw9"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-load saved model\n",
        "try:\n",
        "    model_pkl = joblib.load(model_save_path_pkl)\n",
        "    model_jl = joblib.load(model_save_path_jl)\n",
        "    print(\"Loaded both model objects\")\n",
        "except:\n",
        "    print(\"unable to load models, make sure object paths are correct and conda env in use\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoJn7rKUHrjZ",
        "outputId": "52d2d3d3-e592-421b-d0bd-e4952082c906"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded both model objects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_val_trial = model_pkl.predict(X_val)\n",
        "y_pred_val_trial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkqHgequKeUp",
        "outputId": "25f5262f-cbe3-4779-8c28-8fe35b0d1f22"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.4s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.09666841, -0.06275384, -0.0656414 , ...,  1.59418392,\n",
              "        1.59418392,  1.59418392])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kksR8zwmamyQ"
      },
      "source": [
        "## Get performance by IGBP type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "tags": [],
        "id": "tYMikpRjamyQ"
      },
      "outputs": [],
      "source": [
        "# # Get categorical feature back from dummies\n",
        "# igbp_cols = [x for x in test_df.columns if 'IGBP_' in x]\n",
        "# test_df['MODIS_IGBP'] = test_df[igbp_cols].idxmax(axis=1)\n",
        "# test_df['MODIS_IGBP'] = test_df['MODIS_IGBP'].apply(lambda x: x.split(\"_\")[-1])\n",
        "\n",
        "# # Subset df\n",
        "# test_trim = test_df[['MODIS_IGBP', 'GPP_NT_VUT_REF']].copy()\n",
        "# test_trim['y_pred'] = y_pred_test\n",
        "\n",
        "# # Get metrics by group\n",
        "# igbp_group_metrics = {}\n",
        "# groups = test_df['MODIS_IGBP'].unique()\n",
        "# for group in groups:\n",
        "#     test_group = test_trim.loc[test_trim['MODIS_IGBP']==group, ].copy()\n",
        "    \n",
        "#     # Get metrics\n",
        "#     rmse = np.sqrt(mean_squared_error(test_group['GPP_NT_VUT_REF'], test_group['y_pred']))\n",
        "#     mae = mean_absolute_error(test_group['GPP_NT_VUT_REF'], test_group['y_pred'])\n",
        "#     r2 = r2_score(test_group['GPP_NT_VUT_REF'], test_group['y_pred'])\n",
        "    \n",
        "#     # Save to dict\n",
        "#     igbp_group_metrics[group] = {'RMSE': round(rmse, 2), 'MAE': round(mae, 2), 'R2': round(r2, 2)}\n",
        "    \n",
        "# igbp_metric_df = pd.DataFrame.from_dict(igbp_group_metrics, orient='index')\n",
        "# igbp_metric_df = igbp_metric_df.reset_index().rename(columns={'index': 'MODIS_IGBP'})\n",
        "# igbp_metric_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "tags": [],
        "id": "3Dx10GuJamyQ"
      },
      "outputs": [],
      "source": [
        "# # compute the percentage of the dataset represented by each group\n",
        "# group_sizes = test_trim.groupby('MODIS_IGBP').size()\n",
        "# percentages = group_sizes / len(test_trim) * 100\n",
        "# group_stats = test_trim.groupby('MODIS_IGBP')['GPP_NT_VUT_REF'].agg(['mean', 'var'])\n",
        "# group_stats.columns = ['mean_GPP', 'var_GPP']\n",
        "# group_stats['percent_dataset'] = percentages\n",
        "# group_stats = group_stats.reset_index()\n",
        "\n",
        "# merged_df = pd.merge(group_stats, igbp_metric_df, on='MODIS_IGBP')\n",
        "# merged_df.sort_values('R2', ascending=False, inplace=True)\n",
        "# merged_df"
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      }
    ],
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "collapsed_sections": [
        "fIuu0NalUcht"
      ]
    },
    "instance_type": "ml.m5.2xlarge",
    "kernelspec": {
      "display_name": "Python [conda env:py310] (arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0)",
      "language": "python",
      "name": "conda-env-py310-py__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}