{"cells":[{"cell_type":"markdown","metadata":{"id":"4-mBiDcbrZ1f"},"source":["# Notebook Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":883,"status":"ok","timestamp":1676804752494,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"0vOPrR8CrO1r","outputId":"97955b62-22e1-4653-cdb5-0b475838d897"},"outputs":[],"source":["if 'google.colab' in str(get_ipython()):\n","  IN_COLLAB = True\n","else:\n","  IN_COLLAB = False\n","\n","#TODO: CHANGE THIS BASED ON YOUR OWN LOCAL SETTINGS\n","MY_HOME_ABS_PATH = \"/Users/jetcalz07/Desktop/MIDS/W210_Capstone/co2-flux-hourly-gpp-modeling\"\n","\n","if IN_COLLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"nuowBABbrhti"},"source":["## Import Modules"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1376,"status":"ok","timestamp":1676804760778,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"noZwsViCrnAS"},"outputs":[],"source":["# install required modules quietly\n","required_packages = ['geopandas', 'pyspark', 'azure-storage-blob']\n","\n","for p in required_packages: \n","  try:\n","      __import__(p)\n","  except ImportError:\n","      %pip install {p} --quiet\n","\n","import os\n","os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n","os.chdir(MY_HOME_ABS_PATH) # <------------------ ADDED\n","import math\n","import json\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","from pyspark.sql.functions import col\n","import pyspark.pandas as pd\n","from calendar import monthrange\n","from datetime import datetime\n","from io import BytesIO\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# Load locale custome modules\n","import sys\n","if IN_COLLAB:\n","  os.chdir(MY_HOME_ABS_PATH)\n","  sys.path.insert(0,os.path.abspath(\"./code/src/tools\"))\n","else:\n","  sys.path.append(os.path.abspath(\"./code/src/tools\"))\n","\n","from CloudIO.AzStorageClient import AzStorageClient\n","from data_pipeline_lib import *\n","\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.float_format', lambda x: '%.5f' % x)"]},{"cell_type":"markdown","metadata":{"id":"2IwvFVLFrtkM"},"source":["# Constant Definitions"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1676804775178,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"KXgevZgWrxiV"},"outputs":[],"source":["root_dir =  MY_HOME_ABS_PATH\n","tmp_dir =  root_dir + os.sep + '.tmp'\n","raw_data_dir = root_dir + os.sep + 'data'\n","data_dir = root_dir + os.sep + 'data/datasets'\n","cred_dir = root_dir + os.sep + '.cred'\n","az_cred_file = cred_dir + os.sep + 'azblobcred.json'\n","\n","if IN_COLLAB:\n","  raw_data_dir = \"/content/drive/MyDrive/CO2_flux_gpp_modeling/DS_capstone_23Spring_CO2/Data\"\n","\n","\n","\n","monthly_data_input_fname = data_dir + os.sep + 'data_monthly_v1_0.csv'\n","monthly_data_output_fname = raw_data_dir + os.sep + \"monthly-interpolated-v3.csv\"\n","\n","gap_fill_monthly = False\n","interpolate_na = False\n","\n","included_features= ['SITE_ID', 'year', 'month', 'TIMESTAMP',\n","                   'ESACCI-sm',    # ESACCI Soil Moisture (%)\n","                   'Percent_Snow', # Percentage of snow cover (%)\n","                   'NDWI',      # Normalized Different Water Index (NDWI)\n","                   'PET',       # Potential ET (m)\n","                   'MODIS_PFT', # Plant Function Type\n","                   'MODIS_LC',  # MODIS Land Cover\n","                   'Ts',        # Skin temperature (K) ??\n","                   'LST_Day',   # Daytime land surface temperature (K)\n","                   'LST_Night', # Nightime land surface temperature (K)\n","                   'Lai',       # Leaf Area Index (LAI)\n","                   'Fpar',      # Fraction of photosynthetically active radiation (fPAR)\n","                   'CSIF-SIFdaily', # All-sky daily average SIF\n","                   'BESS-PAR',      # Photosynthetic Active Radiation (PAR) (W/m^2)\n","                   'BESS-PARdiff',  # Diffuse PAR (W/m^2)\n","                   'BESS-RSDN'      # Shortwave downwelling radiation (W/m^2)\n","                   ]"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["class PrepareMonthlyData:\n","    def __init__(self, included_features, monthly_data_input_fname, interpolate_na=False, gap_fill_monthly=False):\n","        self.interpolate_na = interpolate_na\n","        self.gap_fill_monthly = gap_fill_monthly\n","        self.included_features =included_features\n","        self.monthly_data_input_fname = monthly_data_input_fname\n","        self.month_df = pd.read_csv(self.monthly_data_input_fname, usecols=self.included_features)\n","        self.month_df['date'] = pd.to_datetime(self.month_df['TIMESTAMP'],  format=\"%Y%m\")\n","\n","\n","    def to_datetime(self, row):\n","        return pd.to_datetime(f'{row.year}{row.month:02}', format='%Y%m')\n","\n","\n","    def gap_fill(self):\n","        # Resample to fill in missing month gaps, and interpolate values at site-level\n","        monthly_df = None  \n","\n","        # Loop through hourly site data to determine which months are present\n","        for i, s in tqdm(enumerate(self.month_df['SITE_ID'].unique())):\n","            try:\n","                site_file = f'data_full_half_hourly_raw_v0_1_{s}.csv'\n","                site_hr_df = pd.read_csv(f\"{tmp_dir}/{site_file}\", usecols=['SITE_ID', 'year', 'month'])\n","\n","                # Get set of year-months represented in site-hourly dataset\n","                site_hr_df.drop_duplicates(inplace=True)\n","                site_hr_df['datetime'] = site_hr_df.apply(self.to_datetime, axis=1)\n","\n","                # Get monthly data for site\n","                site_month = self.month_df[self.month_df['SITE_ID'] == s]\n","                site_month.reset_index(drop = True, inplace=True)\n","\n","                # Resample montlhly data to get the months required in hourly data\n","                pft = site_month['MODIS_PFT'][0] # retain PFT to fill new rows\n","                site_month = pd.merge(site_hr_df, site_month, how='left', on =['SITE_ID', 'year', 'month'])\n","\n","                # Fill in known values for new/resampled month-level rows\n","                site_month.set_index('datetime', inplace=True)\n","                #site_df['year'] = site_df.index.year.astype(int)\n","                #site_df['month'] = site_df.index.month.astype(int)\n","                site_month['MODIS_PFT'] = pft\n","                site_month['SITE_ID'] = s\n","                site_month.drop(columns='TIMESTAMP', inplace=True)\n","                site_month.drop(columns='date', inplace=True)\n","\n","                # If any new months added by resample, interpolate gap values at site-level\n","                if interpolate_na:\n","                    print(\"Interpolating Values for Missing Months\")\n","                    if site_month.isna().sum().sum() != 0: \n","                        site_month.interpolate(method='linear', limit_direction='both', inplace=True)\n","\n","                # Concat to monthly_df across sites\n","                if type(monthly_df) == type(None):\n","                    monthly_df = site_month\n","                else:\n","                    monthly_df = pd.concat([monthly_df, site_month])\n","\n","            except:\n","                continue\n","\n","        return monthly_df\n","\n","\n","    def run(self):\n","        # fill in missing months or leave it\n","        if self.gap_fill_monthly:\n","            print(\"Gap-Filling Missing Months\")\n","            monthly_df = self.gap_fill()\n","        else:\n","            print(\"No Gap Filling of Monthly Data\")\n","            monthly_df = self.month_df.copy()\n","\n","        # interpolate missing vals or fill w/ -1\n","        if monthly_df.isna().sum().sum() != 0: \n","            if self.interpolate_na:\n","                print(\"Interpolating Values for Missing Records\")\n","                monthly_df.interpolate(method='linear', limit_direction='both', inplace=True)\n","            else:\n","                print(\"Fill all NA with -1\")\n","                monthly_df = monthly_df.fillna(-1)\n","\n","        # Confirm No NAS\n","        if monthly_df.isna().sum().sum() == 0:\n","            print(\"Confirmed: No NA values remain\")\n","        else:\n","            print(\"ISSUE: SOME NA VALUES REMAIN - INVESTIGATE\")\n","            monthly_df.isna().sum()\n","\n","        return monthly_df\n","        "]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No Gap Filling of Monthly Data\n","Fill all NA with -1\n","Confirmed: No NA values remain\n"]}],"source":["# Execute Monthly Preparation\n","PrepMonthly = PrepareMonthlyData(included_features, monthly_data_input_fname, interpolate_na=False, gap_fill_monthly=False)                                \n","monthly_df_out = PrepMonthly.run()"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No NAS\n"]}],"source":["# Save out\n","monthly_df_out.to_csv(monthly_data_output_fname)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMksgG6dJySdU68N+q2MrXO","collapsed_sections":["4-mBiDcbrZ1f","nuowBABbrhti","eHPfBKGasKAQ"],"provenance":[]},"kernelspec":{"display_name":"src-rYFmMrY7-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"5cbe69e04c91e7625dfb8f223669796fe243b4d7c88cd4431379e3b6898fe927"}}},"nbformat":4,"nbformat_minor":0}
