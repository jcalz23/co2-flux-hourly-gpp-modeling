{"cells":[{"cell_type":"markdown","metadata":{"id":"4-mBiDcbrZ1f"},"source":["# Notebook Setup"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["CHANGES FROM V1 - V2:\n","- Fixed some issues with date columns in gap-filled records\n","- Use linear interpolator instead of quadratic\n","- For features that were 100% missing at site-level, impute them using linear interpolator at global level\n","RESULT: 0 NA values in monthly df"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":883,"status":"ok","timestamp":1676804752494,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"0vOPrR8CrO1r","outputId":"97955b62-22e1-4653-cdb5-0b475838d897"},"outputs":[],"source":["if 'google.colab' in str(get_ipython()):\n","  IN_COLLAB = True\n","else:\n","  IN_COLLAB = False\n","\n","#TODO: CHANGE THIS BASED ON YOUR OWN LOCAL SETTINGS\n","MY_HOME_ABS_PATH = \"/Users/jetcalz07/Desktop/MIDS/W210_Capstone/co2-flux-hourly-gpp-modeling\"\n","\n","if IN_COLLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"nuowBABbrhti"},"source":["## Import Modules"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1376,"status":"ok","timestamp":1676804760778,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"noZwsViCrnAS"},"outputs":[],"source":["# install required modules quietly\n","required_packages = ['geopandas', 'pyspark', 'azure-storage-blob']\n","\n","for p in required_packages: \n","  try:\n","      __import__(p)\n","  except ImportError:\n","      %pip install {p} --quiet\n","\n","import os\n","os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n","os.chdir(MY_HOME_ABS_PATH) # <------------------ ADDED\n","import math\n","import json\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","from pyspark.sql.functions import col\n","import pyspark.pandas as pd\n","from calendar import monthrange\n","from datetime import datetime\n","from io import BytesIO\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# Load locale custome modules\n","import sys\n","if IN_COLLAB:\n","  os.chdir(MY_HOME_ABS_PATH)\n","  sys.path.insert(0,os.path.abspath(\"./code/src/tools\"))\n","else:\n","  sys.path.append(os.path.abspath(\"./code/src/tools\"))\n","\n","from CloudIO.AzStorageClient import AzStorageClient\n","from data_pipeline_lib import *\n","\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.float_format', lambda x: '%.5f' % x)"]},{"cell_type":"markdown","metadata":{"id":"2IwvFVLFrtkM"},"source":["# Constant Definitions"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1676804775178,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"KXgevZgWrxiV"},"outputs":[],"source":["root_dir =  MY_HOME_ABS_PATH\n","tmp_dir =  root_dir + os.sep + '.tmp'\n","raw_data_dir = root_dir + os.sep + 'data'\n","data_dir = root_dir + os.sep + 'data/datasets'\n","cred_dir = root_dir + os.sep + '.cred'\n","az_cred_file = cred_dir + os.sep + 'azblobcred.json'\n","\n","if IN_COLLAB:\n","  raw_data_dir = \"/content/drive/MyDrive/CO2_flux_gpp_modeling/DS_capstone_23Spring_CO2/Data\"\n","\n","\n","\n","monthly_data_input_fname = data_dir + os.sep + 'data_monthly_v1_0.csv'\n","monthly_data_output_fname = raw_data_dir + os.sep + \"monthly-interpolated-v3.csv\"\n","\n","gap_fill_monthly = False\n","interpolate_na = False\n","\n","included_features= ['SITE_ID', 'year', 'month', 'TIMESTAMP',\n","                   'ESACCI-sm',    # ESACCI Soil Moisture (%)\n","                   'Percent_Snow', # Percentage of snow cover (%)\n","                   'NDWI',      # Normalized Different Water Index (NDWI)\n","                   'PET',       # Potential ET (m)\n","                   'MODIS_PFT', # Plant Function Type\n","                   'MODIS_LC',  # MODIS Land Cover\n","                   'Ts',        # Skin temperature (K) ??\n","                   'LST_Day',   # Daytime land surface temperature (K)\n","                   'LST_Night', # Nightime land surface temperature (K)\n","                   'Lai',       # Leaf Area Index (LAI)\n","                   'Fpar',      # Fraction of photosynthetically active radiation (fPAR)\n","                   'CSIF-SIFdaily', # All-sky daily average SIF\n","                   'BESS-PAR',      # Photosynthetic Active Radiation (PAR) (W/m^2)\n","                   'BESS-PARdiff',  # Diffuse PAR (W/m^2)\n","                   'BESS-RSDN'      # Shortwave downwelling radiation (W/m^2)\n","                   ]"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["class PrepareMonthlyData:\n","    def __init__(self, included_features, monthly_data_input_fname, interpolate_na=False, gap_fill_monthly=False):\n","        self.interpolate_na = interpolate_na\n","        self.gap_fill_monthly = gap_fill_monthly\n","        self.included_features =included_features\n","        self.monthly_data_input_fname = monthly_data_input_fname\n","        self.month_df = pd.read_csv(self.monthly_data_input_fname, usecols=self.included_features)\n","        self.month_df['date'] = pd.to_datetime(self.month_df['TIMESTAMP'],  format=\"%Y%m\")\n","\n","\n","    def to_datetime(self, row):\n","        return pd.to_datetime(f'{row.year}{row.month:02}', format='%Y%m')\n","\n","\n","    def gap_fill(self):\n","        # Resample to fill in missing month gaps, and interpolate values at site-level\n","        monthly_df = None  \n","\n","        # Loop through hourly site data to determine which months are present\n","        for i, s in tqdm(enumerate(self.month_df['SITE_ID'].unique())):\n","            try:\n","                site_file = f'data_full_half_hourly_raw_v0_1_{s}.csv'\n","                site_hr_df = pd.read_csv(f\"{tmp_dir}/{site_file}\", usecols=['SITE_ID', 'year', 'month'])\n","\n","                # Get set of year-months represented in site-hourly dataset\n","                site_hr_df.drop_duplicates(inplace=True)\n","                site_hr_df['datetime'] = site_hr_df.apply(self.to_datetime, axis=1)\n","\n","                # Get monthly data for site\n","                site_month = self.month_df[self.month_df['SITE_ID'] == s]\n","                site_month.reset_index(drop = True, inplace=True)\n","\n","                # Resample montlhly data to get the months required in hourly data\n","                pft = site_month['MODIS_PFT'][0] # retain PFT to fill new rows\n","                site_month = pd.merge(site_hr_df, site_month, how='left', on =['SITE_ID', 'year', 'month'])\n","\n","                # Fill in known values for new/resampled month-level rows\n","                site_month.set_index('datetime', inplace=True)\n","                #site_df['year'] = site_df.index.year.astype(int)\n","                #site_df['month'] = site_df.index.month.astype(int)\n","                site_month['MODIS_PFT'] = pft\n","                site_month['SITE_ID'] = s\n","                site_month.drop(columns='TIMESTAMP', inplace=True)\n","                site_month.drop(columns='date', inplace=True)\n","\n","                # If any new months added by resample, interpolate gap values at site-level\n","                if interpolate_na:\n","                    if site_month.isna().sum().sum() != 0: \n","                        site_month.interpolate(method='linear', limit_direction='both', inplace=True)\n","\n","                # Concat to monthly_df across sites\n","                if type(monthly_df) == type(None):\n","                    monthly_df = site_month\n","                else:\n","                    monthly_df = pd.concat([monthly_df, site_month])\n","\n","            except:\n","                continue\n","\n","        return monthly_df\n","\n","\n","    def run(self):\n","        # fill in missing months or leave it\n","        if self.gap_fill_monthly:\n","            monthly_df = self.gap_fill()\n","        else:\n","            monthly_df = self.month_df.copy()\n","\n","        # interpolate missing vals or fill w/ -1\n","        if monthly_df.isna().sum().sum() != 0: \n","            if self.interpolate_na:\n","                monthly_df.interpolate(method='linear', limit_direction='both', inplace=True)\n","            else:\n","                monthly_df = monthly_df.fillna(-1)\n","\n","        return monthly_df\n","        "]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["PrepMonthly = PrepareMonthlyData(included_features, monthly_data_input_fname, interpolate_na=False, gap_fill_monthly=False)                                \n","monthly_df_out = PrepMonthly.run()"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No NAS\n"]}],"source":["# Confirm No NAS\n","if monthly_df_out.isna().sum().sum() == 0:\n","    print(\"No NAS\")\n","else:\n","    monthly_df_out.isna().sum()\n","\n","# Save out\n","monthly_df_out.to_csv(monthly_data_output_fname)"]},{"cell_type":"markdown","metadata":{"id":"eHPfBKGasKAQ"},"source":["# Load Monthly Data"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":357,"status":"ok","timestamp":1676804775528,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"HiNBHf5HsC7c","outputId":"15c4fc27-3203-4e3d-e5e6-6b83a2320a1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["size:(19015, 20)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SITE_ID</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>TIMESTAMP</th>\n","      <th>BESS-PAR</th>\n","      <th>BESS-PARdiff</th>\n","      <th>BESS-RSDN</th>\n","      <th>CSIF-SIFdaily</th>\n","      <th>PET</th>\n","      <th>Ts</th>\n","      <th>ESACCI-sm</th>\n","      <th>MODIS_LC</th>\n","      <th>NDWI</th>\n","      <th>Percent_Snow</th>\n","      <th>Fpar</th>\n","      <th>Lai</th>\n","      <th>LST_Day</th>\n","      <th>LST_Night</th>\n","      <th>MODIS_PFT</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AR-SLu</td>\n","      <td>2010</td>\n","      <td>1</td>\n","      <td>201001</td>\n","      <td>154</td>\n","      <td>40</td>\n","      <td>336</td>\n","      <td>0.20432</td>\n","      <td>-0.01339</td>\n","      <td>302.46967</td>\n","      <td>0.15152</td>\n","      <td>7</td>\n","      <td>0.03542</td>\n","      <td>0.00000</td>\n","      <td>0.49000</td>\n","      <td>1.20000</td>\n","      <td>313.84000</td>\n","      <td>293.58000</td>\n","      <td>SH</td>\n","      <td>2010-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AR-SLu</td>\n","      <td>2010</td>\n","      <td>2</td>\n","      <td>201002</td>\n","      <td>120</td>\n","      <td>46</td>\n","      <td>258</td>\n","      <td>0.14553</td>\n","      <td>-0.00894</td>\n","      <td>298.78864</td>\n","      <td>0.16656</td>\n","      <td>7</td>\n","      <td>0.00040</td>\n","      <td>0.00000</td>\n","      <td>0.43000</td>\n","      <td>0.90000</td>\n","      <td>309.86000</td>\n","      <td>292.96000</td>\n","      <td>SH</td>\n","      <td>2010-02-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  SITE_ID  year  month  TIMESTAMP  BESS-PAR  BESS-PARdiff  BESS-RSDN  \\\n","0  AR-SLu  2010      1     201001       154            40        336   \n","1  AR-SLu  2010      2     201002       120            46        258   \n","\n","   CSIF-SIFdaily      PET        Ts  ESACCI-sm  MODIS_LC    NDWI  \\\n","0        0.20432 -0.01339 302.46967    0.15152         7 0.03542   \n","1        0.14553 -0.00894 298.78864    0.16656         7 0.00040   \n","\n","   Percent_Snow    Fpar     Lai   LST_Day  LST_Night MODIS_PFT       date  \n","0       0.00000 0.49000 1.20000 313.84000  293.58000        SH 2010-01-01  \n","1       0.00000 0.43000 0.90000 309.86000  292.96000        SH 2010-02-01  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Load monthly data\n","month_df = pd.read_csv(monthly_data_filename, usecols = included_features)\n","month_df['date'] = pd.to_datetime(month_df['TIMESTAMP'],  format=\"%Y%m\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get Site-Months from Hourly Data\n","Goal: Determine which months we need monthly data from. Ultimately left-merge into hourly data, so we only need months that are available in hourly"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def to_datetime(row):\n","        return pd.to_datetime(f'{row.year}{row.month:02}', format='%Y%m')"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["243it [00:43,  5.63it/s]\n"]}],"source":["def gap_fill():\n","    # Resample to fill in missing month gaps, and interpolate values at site-level\n","    monthly_df = None  \n","\n","    # Loop through hourly site data to determine which months are present\n","    for i, s in tqdm(enumerate(month_df['SITE_ID'].unique())):\n","        try:\n","            site_file = f'data_full_half_hourly_raw_v0_1_{s}.csv'\n","            site_hr_df = pd.read_csv(f\"{tmp_dir}/{site_file}\", usecols=['SITE_ID', 'year', 'month'])\n","\n","            # Get set of year-months represented in site-hourly dataset\n","            site_hr_df.drop_duplicates(inplace=True)\n","            site_hr_df['datetime'] = site_hr_df.apply(to_datetime, axis=1)\n","\n","            # Get monthly data for site\n","            site_month = month_df[month_df['SITE_ID'] == s]\n","            site_month.reset_index(drop = True, inplace=True)\n","\n","            # Resample montlhly data to get the months required in hourly data\n","            pft = site_month['MODIS_PFT'][0] # retain PFT to fill new rows\n","            site_month = pd.merge(site_hr_df, site_month, how='left', on =['SITE_ID', 'year', 'month'])\n","\n","            # Fill in known values for new/resampled month-level rows\n","            site_month.set_index('datetime', inplace=True)\n","            #site_df['year'] = site_df.index.year.astype(int)\n","            #site_df['month'] = site_df.index.month.astype(int)\n","            site_month['MODIS_PFT'] = pft\n","            site_month['SITE_ID'] = s\n","            site_month.drop(columns='TIMESTAMP', inplace=True)\n","            site_month.drop(columns='date', inplace=True)\n","\n","            # If any new months added by resample, interpolate gap values at site-level\n","            if interpolate_na:\n","                if site_month.isna().sum().sum() != 0: \n","                    site_month.interpolate(method='linear', limit_direction='both', inplace=True)\n","\n","            # Concat to monthly_df across sites\n","            if type(monthly_df) == type(None):\n","                monthly_df = site_month\n","            else:\n","                monthly_df = pd.concat([monthly_df, site_month])\n","\n","        except:\n","            continue\n","\n","    return monthly_df\n","\n","\n","\n","# fill in missing months or leave it\n","if gap_fill_monthly:\n","    monthly_df = gap_fill()\n","else:\n","    monthly_df = month_df.copy()\n","\n","# interpolate missing vals or fill w/ -1\n","if interpolate_na:\n","    if monthly_df.isna().sum().sum() != 0: \n","        monthly_df.interpolate(method='linear', limit_direction='both', inplace=True)\n","else:\n","    if monthly_df.isna().sum().sum() != 0: \n","        monthly_df = month_df.fillna(-1)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No NAS\n"]}],"source":["if monthly_df.isna().sum().sum() == 0:\n","    print(\"No NAS\")\n","else:\n","    monthly_df.isna().sum()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":383,"status":"ok","timestamp":1676804780785,"user":{"displayName":"Mary Chau","userId":"14027067063095206122"},"user_tz":480},"id":"9lae_PM4U0py"},"outputs":[],"source":["# Save interpolated monthly data checkpoint\n","#monthly_df.to_csv(interpolated_monthly_data_filename)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMksgG6dJySdU68N+q2MrXO","collapsed_sections":["4-mBiDcbrZ1f","nuowBABbrhti","eHPfBKGasKAQ"],"provenance":[]},"kernelspec":{"display_name":"src-rYFmMrY7-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"5cbe69e04c91e7625dfb8f223669796fe243b4d7c88cd4431379e3b6898fe927"}}},"nbformat":4,"nbformat_minor":0}
