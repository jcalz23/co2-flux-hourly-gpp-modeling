{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6072a929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from calendar import monthrange\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab73bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_dir =  os.path.abspath(os.getcwd()+\"..\\\\..\\\\..\\\\..\\\\..\\\\\")\n",
    "tmp_dir = root_dir + \"\\\\.tmp\"\n",
    "data_dir = root_dir + \"\\\\data\\\\\"\n",
    "\n",
    "site_metadata_filename = data_dir + \"site-metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5160f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"Golden\" Sites\n",
    "target_site = [\"US-MMS\", \"US-Vcp\", \"FR-Pue\", \"CH-Lae\", \"US-Var\", \"US-Ne2\", \"ES-LJu\", \"US-Ton\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a85c33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:(8, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>file</th>\n",
       "      <th>is_dup</th>\n",
       "      <th>IGBP</th>\n",
       "      <th>elevation</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>c4_percent</th>\n",
       "      <th>filename</th>\n",
       "      <th>size</th>\n",
       "      <th>country</th>\n",
       "      <th>record_count</th>\n",
       "      <th>site_IGBP</th>\n",
       "      <th>site_koppen</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>recorded_day_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>FR-Pue</td>\n",
       "      <td>FLUXNET</td>\n",
       "      <td>2000</td>\n",
       "      <td>2014</td>\n",
       "      <td>FLX_FR-Pue_FLUXNET2015_FULLSET_MM_2000-2014_2-...</td>\n",
       "      <td>False</td>\n",
       "      <td>EBF</td>\n",
       "      <td>270.0</td>\n",
       "      <td>43.74130</td>\n",
       "      <td>3.59570</td>\n",
       "      <td>...</td>\n",
       "      <td>6.59</td>\n",
       "      <td>data_full_half_hourly_raw_v0_1_FR-Pue.csv</td>\n",
       "      <td>109116169.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>245760.0</td>\n",
       "      <td>EBF</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2000-07-26 00:00:00</td>\n",
       "      <td>2014-12-31 23:30:00</td>\n",
       "      <td>5120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>US-Ne2</td>\n",
       "      <td>FLUXNET</td>\n",
       "      <td>2001</td>\n",
       "      <td>2013</td>\n",
       "      <td>FLX_US-Ne2_FLUXNET2015_FULLSET_MM_2001-2013_1-...</td>\n",
       "      <td>False</td>\n",
       "      <td>CRO</td>\n",
       "      <td>362.0</td>\n",
       "      <td>41.16487</td>\n",
       "      <td>-96.47010</td>\n",
       "      <td>...</td>\n",
       "      <td>48.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>US-Ton</td>\n",
       "      <td>FLUXNET</td>\n",
       "      <td>2001</td>\n",
       "      <td>2014</td>\n",
       "      <td>FLX_US-Ton_FLUXNET2015_FULLSET_MM_2001-2014_1-...</td>\n",
       "      <td>False</td>\n",
       "      <td>WSA</td>\n",
       "      <td>177.0</td>\n",
       "      <td>38.43160</td>\n",
       "      <td>-120.96598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>data_full_half_hourly_raw_v0_1_US-Ton.csv</td>\n",
       "      <td>103999932.0</td>\n",
       "      <td>US</td>\n",
       "      <td>230928.0</td>\n",
       "      <td>WSA</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2001-05-24 00:00:00</td>\n",
       "      <td>2014-12-31 23:30:00</td>\n",
       "      <td>4811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>US-Var</td>\n",
       "      <td>FLUXNET</td>\n",
       "      <td>2000</td>\n",
       "      <td>2014</td>\n",
       "      <td>FLX_US-Var_FLUXNET2015_FULLSET_MM_2000-2014_1-...</td>\n",
       "      <td>False</td>\n",
       "      <td>GRA</td>\n",
       "      <td>129.0</td>\n",
       "      <td>38.41330</td>\n",
       "      <td>-120.95070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>data_full_half_hourly_raw_v0_1_US-Var.csv</td>\n",
       "      <td>110098318.0</td>\n",
       "      <td>US</td>\n",
       "      <td>245712.0</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2000-11-01 00:00:00</td>\n",
       "      <td>2014-12-31 23:30:00</td>\n",
       "      <td>5119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>US-MMS</td>\n",
       "      <td>AmeriFlux</td>\n",
       "      <td>1999</td>\n",
       "      <td>2017</td>\n",
       "      <td>FLX_US-MMS_FLUXNET2015_FULLSET_MM_1999-2017_be...</td>\n",
       "      <td>True</td>\n",
       "      <td>DBF</td>\n",
       "      <td>275.0</td>\n",
       "      <td>39.32320</td>\n",
       "      <td>-86.41310</td>\n",
       "      <td>...</td>\n",
       "      <td>42.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>US-Vcp</td>\n",
       "      <td>AmeriFlux</td>\n",
       "      <td>2007</td>\n",
       "      <td>2017</td>\n",
       "      <td>FLX_US-Vcp_FLUXNET2015_FULLSET_MM_2007-2017_be...</td>\n",
       "      <td>False</td>\n",
       "      <td>ENF</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>35.86240</td>\n",
       "      <td>-106.59740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>data_full_half_hourly_raw_v0_1_US-Vcp.csv</td>\n",
       "      <td>72934242.0</td>\n",
       "      <td>US</td>\n",
       "      <td>174528.0</td>\n",
       "      <td>ENF</td>\n",
       "      <td>Cold</td>\n",
       "      <td>2007-01-01 00:00:00</td>\n",
       "      <td>2017-12-31 23:30:00</td>\n",
       "      <td>3636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>CH-Lae</td>\n",
       "      <td>ICOS2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2020</td>\n",
       "      <td>FLX_CH-Lae_FLUXNET2015_FULLSET_MM_2004-2020_be...</td>\n",
       "      <td>True</td>\n",
       "      <td>MF</td>\n",
       "      <td>689.0</td>\n",
       "      <td>47.47833</td>\n",
       "      <td>8.36439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>data_full_half_hourly_raw_v0_1_CH-Lae.csv</td>\n",
       "      <td>116210397.0</td>\n",
       "      <td>CH</td>\n",
       "      <td>288384.0</td>\n",
       "      <td>MF</td>\n",
       "      <td>Cold</td>\n",
       "      <td>2004-04-09 00:00:00</td>\n",
       "      <td>2020-12-17 23:30:00</td>\n",
       "      <td>6008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>ES-LJu</td>\n",
       "      <td>ICOS2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2020</td>\n",
       "      <td>FLX_ES-LJu_FLUXNET2015_FULLSET_MM_2004-2020_be...</td>\n",
       "      <td>True</td>\n",
       "      <td>OSH</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>36.92659</td>\n",
       "      <td>-2.75212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>data_full_half_hourly_raw_v0_1_ES-LJu.csv</td>\n",
       "      <td>111661016.0</td>\n",
       "      <td>ES</td>\n",
       "      <td>239616.0</td>\n",
       "      <td>OSH</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2004-05-26 00:00:00</td>\n",
       "      <td>2020-12-31 23:30:00</td>\n",
       "      <td>4992.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    site_id    dataset  start_year  end_year  \\\n",
       "67   FR-Pue    FLUXNET        2000      2014   \n",
       "119  US-Ne2    FLUXNET        2001      2013   \n",
       "127  US-Ton    FLUXNET        2001      2014   \n",
       "130  US-Var    FLUXNET        2000      2014   \n",
       "181  US-MMS  AmeriFlux        1999      2017   \n",
       "206  US-Vcp  AmeriFlux        2007      2017   \n",
       "219  CH-Lae   ICOS2020        2004      2020   \n",
       "244  ES-LJu   ICOS2020        2004      2020   \n",
       "\n",
       "                                                  file  is_dup IGBP  \\\n",
       "67   FLX_FR-Pue_FLUXNET2015_FULLSET_MM_2000-2014_2-...   False  EBF   \n",
       "119  FLX_US-Ne2_FLUXNET2015_FULLSET_MM_2001-2013_1-...   False  CRO   \n",
       "127  FLX_US-Ton_FLUXNET2015_FULLSET_MM_2001-2014_1-...   False  WSA   \n",
       "130  FLX_US-Var_FLUXNET2015_FULLSET_MM_2000-2014_1-...   False  GRA   \n",
       "181  FLX_US-MMS_FLUXNET2015_FULLSET_MM_1999-2017_be...    True  DBF   \n",
       "206  FLX_US-Vcp_FLUXNET2015_FULLSET_MM_2007-2017_be...   False  ENF   \n",
       "219  FLX_CH-Lae_FLUXNET2015_FULLSET_MM_2004-2020_be...    True   MF   \n",
       "244  FLX_ES-LJu_FLUXNET2015_FULLSET_MM_2004-2020_be...    True  OSH   \n",
       "\n",
       "     elevation       lat       long  ... c4_percent  \\\n",
       "67       270.0  43.74130    3.59570  ...       6.59   \n",
       "119      362.0  41.16487  -96.47010  ...      48.91   \n",
       "127      177.0  38.43160 -120.96598  ...       0.00   \n",
       "130      129.0  38.41330 -120.95070  ...       0.00   \n",
       "181      275.0  39.32320  -86.41310  ...      42.28   \n",
       "206     2542.0  35.86240 -106.59740  ...       0.04   \n",
       "219      689.0  47.47833    8.36439  ...       0.00   \n",
       "244     1600.0  36.92659   -2.75212  ...       0.00   \n",
       "\n",
       "                                      filename         size country  \\\n",
       "67   data_full_half_hourly_raw_v0_1_FR-Pue.csv  109116169.0      FR   \n",
       "119                                        NaN          NaN     NaN   \n",
       "127  data_full_half_hourly_raw_v0_1_US-Ton.csv  103999932.0      US   \n",
       "130  data_full_half_hourly_raw_v0_1_US-Var.csv  110098318.0      US   \n",
       "181                                        NaN          NaN     NaN   \n",
       "206  data_full_half_hourly_raw_v0_1_US-Vcp.csv   72934242.0      US   \n",
       "219  data_full_half_hourly_raw_v0_1_CH-Lae.csv  116210397.0      CH   \n",
       "244  data_full_half_hourly_raw_v0_1_ES-LJu.csv  111661016.0      ES   \n",
       "\n",
       "    record_count site_IGBP  site_koppen           start_time  \\\n",
       "67      245760.0       EBF    Temperate  2000-07-26 00:00:00   \n",
       "119          NaN       NaN          NaN                  NaN   \n",
       "127     230928.0       WSA    Temperate  2001-05-24 00:00:00   \n",
       "130     245712.0       GRA    Temperate  2000-11-01 00:00:00   \n",
       "181          NaN       NaN          NaN                  NaN   \n",
       "206     174528.0       ENF         Cold  2007-01-01 00:00:00   \n",
       "219     288384.0        MF         Cold  2004-04-09 00:00:00   \n",
       "244     239616.0       OSH    Temperate  2004-05-26 00:00:00   \n",
       "\n",
       "                end_time recorded_day_count  \n",
       "67   2014-12-31 23:30:00             5120.0  \n",
       "119                  NaN                NaN  \n",
       "127  2014-12-31 23:30:00             4811.0  \n",
       "130  2014-12-31 23:30:00             5119.0  \n",
       "181                  NaN                NaN  \n",
       "206  2017-12-31 23:30:00             3636.0  \n",
       "219  2020-12-17 23:30:00             6008.0  \n",
       "244  2020-12-31 23:30:00             4992.0  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Site data\n",
    "site_metadata_df = pd.read_csv(site_metadata_filename)\n",
    "\n",
    "# only focus on target sites\n",
    "site_metadata_df= site_metadata_df.loc[site_metadata_df['site_id'].isin(target_site)]\n",
    "print(f\"size:{site_metadata_df.shape}\")\n",
    "site_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f6c0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_min_max(df):\n",
    "    return (df.min(), df.max())\n",
    "\n",
    "def get_min_max_datetime(df):\n",
    "    return (pd.to_datetime(df).min(), pd.to_datetime(df).max())\n",
    "\n",
    "def is_leap_year(year):\n",
    "    return year%4 == 0 ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ac242",
   "metadata": {},
   "source": [
    "# Process a sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbc9f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_full_half_hourly_raw_v0_1_ES-LJu.csv\n"
     ]
    }
   ],
   "source": [
    "r = site_metadata_df[['site_id','filename']].iloc[-1]\n",
    "print(r.filename)\n",
    "local_filename = tmp_dir + \"\\\\\" + r.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f39f2013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:(239616, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "      <th>GPP_NT_VUT_REF</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200405260000</td>\n",
       "      <td>200405260030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-05-26 00:00:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>ES-LJu</td>\n",
       "      <td>2004-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200405260030</td>\n",
       "      <td>200405260100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-05-26 00:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>ES-LJu</td>\n",
       "      <td>2004-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200405260100</td>\n",
       "      <td>200405260130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-05-26 01:00:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>ES-LJu</td>\n",
       "      <td>2004-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200405260130</td>\n",
       "      <td>200405260200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-05-26 01:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>ES-LJu</td>\n",
       "      <td>2004-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200405260200</td>\n",
       "      <td>200405260230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-05-26 02:00:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>ES-LJu</td>\n",
       "      <td>2004-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIMESTAMP_START  TIMESTAMP_END  GPP_NT_VUT_REF            datetime  year  \\\n",
       "0     200405260000   200405260030             NaN 2004-05-26 00:00:00  2004   \n",
       "1     200405260030   200405260100             NaN 2004-05-26 00:30:00  2004   \n",
       "2     200405260100   200405260130             NaN 2004-05-26 01:00:00  2004   \n",
       "3     200405260130   200405260200             NaN 2004-05-26 01:30:00  2004   \n",
       "4     200405260200   200405260230             NaN 2004-05-26 02:00:00  2004   \n",
       "\n",
       "   month  day  hour SITE_ID        date  \n",
       "0      5   26     0  ES-LJu  2004-05-26  \n",
       "1      5   26     0  ES-LJu  2004-05-26  \n",
       "2      5   26     1  ES-LJu  2004-05-26  \n",
       "3      5   26     1  ES-LJu  2004-05-26  \n",
       "4      5   26     2  ES-LJu  2004-05-26  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['SITE_ID','TIMESTAMP_START', 'TIMESTAMP_END', 'datetime', 'date', 'year', 'month', 'day', 'hour',\"GPP_NT_VUT_REF\"]\n",
    "site_df = pd.read_csv(local_filename, usecols=features)\n",
    "site_df['datetime'] = pd.to_datetime(site_df['datetime'])\n",
    "print(f\"size:{site_df.shape}\")\n",
    "site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efb3924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES-LJu\n",
      "TIMESTAMP_START       0\n",
      "TIMESTAMP_END         0\n",
      "GPP_NT_VUT_REF     8880\n",
      "datetime              0\n",
      "year                  0\n",
      "month                 0\n",
      "day                   0\n",
      "hour                  0\n",
      "SITE_ID               0\n",
      "date                  0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# is there NA\n",
    "if site_df.isna().sum().sum() != 0:\n",
    "    print(f'{site_df.SITE_ID.iloc[0]}\\n{site_df.isna().sum()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6edd75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def has_full_month_record(year, month, actual_record_count):\n",
    "    if actual_record_count == 0:\n",
    "        return False\n",
    "    \n",
    "    expected_days = monthrange(year, month)\n",
    "    expected_record_count = expected_days[1]*48\n",
    "    if(expected_record_count != actual_record_count):\n",
    "        #print(f\"  {month:2}: expected-[{expected_record_count}], actual-[{actual_record_count}]\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def has_full_day_record(year, month, day, actual_record_count):\n",
    "    if actual_record_count == 0:\n",
    "        #print(f\"    {month}/{day}: none\")\n",
    "        return False\n",
    "    \n",
    "    expected_record_count = 48\n",
    "    if(expected_record_count != actual_record_count):\n",
    "        print(f\"    {month}/{day}: expected-[{expected_record_count}], actual-[{actual_record_count}]\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def plot_month_records(site_id, year, month, df):\n",
    "    df.plot.bar(x='datetime', y='GPP_NT_VUT_REF', \n",
    "                    title=f'{site_id}:{year}.{month}',\n",
    "                    figsize= (16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e7211c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FULL_YEAR_DATA_COUNT = 2*24*365 #17520\n",
    "LEAP_YEAR_DATA_COUNT = 2*24*366 #17568\n",
    "\n",
    "def get_gaps(site_df):\n",
    "    start_year, end_year = get_min_max(site_df['year'])\n",
    "    gap_start = None\n",
    "    for y in range(start_year, end_year+1):\n",
    "        year_df = site_df.loc[site_df['year'] == y]\n",
    "\n",
    "        start_date, end_date = get_min_max_datetime(year_df['datetime'])\n",
    "        date_delta = (end_date - start_date)\n",
    "        \n",
    "        if (not is_leap_year(y) and year_df.shape[0] != FULL_YEAR_DATA_COUNT) or\\\n",
    "        (is_leap_year(y) and year_df.shape[0] != LEAP_YEAR_DATA_COUNT):\n",
    "            print(f\"{y}: {year_df.shape[0]} ({date_delta}) {'Leap' if is_leap_year(y) else ''}\")\n",
    "            for m in range(1,13):\n",
    "                month_df = year_df.loc[year_df['month'] == m]\n",
    "                if month_df.shape[0] == 0:\n",
    "                    #print(f\"  {m:2}: none\")\n",
    "                    if gap_start == None:\n",
    "                        gap_start = f\"{y}/{m}/1\"\n",
    "                elif has_full_month_record(y, m, month_df.shape[0]):\n",
    "                    if gap_start != None:\n",
    "                        if m-1 > 1:\n",
    "                            print(f\"    gap:{gap_start} - {y}/{m-1}/{monthrange(y, m-1)[1]}\")\n",
    "                        else:\n",
    "                            print(f\"    gap:{gap_start} - {y-1}/12/31\")\n",
    "                        gap_start = None\n",
    "                else:\n",
    "                    for d in range(1, monthrange(y, m)[1]+1):\n",
    "                        day_df = month_df.loc[month_df['day'] == d]\n",
    "                        if has_full_day_record(y, m, d, day_df.shape[0]):\n",
    "                            if gap_start != None:\n",
    "                                print(f\"    gap: {gap_start} - {y}/{m}/{d-1}\")\n",
    "                                gap_start = None\n",
    "                        elif gap_start == None:\n",
    "                            gap_start = f\"{y}/{m}/{d}\"\n",
    "        elif gap_start != None:\n",
    "            print(f\"    gap:{gap_start} - {y-1}/12/31\")\n",
    "            gap_start = None\n",
    "            \n",
    "    if gap_start != None:\n",
    "        print(f\"    gap:{gap_start} - {site_df['date'].max()}\")\n",
    "        gap_start = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9fab9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004: 8880 (219 days 23:30:00) Leap\n",
      "    gap: 2004/1/1 - 2004/5/25\n",
      "    gap: 2004/7/15 - 2004/7/29\n",
      "    gap: 2004/12/5 - 2004/12/24\n",
      "2005: 9216 (364 days 23:30:00) \n",
      "    gap: 2005/1/7 - 2005/6/17\n",
      "    gap: 2005/7/31 - 2005/8/10\n",
      "2006: 14208 (364 days 23:30:00) \n",
      "    gap: 2006/3/25 - 2006/4/5\n",
      "    gap: 2006/7/16 - 2006/7/27\n",
      "    gap: 2006/11/6 - 2006/12/20\n",
      "2007: 13632 (364 days 23:30:00) \n",
      "    gap: 2007/1/12 - 2007/2/15\n",
      "    gap: 2007/10/31 - 2007/11/21\n",
      "    gap: 2007/11/30 - 2007/12/23\n",
      "2008: 14976 (365 days 23:30:00) Leap\n",
      "    gap: 2008/1/16 - 2008/2/17\n",
      "    gap: 2008/11/21 - 2008/12/11\n",
      "2009: 17040 (364 days 23:30:00) \n",
      "    gap: 2009/11/26 - 2009/12/5\n",
      "2010: 15216 (364 days 23:30:00) \n",
      "    gap: 2010/1/29 - 2010/3/17\n",
      "2012: 17520 (364 days 23:30:00) Leap\n",
      "2013: 17088 (355 days 23:30:00) \n",
      "    gap: 2012/12/31 - 2013/1/9\n",
      "2015: 15072 (364 days 23:30:00) \n",
      "    gap: 2015/2/3 - 2015/3/25\n",
      "2016: 16128 (335 days 23:30:00) Leap\n",
      "2017: 9504 (277 days 23:30:00) \n",
      "    gap: 2016/12/2 - 2017/3/28\n",
      "    gap: 2017/5/9 - 2017/5/23\n",
      "    gap: 2017/7/27 - 2017/8/8\n",
      "    gap: 2017/10/12 - 2017/12/2\n",
      "2018: 14640 (364 days 23:30:00) \n",
      "    gap: 2018/9/26 - 2018/11/24\n",
      "2019: 5760 (364 days 23:30:00) \n",
      "    gap: 2019/1/28 - 2019/3/11\n",
      "    gap: 2019/5/15 - 2019/6/25\n",
      "    gap: 2019/7/6 - 2019/12/12\n",
      "2020: 15696 (365 days 23:30:00) Leap\n",
      "    gap: 2020/7/8 - 2020/8/3\n",
      "    gap: 2020/9/4 - 2020/9/15\n"
     ]
    }
   ],
   "source": [
    "get_gaps(site_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf67c54",
   "metadata": {},
   "source": [
    "# Process all \"golden files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e93079",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FR-Pue\n",
      "2000: 6432 (158 days 23:30:00) Leap\n",
      "    gap: 2000/1/1 - 2000/7/25\n",
      "    gap: 2000/9/12 - 2000/9/23\n",
      "    gap: 2000/11/16 - 2000/11/28\n",
      "2009: 16800 (364 days 23:30:00) \n",
      "    gap: 2009/8/18 - 2009/9/1\n",
      "2010: 16416 (364 days 23:30:00) \n",
      "    gap: 2010/6/29 - 2010/7/8\n",
      "    gap: 2010/12/6 - 2010/12/18\n",
      "2011: 16224 (364 days 23:30:00) \n",
      "    gap:2011/8/5 - 2011/8/31\n",
      "2012: 14592 (365 days 23:30:00) Leap\n",
      "    gap: 2012/1/9 - 2012/3/10\n",
      "\n",
      "ERROR: US-Ne2 is mssing hourly data.\n",
      "\n",
      "US-Ton\n",
      "2001: 10656 (221 days 23:30:00) \n",
      "    gap: 2001/1/1 - 2001/5/23\n",
      "2004: 15408 (365 days 23:30:00) Leap\n",
      "    gap: 2004/5/23 - 2004/7/6\n",
      "2007: 15168 (364 days 23:30:00) \n",
      "    gap: 2007/1/15 - 2007/2/22\n",
      "    gap: 2007/6/3 - 2007/6/12\n",
      "2010: 17136 (356 days 23:30:00) \n",
      "2011: 16368 (361 days 23:30:00) \n",
      "    gap: 2010/12/24 - 2011/1/3\n",
      "    gap: 2011/1/11 - 2011/1/21\n",
      "    gap: 2011/4/3 - 2011/4/12\n",
      "2013: 15936 (364 days 23:30:00) \n",
      "    gap: 2013/4/25 - 2013/5/27\n",
      "\n",
      "US-Var\n",
      "2000: 2928 (60 days 23:30:00) Leap\n",
      "    gap:2000/1/1 - 2000/10/31\n",
      "2005: 15648 (364 days 23:30:00) \n",
      "    gap: 2005/1/3 - 2005/2/10\n",
      "2010: 16752 (364 days 23:30:00) \n",
      "    gap: 2010/3/25 - 2010/4/9\n",
      "\n",
      "ERROR: US-MMS is mssing hourly data.\n",
      "\n",
      "US-Vcp\n",
      "2007: 16272 (364 days 23:30:00) \n",
      "    gap: 2007/5/31 - 2007/6/25\n",
      "2008: 13776 (365 days 23:30:00) Leap\n",
      "    gap: 2008/5/2 - 2008/6/6\n",
      "    gap: 2008/9/23 - 2008/11/4\n",
      "2009: 15840 (364 days 23:30:00) \n",
      "    gap: 2009/5/24 - 2009/6/27\n",
      "2010: 15984 (364 days 23:30:00) \n",
      "    gap: 2010/3/6 - 2010/4/6\n",
      "2011: 16512 (364 days 23:30:00) \n",
      "    gap: 2011/1/2 - 2011/1/11\n",
      "    gap: 2011/7/7 - 2011/7/17\n",
      "2013: 12864 (364 days 23:30:00) \n",
      "    gap: 2013/5/31 - 2013/8/6\n",
      "    gap: 2013/11/29 - 2013/12/17\n",
      "    gap: 2013/12/19 - 2013/12/28\n",
      "2015: 15216 (364 days 23:30:00) \n",
      "    gap: 2015/9/16 - 2015/11/2\n",
      "2016: 16416 (365 days 23:30:00) Leap\n",
      "    gap: 2016/1/12 - 2016/1/21\n",
      "    gap: 2016/11/2 - 2016/11/15\n",
      "2017: 16560 (364 days 23:30:00) \n",
      "    gap: 2017/11/13 - 2017/12/2\n",
      "\n",
      "CH-Lae\n",
      "2004: 12816 (266 days 23:30:00) Leap\n",
      "    gap: 2004/1/1 - 2004/4/8\n",
      "2012: 17088 (365 days 23:30:00) Leap\n",
      "    gap: 2012/11/15 - 2012/11/24\n",
      "2017: 17040 (354 days 23:30:00) \n",
      "2018: 16224 (356 days 23:30:00) \n",
      "    gap: 2017/12/22 - 2018/1/8\n",
      "    gap: 2018/5/20 - 2018/6/7\n",
      "2019: 16224 (364 days 23:30:00) \n",
      "    gap: 2019/9/1 - 2019/9/11\n",
      "    gap: 2019/11/4 - 2019/11/19\n",
      "2020: 16176 (351 days 23:30:00) Leap\n",
      "    gap: 2020/8/2 - 2020/8/16\n",
      "    gap:2020/12/18 - 2020-12-17\n",
      "\n",
      "ES-LJu\n",
      "TIMESTAMP_START       0\n",
      "TIMESTAMP_END         0\n",
      "GPP_NT_VUT_REF     8880\n",
      "datetime              0\n",
      "year                  0\n",
      "month                 0\n",
      "day                   0\n",
      "hour                  0\n",
      "SITE_ID               0\n",
      "date                  0\n",
      "dtype: int64\n",
      "\n",
      "2005: 9216 (364 days 23:30:00) \n",
      "    gap: 2005/1/7 - 2005/6/17\n",
      "    gap: 2005/7/31 - 2005/8/10\n",
      "2006: 14208 (364 days 23:30:00) \n",
      "    gap: 2006/3/25 - 2006/4/5\n",
      "    gap: 2006/7/16 - 2006/7/27\n",
      "    gap: 2006/11/6 - 2006/12/20\n",
      "2007: 13632 (364 days 23:30:00) \n",
      "    gap: 2007/1/12 - 2007/2/15\n",
      "    gap: 2007/10/31 - 2007/11/21\n",
      "    gap: 2007/11/30 - 2007/12/23\n",
      "2008: 14976 (365 days 23:30:00) Leap\n",
      "    gap: 2008/1/16 - 2008/2/17\n",
      "    gap: 2008/11/21 - 2008/12/11\n",
      "2009: 17040 (364 days 23:30:00) \n",
      "    gap: 2009/11/26 - 2009/12/5\n",
      "2010: 15216 (364 days 23:30:00) \n",
      "    gap: 2010/1/29 - 2010/3/17\n",
      "2012: 17520 (364 days 23:30:00) Leap\n",
      "2013: 17088 (355 days 23:30:00) \n",
      "    gap: 2012/12/31 - 2013/1/9\n",
      "2015: 15072 (364 days 23:30:00) \n",
      "    gap: 2015/2/3 - 2015/3/25\n",
      "2016: 16128 (335 days 23:30:00) Leap\n",
      "2017: 9504 (277 days 23:30:00) \n",
      "    gap: 2016/12/2 - 2017/3/28\n",
      "    gap: 2017/5/9 - 2017/5/23\n",
      "    gap: 2017/7/27 - 2017/8/8\n",
      "    gap: 2017/10/12 - 2017/12/2\n",
      "2018: 14640 (364 days 23:30:00) \n",
      "    gap: 2018/9/26 - 2018/11/24\n",
      "2019: 5760 (364 days 23:30:00) \n",
      "    gap: 2019/1/28 - 2019/3/11\n",
      "    gap: 2019/5/15 - 2019/6/25\n",
      "    gap: 2019/7/6 - 2019/12/12\n",
      "2020: 15696 (365 days 23:30:00) Leap\n",
      "    gap: 2020/7/8 - 2020/8/3\n",
      "    gap: 2020/9/4 - 2020/9/15\n"
     ]
    }
   ],
   "source": [
    "# Iterate through sites\n",
    "features = ['SITE_ID','TIMESTAMP_START', 'TIMESTAMP_END', 'datetime', 'date', 'year', 'month', 'day', 'hour', 'GPP_NT_VUT_REF']\n",
    "for i, r in site_metadata_df[['site_id','filename']].iterrows():\n",
    "    if not r.filename or type(r.filename) != type(\"\"):\n",
    "        print(f'\\nERROR: {r.site_id} is mssing hourly data.')\n",
    "        continue\n",
    "\n",
    "    local_filename = tmp_dir + \"\\\\\" + r.filename\n",
    "    site_df = pd.read_csv(local_filename, usecols=features)\n",
    "    site_df['datetime'] = pd.to_datetime(site_df['datetime'])\n",
    "    \n",
    "    print(f\"\\n{r.site_id}\")\n",
    "    if site_df.isna().sum().sum() != 0:\n",
    "        print(f'{site_df.isna().sum()}\\n')\n",
    "        site_df.dropna(inplace=True)\n",
    "    \n",
    "    get_gaps(site_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
