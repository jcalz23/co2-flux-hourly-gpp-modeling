2023-04-01 18:58:38.078303: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.2023-04-01 18:58:38.080642: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.2023-04-01 18:58:38.126575: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.2023-04-01 18:58:38.127051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.2023-04-01 18:58:38.798198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRTGlobal seed set to 42Global seed set to 42GPU available: True (cuda), used: TrueTPU available: False, using: 0 TPU coresIPU available: False, using: 0 IPUsHPU available: False, using: 0 HPUs[rank: 0] Global seed set to 42Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/42023-04-01 18:59:27.786754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT2023-04-01 18:59:27.786785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT2023-04-01 18:59:27.793824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[rank: 1] Global seed set to 42[rank: 3] Global seed set to 42[rank: 2] Global seed set to 42[rank: 1] Global seed set to 42[rank: 2] Global seed set to 42[rank: 3] Global seed set to 42[rank: 2] Global seed set to 42Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4[rank: 1] Global seed set to 42Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4[rank: 3] Global seed set to 42Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4----------------------------------------------------------------------------------------------------distributed_backend=ncclAll distributed processes registered. Starting with 4 processes----------------------------------------------------------------------------------------------------LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]   | Name                               | Type                            | Params----------------------------------------------------------------------------------------0  | loss                               | QuantileLoss                    | 0     1  | logging_metrics                    | ModuleList                      | 0     2  | input_embeddings                   | MultiEmbedding                  | 403   3  | prescalers                         | ModuleDict                      | 1.0 K 4  | static_variable_selection          | VariableSelectionNetwork        | 868   5  | encoder_variable_selection         | VariableSelectionNetwork        | 211 K 6  | decoder_variable_selection         | VariableSelectionNetwork        | 192 K 7  | static_context_variable_selection  | GatedResidualNetwork            | 74.8 K8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 74.8 K9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 74.8 K10 | static_context_enrichment          | GatedResidualNetwork            | 74.8 K11 | lstm_encoder                       | LSTM                            | 149 K 12 | lstm_decoder                       | LSTM                            | 149 K 13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 37.3 K14 | post_lstm_add_norm_encoder         | AddNorm                         | 272   15 | static_enrichment                  | GatedResidualNetwork            | 93.3 K16 | multihead_attn                     | InterpretableMultiHeadAttention | 74.4 K17 | post_attn_gate_norm                | GateAddNorm                     | 37.5 K18 | pos_wise_ff                        | GatedResidualNetwork            | 74.8 K19 | pre_output_gate_norm               | GateAddNorm                     | 37.5 K20 | output_layer                       | Linear                          | 959   ----------------------------------------------------------------------------------------1.4 M     Trainable params0         Non-trainable params1.4 M     Total params5.432     Total estimated model params size (MB)Data size: (4862712, 52)Data Columns: Index(['GPP_NT_VUT_REF', 'site_id', 'timestep_idx_local',       'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day',       'hour', 'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA',       'PA_ERA', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',       'b7', 'IGBP', 'lat', 'long', 'koppen_sub', 'koppen_main', 'c3c4',       'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily',       'PET', 'Ts', 'ESACCI-sm', 'MODIS_LC', 'NDWI', 'Percent_Snow', 'Fpar',       'Lai', 'LST_Day', 'LST_Night', 'MODIS_IGBP', 'MODIS_PFT',       'gap_flag_hour', 'gap_flag_month', 'rfr_pred_gpp'],      dtype='object')NA count: 0Experiment logs saved to /root/co2-flux-hourly-gpp-modeling/data/models/treeft_5YrTrain_1WkEncode_RFRGPP_slimFeatures_230401_1858.Number of parameters in network: 1357.9kSanity Checking: 0it [00:00, ?it/s]Data size: (4862712, 52)Data Columns: Index(['GPP_NT_VUT_REF', 'site_id', 'timestep_idx_local',       'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day',       'hour', 'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA',       'PA_ERA', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',       'b7', 'IGBP', 'lat', 'long', 'koppen_sub', 'koppen_main', 'c3c4',       'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily',       'PET', 'Ts', 'ESACCI-sm', 'MODIS_LC', 'NDWI', 'Percent_Snow', 'Fpar',       'Lai', 'LST_Day', 'LST_Night', 'MODIS_IGBP', 'MODIS_PFT',       'gap_flag_hour', 'gap_flag_month', 'rfr_pred_gpp'],      dtype='object')NA count: 0Experiment logs saved to /root/co2-flux-hourly-gpp-modeling/data/models/treeft_5YrTrain_1WkEncode_RFRGPP_slimFeatures_230401_1859.Number of parameters in network: 1357.9kData size: (4862712, 52)Data Columns: Index(['GPP_NT_VUT_REF', 'site_id', 'timestep_idx_local',       'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day',       'hour', 'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA',       'PA_ERA', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',       'b7', 'IGBP', 'lat', 'long', 'koppen_sub', 'koppen_main', 'c3c4',       'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily',       'PET', 'Ts', 'ESACCI-sm', 'MODIS_LC', 'NDWI', 'Percent_Snow', 'Fpar',       'Lai', 'LST_Day', 'LST_Night', 'MODIS_IGBP', 'MODIS_PFT',       'gap_flag_hour', 'gap_flag_month', 'rfr_pred_gpp'],      dtype='object')NA count: 0Experiment logs saved to /root/co2-flux-hourly-gpp-modeling/data/models/treeft_5YrTrain_1WkEncode_RFRGPP_slimFeatures_230401_1859.Number of parameters in network: 1357.9kData size: (4862712, 52)Data Columns: Index(['GPP_NT_VUT_REF', 'site_id', 'timestep_idx_local',       'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day',       'hour', 'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA',       'PA_ERA', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',       'b7', 'IGBP', 'lat', 'long', 'koppen_sub', 'koppen_main', 'c3c4',       'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily',       'PET', 'Ts', 'ESACCI-sm', 'MODIS_LC', 'NDWI', 'Percent_Snow', 'Fpar',       'Lai', 'LST_Day', 'LST_Night', 'MODIS_IGBP', 'MODIS_PFT',       'gap_flag_hour', 'gap_flag_month', 'rfr_pred_gpp'],      dtype='object')NA count: 0Experiment logs saved to /root/co2-flux-hourly-gpp-modeling/data/models/treeft_5YrTrain_1WkEncode_RFRGPP_slimFeatures_230401_1859.Number of parameters in network: 1357.9kSanity Checking:   0%|                                                                                                                                                                                                       | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 1/2 [00:00<00:00,  1.21it/s]Sanity Checking DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.92it/s]                                                                                                                                                                                                                                               Training: 0it [00:00, ?it/s]Training:   0%|                                                                                                                                                                                                           | 0/7545 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                                                                                                                                            | 0/7545 [00:00<?, ?it/s][W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())Epoch 0:   0%|                                                                                                                                                      | 1/7545 [00:06<12:38:03,  6.03s/it, loss=2.87, v_num=4, train_loss_step=2.870]Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2055/2055 [07:14<00:00,  4.72it/s]Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7545/7545 [54:53<00:00,  2.29it/s, loss=0.867, v_num=4, train_loss_step=0.812, val_loss=1.160, train_loss_epoch=0.927]Epoch 1:   0%|                                                                                                             | 1/7545 [00:05<11:19:49,  5.41s/it, loss=0.867, v_num=4, train_loss_step=0.812, val_loss=1.160, train_loss_epoch=0.927]Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2055/2055 [07:12<00:00,  4.76it/s]Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7545/7545 [54:53<00:00,  2.29it/s, loss=0.751, v_num=4, train_loss_step=0.758, val_loss=1.200, train_loss_epoch=0.835]Epoch 2:   0%|                                                                                                             | 1/7545 [00:05<11:43:19,  5.59s/it, loss=0.751, v_num=4, train_loss_step=0.758, val_loss=1.200, train_loss_epoch=0.835]Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2055/2055 [07:15<00:00,  4.72it/s]Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7545/7545 [55:48<00:00,  2.25it/s, loss=0.812, v_num=4, train_loss_step=0.852, val_loss=1.210, train_loss_epoch=0.802]Epoch 3:   0%|                                                                                                             | 1/7545 [00:05<11:40:59,  5.58s/it, loss=0.812, v_num=4, train_loss_step=0.852, val_loss=1.210, train_loss_epoch=0.802]Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2055/2055 [07:15<00:00,  4.72it/s]Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7545/7545 [54:55<00:00,  2.29it/s, loss=0.741, v_num=4, train_loss_step=0.681, val_loss=1.250, train_loss_epoch=0.782]Epoch 4:   0%|                                                                                                             | 1/7545 [00:05<11:34:02,  5.52s/it, loss=0.741, v_num=4, train_loss_step=0.681, val_loss=1.250, train_loss_epoch=0.782]Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2055/2055 [07:16<00:00,  4.71it/s]Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7545/7545 [54:54<00:00,  2.29it/s, loss=0.746, v_num=4, train_loss_step=0.734, val_loss=1.220, train_loss_epoch=0.765]Epoch 5:   0%|                                                                                                             | 1/7545 [00:05<11:31:18,  5.50s/it, loss=0.746, v_num=4, train_loss_step=0.734, val_loss=1.220, train_loss_epoch=0.765]Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2055/2055 [07:23<00:00,  4.63it/s]Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7545/7545 [56:18<00:00,  2.23it/s, loss=0.801, v_num=4, train_loss_step=0.864, val_loss=1.250, train_loss_epoch=0.739]Epoch 6:   0%|                                                                                                             | 1/7545 [00:06<13:38:24,  6.51s/it, loss=0.801, v_num=4, train_loss_step=0.864, val_loss=1.250, train_loss_epoch=0.739]Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2055/2055 [07:24<00:00,  4.63it/s]Epoch 6: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7545/7545 [59:59<00:00,  2.10it/s, loss=0.733, v_num=4, train_loss_step=0.809, val_loss=1.270, train_loss_epoch=0.733]Training time: 23515.272236694Best model path: /root/co2-flux-hourly-gpp-modeling/data/models/treeft_5YrTrain_1WkEncode_RFRGPP_slimFeatures_230401_1859/version_0/checkpoints/epoch=6-step=38430.ckptSaved model to /root/co2-flux-hourly-gpp-modeling/data/models/treeft_5YrTrain_1WkEncode_RFRGPP_slimFeatures_230401_1859/model.pth