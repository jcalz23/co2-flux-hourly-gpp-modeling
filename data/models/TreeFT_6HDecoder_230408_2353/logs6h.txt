2023-04-08 23:52:47.382050: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.2023-04-08 23:52:47.386891: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.2023-04-08 23:52:47.485071: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.2023-04-08 23:52:47.487140: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.2023-04-08 23:52:49.325708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRTGlobal seed set to 42Global seed set to 42GPU available: True (cuda), used: TrueTPU available: False, using: 0 TPU coresIPU available: False, using: 0 IPUsHPU available: False, using: 0 HPUs[rank: 0] Global seed set to 42Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1----------------------------------------------------------------------------------------------------distributed_backend=ncclAll distributed processes registered. Starting with 1 processes----------------------------------------------------------------------------------------------------Missing logger folder: /root/co2-flux-hourly-gpp-modeling/data/models/TreeFT_6HDecoder_230408_2353/lightning_logsLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]   | Name                               | Type                            | Params----------------------------------------------------------------------------------------0  | loss                               | QuantileLoss                    | 0     1  | logging_metrics                    | ModuleList                      | 0     2  | input_embeddings                   | MultiEmbedding                  | 403   3  | prescalers                         | ModuleDict                      | 416   4  | static_variable_selection          | VariableSelectionNetwork        | 148   5  | encoder_variable_selection         | VariableSelectionNetwork        | 20.0 K6  | decoder_variable_selection         | VariableSelectionNetwork        | 17.8 K7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K 8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K 9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K 10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K 11 | lstm_encoder                       | LSTM                            | 2.2 K 12 | lstm_decoder                       | LSTM                            | 2.2 K 13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K 16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K 17 | post_attn_gate_norm                | GateAddNorm                     | 576   18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K 19 | pre_output_gate_norm               | GateAddNorm                     | 576   20 | output_layer                       | Linear                          | 119   ----------------------------------------------------------------------------------------52.1 K    Trainable params0         Non-trainable params52.1 K    Total params0.209     Total estimated model params size (MB)Data size: (4862712, 52)Data Columns: Index(['GPP_NT_VUT_REF', 'site_id', 'timestep_idx_local',       'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day',       'hour', 'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA',       'PA_ERA', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',       'b7', 'IGBP', 'lat', 'long', 'koppen_sub', 'koppen_main', 'c3c4',       'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily',       'PET', 'Ts', 'ESACCI-sm', 'MODIS_LC', 'NDWI', 'Percent_Snow', 'Fpar',       'Lai', 'LST_Day', 'LST_Night', 'MODIS_IGBP', 'MODIS_PFT',       'gap_flag_hour', 'gap_flag_month', 'rfr_pred_gpp'],      dtype='object')NA count: 0Training timestemp length = 4380.Experiment logs saved to /root/co2-flux-hourly-gpp-modeling/data/models/TreeFT_6HDecoder_230408_2353.Subest length: 4380 timesteps for each sitesSubset num train timesteps: 341640Subset num val timesteps: 113880Number of parameters in network: 52.1kSanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|                                                                                               | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|                                                                                  | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  3.36it/s]Sanity Checking DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.95it/s]                                                                                                                                           Training: 0it [00:00, ?it/s]Training:   0%|                                                                                                   | 0/6993 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                                    | 0/6993 [00:00<?, ?it/s][W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())Training time: 11841.435663096Best model path: /root/co2-flux-hourly-gpp-modeling/data/models/TreeFT_6HDecoder_230408_2353/lightning_logs/version_0/checkpoints/epoch=19-step=104880.ckptSaved model to /root/co2-flux-hourly-gpp-modeling/data/models/TreeFT_6HDecoder_230408_2353/model.pth