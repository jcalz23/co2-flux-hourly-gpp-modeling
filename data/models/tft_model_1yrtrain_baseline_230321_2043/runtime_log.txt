2023-03-21 20:43:01.827341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMATo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.2023-03-21 20:43:01.955834: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.2023-03-21 20:43:01.959770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory2023-03-21 20:43:01.959798: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.2023-03-21 20:43:02.628333: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory2023-03-21 20:43:02.628414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory2023-03-21 20:43:02.628429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.Global seed set to 42Global seed set to 42GPU available: True (cuda), used: TrueTPU available: False, using: 0 TPU coresIPU available: False, using: 0 IPUsHPU available: False, using: 0 HPUsMissing logger folder: /root/co2-flux-hourly-gpp-modeling/data/models/tft_model_1yrtrain_baseline_230321_2043/lightning_logsLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]   | Name                               | Type                            | Params----------------------------------------------------------------------------------------0  | loss                               | QuantileLoss                    | 0     1  | logging_metrics                    | ModuleList                      | 0     2  | input_embeddings                   | MultiEmbedding                  | 877   3  | prescalers                         | ModuleDict                      | 4.1 K 4  | static_variable_selection          | VariableSelectionNetwork        | 1.3 K 5  | encoder_variable_selection         | VariableSelectionNetwork        | 914 K 6  | decoder_variable_selection         | VariableSelectionNetwork        | 878 K 7  | static_context_variable_selection  | GatedResidualNetwork            | 66.3 K8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 66.3 K9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 66.3 K10 | static_context_enrichment          | GatedResidualNetwork            | 66.3 K11 | lstm_encoder                       | LSTM                            | 132 K 12 | lstm_decoder                       | LSTM                            | 132 K 13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 33.0 K14 | post_lstm_add_norm_encoder         | AddNorm                         | 256   15 | static_enrichment                  | GatedResidualNetwork            | 82.7 K16 | multihead_attn                     | InterpretableMultiHeadAttention | 41.2 K17 | post_attn_gate_norm                | GateAddNorm                     | 33.3 K18 | pos_wise_ff                        | GatedResidualNetwork            | 66.3 K19 | pre_output_gate_norm               | GateAddNorm                     | 33.3 K20 | output_layer                       | Linear                          | 903   ----------------------------------------------------------------------------------------2.6 M     Trainable params0         Non-trainable params2.6 M     Total params10.444    Total estimated model params size (MB)Data size: (4862712, 51)Data Columns: Index(['GPP_NT_VUT_REF', 'site_id', 'timestep_idx_local',       'timestep_idx_global', 'datetime', 'date', 'year', 'month', 'day',       'hour', 'TA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'VPD_ERA', 'P_ERA',       'PA_ERA', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',       'b7', 'IGBP', 'lat', 'long', 'koppen_sub', 'koppen_main', 'c3c4',       'c4_percent', 'BESS-PAR', 'BESS-PARdiff', 'BESS-RSDN', 'CSIF-SIFdaily',       'PET', 'Ts', 'ESACCI-sm', 'MODIS_LC', 'NDWI', 'Percent_Snow', 'Fpar',       'Lai', 'LST_Day', 'LST_Night', 'MODIS_IGBP', 'MODIS_PFT',       'gap_flag_hour', 'gap_flag_month'],      dtype='object')NA count: 0Training timestemp length = 8760.Experiment logs saved to /root/co2-flux-hourly-gpp-modeling/data/models/tft_model_1yrtrain_baseline_230321_2043.Subest length: 8760 timesteps for each sitesSubset num train timesteps: 683280Subset num val timesteps: 227760  Number of parameters in network: 2610.9kSanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|                                                                                                                                                                                                          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                             | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 1/2 [00:00<00:00,  1.60it/s]Sanity Checking DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.27it/s]                                                                                                                                                                                                                                                 Training: 0it [00:00, ?it/s]Training:   0%|                                                                                                                                                                                                             | 0/13962 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                                                                                         | 1/13962 [00:01<4:39:13,  1.20s/it, loss=3.46, v_num=0, train_loss_step=3.460]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:11<00:00,  3.83it/s]Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:17<00:00,  1.83it/s, loss=0.649, v_num=0, train_loss_step=0.578, val_loss=0.723, train_loss_epoch=0.729]Epoch 1:   0%|                                                                                                                | 1/13962 [00:01<3:56:08,  1.01s/it, loss=0.649, v_num=0, train_loss_step=0.578, val_loss=0.723, train_loss_epoch=0.729]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:10<00:00,  3.83it/s]Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:06<00:00,  1.83it/s, loss=0.662, v_num=0, train_loss_step=0.643, val_loss=0.705, train_loss_epoch=0.662]Epoch 2:   0%|                                                                                                                | 1/13962 [00:00<3:52:20,  1.00it/s, loss=0.662, v_num=0, train_loss_step=0.643, val_loss=0.705, train_loss_epoch=0.662]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:09<00:00,  3.84it/s]Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:18<00:00,  1.83it/s, loss=0.649, v_num=0, train_loss_step=0.718, val_loss=0.707, train_loss_epoch=0.647]Epoch 3:   0%|                                                                                                                | 1/13962 [00:01<3:56:42,  1.02s/it, loss=0.649, v_num=0, train_loss_step=0.718, val_loss=0.707, train_loss_epoch=0.647]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:12<00:00,  3.83it/s]Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:02<00:00,  1.83it/s, loss=0.672, v_num=0, train_loss_step=0.725, val_loss=0.701, train_loss_epoch=0.637]Epoch 4:   0%|                                                                                                                | 1/13962 [00:01<4:00:26,  1.03s/it, loss=0.672, v_num=0, train_loss_step=0.725, val_loss=0.701, train_loss_epoch=0.637]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:12<00:00,  3.82it/s]Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:49<00:00,  1.82it/s, loss=0.585, v_num=0, train_loss_step=0.545, val_loss=0.695, train_loss_epoch=0.630]Epoch 5:   0%|                                                                                                                | 1/13962 [00:01<3:56:07,  1.01s/it, loss=0.585, v_num=0, train_loss_step=0.545, val_loss=0.695, train_loss_epoch=0.630]]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:11<00:00,  3.83it/s]Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:50<00:00,  1.82it/s, loss=0.659, v_num=0, train_loss_step=0.664, val_loss=0.696, train_loss_epoch=0.625]Epoch 6:   0%|                                                                                                                | 1/13962 [00:01<3:54:35,  1.01s/it, loss=0.659, v_num=0, train_loss_step=0.664, val_loss=0.696, train_loss_epoch=0.625]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:12<00:00,  3.82it/s]Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:52<00:00,  1.82it/s, loss=0.601, v_num=0, train_loss_step=0.525, val_loss=0.691,                                                                                                                          | 0/13962 [00:00<?, ?it/s, loss=0.601, v_num=0, train_loss_step=0.525, val_loss=0.691, train_loss_epoch=0.620]Epoch 7:   0%|                                                                                                                | 1/13962 [00:01<4:03:46,  1.05s/it, loss=0.601, v_num=0, train_loss_step=0.525, val_loss=0.691, Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:12<00:00,  3.83it/s]Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:49<00:00,  1.82it/s, loss=0.652, v_num=0, train_loss_step=0.498, val_loss=0.696, train_loss_epoch=0.616]Epoch 8:   0%|                                                                                                                | 1/13962 [00:01<4:00:17,  1.03s/it, loss=0.652, v_num=0, train_loss_step=0.498, val_loss=0.696, train_loss_epoch=0.616]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:11<00:00,  3.83it/s]Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:42<00:00,  1.82it/s, loss=0.575, v_num=0, train_loss_step=0.867, val_loss=0.695, train_loss_epoch=0.612]Epoch 9:   0%|                                                                                                                | 1/13962 [00:01<4:01:40,  1.04s/it, loss=0.575, v_num=0, train_loss_step=0.867, val_loss=0.695, train_loss_epoch=0.612]Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:12<00:00,  3.83it/s]Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:07:53<00:00,  1.82it/s, loss=0.639, v_num=0, train_loss_step=0.499, val_loss=0.691, train_loss_epoch=0.608]Epoch 10:   0%|                                                                                                               | 1/13962 [00:01<4:05:58,  1.06s/it, loss=0.639, v_num=0, train_loss_step=0.499, val_loss=0.691, train_loss_epoch=0.608]                                                                                                          | 8/13962 [00:05<2:42:14,  1.43it/s, loss=0.661, v_num=0, train_loss_step=0.633, val_loss=0.691, Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3491/3491 [15:11<00:00,  3.83it/s]Epoch 10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:08:05<00:00,  1.82it/s, loss=0.632, v_num=0, train_loss_step=0.534, val_loss=0.692, train_loss_epoch=0.605]Epoch 10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 13962/13962 [2:08:06<00:00,  1.82it/s, loss=0.632, v_num=0, train_loss_step=0.534, val_loss=0.692, train_loss_epoch=0.605]Training time: 84239.824539749Best model path: /root/co2-flux-hourly-gpp-modeling/data/models/tft_model_1yrtrain_baseline_230321_2043/lightning_logs/version_0/checkpoints/epoch=10-step=115181.ckptSaved model to /root/co2-flux-hourly-gpp-modeling/data/models/tft_model_1yrtrain_baseline_230321_2043/model.pth